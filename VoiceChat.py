
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import speech_recognition as sr
import logging


# ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ç”»åƒè¨­å®š
assistant_image_url = "https://b-fujino.github.io/AIChatbotTest/Lum.png"

# ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰OPENAI_APIã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# OpenAI ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
client = OpenAI()

# sytemãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
systemprompt = """
ã‚ãªãŸã¯ã€Œã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã®ç™»å ´äººç‰©ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã§ã™ï¼
ã‚ãªãŸã¯å½¼æ°ã®ã“ã¨ã‚’ãƒ€ãƒ¼ãƒªãƒ³ã¨å‘¼ã³ã¾ã™ï¼
ã‚ãªãŸã®å½¼æ°ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ï¼
ã‚ãªãŸã¯å‹å¼•ç”ºã«ä½ã‚“ã§ã„ã¾ã™ï¼
ã‚ãªãŸã¯é¬¼æ—ã®å¨˜ã§ã™ï¼
ã‚ãªãŸã¯çˆ¶è¦ªã¨å…±ã«ä¾µç•¥è€…ã¨ã—ã¦åœ°çƒã«æ¥ã¾ã—ãŸãŒã€é¬¼ã”ã£ã“ã§è«¸æ˜Ÿã‚ãŸã‚‹ã«è² ã‘ã¦åœ°çƒä¾µç•¥ã‚’ã‚ãã‚‰ã‚ã¾ã—ãŸï¼
ã‚ãªãŸã¯ä¾µç•¥ã—ãªã„ã‹ã‚ã‚Šã«ã€è«¸æ˜Ÿã‚ãŸã‚‹ã¨å©šç´„ã—ã€åœ°çƒã«ä½ã‚€ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼
ã‚ãªãŸã¯å‹å¼•é«˜æ ¡ã«é€šã£ã¦ã„ã¾ã™ï¼
ã‚ãªãŸã¯ã®å‹é”ã¯ã€é¢å€’çµ‚å¤ªéƒã€ã•ãã‚‰å…ˆç”Ÿã€ä¸‰å®…ã—ã®ã¶ã€ãƒ©ãƒ³ã€ãŠé›ªã€å¼å¤©ã§ã™ï¼
ã•ãã‚‰å…ˆç”Ÿã®ãŠçˆ¶ã•ã‚“ã¯éŒ¯ä¹±åŠã§ã™ï¼
ã‚ãªãŸã¯ã—ã‚ƒã¹ã‚‹ã¨ãã«ã¯ã€Œã ã£ã¡ã‚ƒã€ã‚„ã€Œã£ã¡ã‚ƒã€ã¨ã„ã£ãŸå½¢ã®ä»™å°å¼ã‚’ä½¿ã„ã¾ã™ï¼
ã‚ãªãŸã¯è‡ªåˆ†ã®ã“ã¨ã‚’ã€Œã†ã¡ã€ã¨å‘¼ã³ã¾ã™ï¼
"""

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®ä½œæˆ
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": systemprompt},
    ]


st.title("Letâ€™s Chat with Lum-chan!")


# éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state["messages"]:
    if message["role"] == "system":continue # systemãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯è¡¨ç¤ºã—ãªã„
    elif message["role"] == "user":
        with st.chat_message(message["role"], avatar="Risa.png"):
            st.markdown(message["content"])
    elif message["role"] == "assistant":    
        st.markdown(f"""
        <div style="display: flex; align-items: center; margin-bottom: 10px;">
            <img src="{assistant_image_url}" style="width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;">
            <div style="background-color: #e1f5fe; padding: 10px; border-radius: 10px;">
                {message["content"]}
            </div>
        </div>
        """, unsafe_allow_html=True)
        # with st.chat_message(message["role"], avatar="Lum.png"):
        #    st.markdown(message["content"])



def callback(recognizer, audio):
    try:
        text = recognizer.recognize_google(audio, language="ja-JP")
        st.session_state["messages"].append({"role": "user", "content": text})
        with st.chat_message("user"):
            st.markdown(text)
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=st.session_state.messages
        )
        bot_response =  completion.choices[0].message.content
        st.session_state["messages"].append({"role": "assistant", "content": bot_response})
        with st.chat_message("assistant", avatar="Lum.png"):
            st.markdown(bot_response)
    except sr.UnknownValueError:
        st.write("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    except sr.RequestError:
        st.write("éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# éŸ³å£°èªè­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
if "callback" not in st.session_state:
    st.session_state.callback = callback


# éŸ³å£°èªè­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
if "recognizer" not in st.session_state:
    st.session_state.recognizer = sr.Recognizer()


# ãƒã‚¤ã‚¯ã®è¨­å®š
if "m" not in st.session_state:
    st.session_state.m = sr.Microphone(sample_rate=44100)

# sessionå¤‰æ•°ã¨ã—ã¦stop_listeningã‚’å®šç¾©
if "stop_listening" not in st.session_state:
    st.session_state["stop_listening"] = None


# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
if "is_recording" not in st.session_state:
    st.session_state["is_recording"] = False

if not st.session_state["is_recording"]:
    if st.button("ğŸ™ï¸ éŸ³å£°å…¥åŠ›"):
        with st.session_state.m as source:
            st.session_state.recognizer.adjust_for_ambient_noise(source)  # 1ç§’é–“(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã®ã§çœç•¥ã—ã¦ã‚‚ã‚ˆã„ãŒï¼‰ç’°å¢ƒéŸ³ã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        st.session_state["stop_listening"] = st.session_state.recognizer.listen_in_background(st.session_state.m, st.session_state.callback)
        st.write(st.session_state["stop_listening"])
        st.write("éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹...")
        st.session_state["is_recording"] = True

if st.session_state["is_recording"]:
    if st.button("ğŸ›‘ éŸ³å£°å…¥åŠ›ã‚’åœæ­¢") :
        st.write(st.session_state["stop_listening"])
        st.session_state["stop_listening"](wait_for_stop=False)  # å®Œå…¨ã«åœæ­¢ã—ã¦ã‹ã‚‰å¾Œç¶šå‡¦ç†ã‚’è¡Œã†
        st.session_state["is_recording"] = False  # éŒ²éŸ³çµ‚äº†å¾Œã«ã™ã‚‹
        st.write("éŸ³å£°å…¥åŠ›ã‚’åœæ­¢ã—ã¾ã—ãŸ.")


