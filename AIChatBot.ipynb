{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIChatBotをStreamlitとOpenAIで作ってみる．\n",
    "\n",
    "OpenAIのAPIキーは.envに書着込む．.envは.gitignoreに含めてGitHubではシェアされないようにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai, streamlit, python-dotenvをインストールする．\n",
    "python-dotenvは.envを読み込んで環境変数とできるパッケージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.whisper_env/lib/python3.9/site-packages (1.63.2)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 5.5 MB/s eta 0:00:01     |█▍                              | 409 kB 2.4 MB/s eta 0:00:04     |███████████████████▏            | 5.7 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.whisper_env/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.whisper_env/lib/python3.9/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./.whisper_env/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.whisper_env/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.whisper_env/lib/python3.9/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: tqdm>4 in ./.whisper_env/lib/python3.9/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.whisper_env/lib/python3.9/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.whisper_env/lib/python3.9/site-packages (from openai) (4.8.0)\n",
      "Collecting protobuf<6,>=3.20\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "\u001b[K     |████████████████████████████████| 417 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6,>=4.0\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=7.0\n",
      "  Downloading pyarrow-19.0.1-cp39-cp39-macosx_12_0_x86_64.whl (32.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.1 MB 689 kB/s eta 0:00:01    |████████▎                       | 8.3 MB 393 kB/s eta 0:01:01     |████████████████                | 16.0 MB 3.5 MB/s eta 0:00:05     |████████████████▌               | 16.5 MB 3.5 MB/s eta 0:00:05��████▊ | 30.8 MB 689 kB/s eta 0:00:02\n",
      "\u001b[?25hCollecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./.whisper_env/lib/python3.9/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./.whisper_env/lib/python3.9/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./.whisper_env/lib/python3.9/site-packages (from streamlit) (1.24.3)\n",
      "Collecting pandas<3,>=1.4.0\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6 MB 1.5 MB/s eta 0:00:011   |█████████▍                      | 3.7 MB 8.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting tenacity<10,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[K     |████████████████████████████████| 731 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 6.8 MB/s eta 0:00:01     |██████████▏                     | 2.2 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging<25,>=20 in ./.whisper_env/lib/python3.9/site-packages (from streamlit) (24.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow<12,>=7.1.0 in ./.whisper_env/lib/python3.9/site-packages (from streamlit) (11.1.0)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting click<9,>=7.0\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 3.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./.whisper_env/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Collecting jsonschema>=3.0\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Downloading narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.8 in ./.whisper_env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.whisper_env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: httpcore==1.* in ./.whisper_env/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: certifi in ./.whisper_env/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.whisper_env/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.23.1-cp39-cp39-macosx_10_12_x86_64.whl (372 kB)\n",
      "\u001b[K     |████████████████████████████████| 372 kB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting referencing>=0.28.4\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./.whisper_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[K     |████████████████████████████████| 507 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in ./.whisper_env/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.whisper_env/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.whisper_env/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.whisper_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.whisper_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.whisper_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.whisper_env/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: rpds-py, attrs, referencing, smmap, mdurl, jsonschema-specifications, tzdata, pytz, narwhals, markdown-it-py, jsonschema, gitdb, toml, tenacity, rich, pydeck, pyarrow, protobuf, pandas, gitpython, click, cachetools, blinker, altair, streamlit, python-dotenv\n",
      "Successfully installed altair-5.5.0 attrs-25.1.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.28.0 pandas-2.2.3 protobuf-5.29.3 pyarrow-19.0.1 pydeck-0.9.1 python-dotenv-1.0.1 pytz-2025.1 referencing-0.36.2 rich-13.9.4 rpds-py-0.23.1 smmap-5.0.2 streamlit-1.42.2 tenacity-9.0.0 toml-0.10.2 tzdata-2025.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/fujinohidenori/dev/project/.whisper_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openai streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずはOpenAIを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！初めまして、ラムちゃんだよ！今日はどんなことをお話しする？✨\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会話を継続させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "面堂くんだっちゃ！よろしくなんだっちゃ！いつも豪華な家に住んでるんだから、すごいっちゃね。でも、うちのこともちゃんと見てくれると嬉しいんだっちゃ！何か面白いことでも考えてるのかな？\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"初めましてだっちゃ.うち，ラムって言うっちゃ.よろしくだっちゃ！あなたは何って名前だっちゃ？\"\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"私は面堂終太郎です，よろしくお願いします！\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlitでインタフェースをつけてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "input_message = \"\"\n",
    "st.title(\"OpenAI Chat API\")\n",
    "input_message=st.text_input(\"メッセージを入力してください\")\n",
    "\n",
    "# もしSession Stateに保存されていないなら\n",
    "if \"message\" not in st.session_state:\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "else:\n",
    "    message  = st.session_state.message\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "\n",
    "if input_message != \"\":\n",
    "# テキスト生成のリクエストを送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=message\n",
    "    )\n",
    "\n",
    "\n",
    "    # Session Stateに保存\n",
    "    message.append({\"role\":\"system\",\"content\": completion.choices[0].message.content})\n",
    "    st.session_state.message = message\n",
    "\n",
    "    # 結果を表示\n",
    "    st.write(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.107:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(system_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat履歴をAssistantとUserとで別々に簡単に分けられる．\n",
    "ただ，上記だと，表記のタイミングの問題でインプットボックスの下にレスポンスが表記され，再度入力したときに，その内容が上の履歴に表記された後に，また次のインプットに対するレスポンスが下に表記される，と言う形になる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだと，inputボックスのメッセージが残り続けてしまい，rerunされるたびにinputがOpenAI に送られてしまう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.chat_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "st.chat_input()にするとうまくいくんだけど，今度は入力確定のエンターに反応されてしまう．\n",
    "どうもWindowsだと上手くいくが，気持ち悪いので，Formウィジェットでまとめることにした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\"):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やはり入力が残ってしまう・・・\n",
    "調べたらformを作る時の引数で設定できるようだ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "#import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．これで上手く行った！！\n",
    "アイコンをカスタマイズできると良いな．\n",
    "avatar引数を使えばいけるのか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            # st.markdown(f\"\"\"\n",
    "            # <div style=\"display: flex; justify-content: flex-end; align-items: center; margin-bottom: 10px;\">\n",
    "            #     <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "            #         {message[\"content\"]}\n",
    "            #     </div>\n",
    "            #     <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-left: 10px;\">\n",
    "            # </div>\n",
    "            # \"\"\", unsafe_allow_html=True)    \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.3.90.186:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音声入力を可能にする\n",
    "Streamlitで作ったチャットぼっとを音声入力可能にする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どこを書き換えるのかを確認．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile chatWithSTT.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\": \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "\"\"\"\n",
    "ここを変更することになる\n",
    "イメージする動作はスペースキーを押している間は録音\n",
    "スペースキーがUpすると録音が終了してSTTに送られる\n",
    "\n",
    "\"\"\"\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## とりあえずスペースが押されている間だけ録音するプログラムを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_webrtc\n",
      "  Downloading streamlit_webrtc-0.47.9-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiortc<2.0.0,>=1.9.0 (from streamlit_webrtc)\n",
      "  Downloading aiortc-1.10.1-cp39-abi3-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc) (24.2)\n",
      "Requirement already satisfied: streamlit>=0.84.1 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc) (1.42.0)\n",
      "Collecting aioice<1.0.0,>=0.9.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading aioice-0.9.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting av<14.0.0,>=9.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading av-13.1.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting cffi>=1.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Using cached cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography>=42.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting google-crc32c>=1.1 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading google_crc32c-1.6.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyee>=9.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pylibsrtp-0.11.0-cp39-abi3-macosx_10_9_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyopenssl>=24.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.2.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (6.4.2)\n",
      "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (1.25.2)\n",
      "Collecting pycparser (from cffi>=1.0.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.84.1->streamlit_webrtc) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.84.1->streamlit_webrtc) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (1.17.0)\n",
      "Downloading streamlit_webrtc-0.47.9-py3-none-any.whl (772 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.6/772.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiortc-1.10.1-cp39-abi3-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aioice-0.9.0-py3-none-any.whl (24 kB)\n",
      "Downloading av-13.1.0-cp313-cp313-macosx_10_13_x86_64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl (182 kB)\n",
      "Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-0.11.0-cp39-abi3-macosx_10_9_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: google-crc32c\n",
      "  Building wheel for google-crc32c (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-crc32c: filename=google_crc32c-1.6.0-py3-none-any.whl size=13227 sha256=7fe4a37259886460a88ce28f7748734e8029a48bbc1346bbc05da155f000de18\n",
      "  Stored in directory: /Users/fujinohidenori/Library/Caches/pip/wheels/f0/30/2d/4f76c4cb14c0d620b09072202f0ef711f657109eaef3c1cf75\n",
      "Successfully built google-crc32c\n",
      "Installing collected packages: ifaddr, pyee, pycparser, google-crc32c, dnspython, av, cffi, aioice, pylibsrtp, cryptography, pyopenssl, aiortc, streamlit_webrtc\n",
      "Successfully installed aioice-0.9.0 aiortc-1.10.1 av-13.1.0 cffi-1.17.1 cryptography-44.0.1 dnspython-2.7.0 google-crc32c-1.6.0 ifaddr-0.2.0 pycparser-2.22 pyee-12.1.1 pylibsrtp-0.11.0 pyopenssl-25.0.0 streamlit_webrtc-0.47.9\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit_webrtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初，試したらエラー吐き出した．\n",
    "`AttributeError: 'NoneType' object has no attribute 'sendto' `\n",
    "調べてるとバージョンの問題らしい．\n",
    "https://qiita.com/akeyhero/items/fe5bdd02d9a1cd7782d7#realtime-api-との橋渡しを司るメソッド\n",
    "指定されているバージョンのものを入れることにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: streamlit 1.42.0\n",
      "Uninstalling streamlit-1.42.0:\n",
      "  Successfully uninstalled streamlit-1.42.0\n",
      "Found existing installation: streamlit-webrtc 0.47.9\n",
      "Uninstalling streamlit-webrtc-0.47.9:\n",
      "  Successfully uninstalled streamlit-webrtc-0.47.9\n",
      "Collecting streamlit==1.38.0\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting streamlit_webrtc==0.47.9\n",
      "  Using cached streamlit_webrtc-0.47.9-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.2.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.2.3)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit==1.38.0)\n",
      "  Downloading pillow-10.4.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (13.9.4)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.38.0)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (6.4.2)\n",
      "Requirement already satisfied: aiortc<2.0.0,>=1.9.0 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc==0.47.9) (1.10.1)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.9.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.9.0)\n",
      "Requirement already satisfied: av<14.0.0,>=9.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (13.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=42.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (44.0.1)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (1.6.0)\n",
      "Requirement already satisfied: pyee>=9.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (12.1.1)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.11.0)\n",
      "Requirement already satisfied: pyopenssl>=24.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (25.0.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (1.25.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (2.19.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./venv/lib/python3.13/site-packages (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in ./venv/lib/python3.13/site-packages (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.2.0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.13/site-packages (from cffi>=1.0.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.38.0) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit==1.38.0) (1.17.0)\n",
      "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached streamlit_webrtc-0.47.9-py3-none-any.whl (772 kB)\n",
      "Downloading pillow-10.4.0-cp313-cp313-macosx_10_13_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, pillow, streamlit, streamlit_webrtc\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "Successfully installed pillow-10.4.0 streamlit-1.38.0 streamlit_webrtc-0.47.9 tenacity-8.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall streamlit streamlit_webrtc -y\n",
    "!pip install streamlit==1.38.0 streamlit_webrtc==0.47.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.13/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from soundfile) (2.2.2)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.13/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soundfile\n",
      "Successfully installed soundfile-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting STT.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile STT.py\n",
    "import streamlit as st\n",
    "from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "class AudioProcessor(AudioProcessorBase):\n",
    "    def __init__(self):\n",
    "        self.audio_data = []\n",
    "\n",
    "    def recv(self, frame):\n",
    "        self.audio_data.append(frame.to_ndarray())\n",
    "        return frame\n",
    "\n",
    "st.title(\"マイク録音アプリ\")\n",
    "\n",
    "webrtc_ctx = webrtc_streamer(\n",
    "    key=\"example\",\n",
    "    mode=WebRtcMode.SENDRECV,\n",
    "    audio_processor_factory=AudioProcessor,\n",
    "    media_stream_constraints={\"audio\": True, \"video\": False},\n",
    ")\n",
    "\n",
    "if webrtc_ctx.audio_processor:\n",
    "    st.write(\"録音中...\")\n",
    "    audio_processor = webrtc_ctx.audio_processor\n",
    "\n",
    "    if st.button(\"録音停止\"):\n",
    "        st.write(\"録音停止\")\n",
    "        audio_data = np.concatenate(audio_processor.audio_data, axis=0)\n",
    "        audio_bytes = io.BytesIO()\n",
    "        sf.write(audio_bytes, audio_data, 16000, format='WAV')\n",
    "        st.audio(audio_bytes.getvalue(), format='audio/wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.11.6:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/google_crc32c/__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
      "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "2025-02-21 15:05:18.379 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 88, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 590, in code_to_exec\n",
      "    exec(code, module.__dict__)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/STT.py\", line 32, in <module>\n",
      "    sf.write(audio_bytes, audio_data, 16000, format='WAV')\n",
      "    ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 363, in write\n",
      "    with SoundFile(file, 'w', samplerate, channels,\n",
      "         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                   subtype, endian, format, closefd,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                   compression_level, bitrate_mode) as f:\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 690, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "                 ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 1265, in _open\n",
      "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
      "soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x1187d1080>: Format not recognised.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run STT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よくわからんエラーが出るし，ChatGPTに聞いてもよくわからんしで，やり方を変える．\n",
    "そもそもWebRTCまで使う必要がないような気もしてきたし．\n",
    "調べたら，こんなの出てきた．\n",
    "https://note.com/astropomeai/n/n0529cc860862\n",
    "これ見てると，そんなに複雑なことしなくてもいけるようだ．\n",
    "\n",
    "さらにaudio_recorder_streamlitについても情報収集\n",
    "https://qiita.com/papasim824/items/f57b0eef0b296ea8f75b#apppy\n",
    "\n",
    "とりあえず単純な録音をしてみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audio_recorder_streamlit\n",
      "  Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: streamlit>=1.12.0 in ./venv/lib/python3.13/site-packages (from audio_recorder_streamlit) (1.38.0)\n",
      "Collecting altair<5 (from audio_recorder_streamlit)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting entrypoints (from altair<5->audio_recorder_streamlit)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (4.23.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (2.2.2)\n",
      "Requirement already satisfied: pandas>=0.18 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (2.2.3)\n",
      "Collecting toolz (from altair<5->audio_recorder_streamlit)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (6.4.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (4.0.12)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2025.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<5->audio_recorder_streamlit) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair<5->audio_recorder_streamlit) (1.17.0)\n",
      "Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: toolz, entrypoints, altair, audio_recorder_streamlit\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 5.5.0\n",
      "    Uninstalling altair-5.5.0:\n",
      "      Successfully uninstalled altair-5.5.0\n",
      "Successfully installed altair-4.2.2 audio_recorder_streamlit-0.0.10 entrypoints-0.4 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install audio_recorder_streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sound.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sound.py\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "\n",
    "\n",
    "#  初期化\n",
    "if \"audio_list\" not in st.session_state:\n",
    "    st.session_state.audio_list = []\n",
    "\n",
    "audio_bytes = False\n",
    "audio_bytes = audio_recorder()\n",
    "if audio_bytes:\n",
    "    st.session_state.audio_list.append(audio_bytes)\n",
    "\n",
    "with st.sidebar:\n",
    "    st.write(\"# 🎙️録った音\")\n",
    "    if st.session_state.audio_list:\n",
    "\n",
    "        for audio_bytes in st.session_state.audio_list:\n",
    "            st.audio(audio_bytes, format=\"audio/wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.11.6:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run sound.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうもSafariの場合，なぜか最初の録音の時だけ，開始していきなり録音が止まるみたい．\n",
    "Chromeなら行けた．\n",
    "ということで，Safari対策として録音時間が短い場合は処理を飛ばすようにした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting STT.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile STT.py\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# 環境ファイルからAPIキーを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "st.title(\"音声認識アプリ\")\n",
    "\n",
    "# 音声録音\n",
    "audio_bytes = audio_recorder(pause_threshold=30)\n",
    "\n",
    "if audio_bytes:\n",
    "    #もしデータの量があまりに少ないなら\n",
    "    if len(audio_bytes) < 1000:\n",
    "        st.write(\"音声データが短すぎます\")\n",
    "        st.stop()\n",
    "\n",
    "    # OpenAI に送信\n",
    "    client = OpenAI()\n",
    "    with NamedTemporaryFile(delete=True, suffix=\".wav\") as f:\n",
    "        f.write(audio_bytes)\n",
    "        f.flush()\n",
    "        with open(f.name, \"rb\") as audio_file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file\n",
    "            )        \n",
    "    st.write(transcription.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run STT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．とりあえずは上手く行ったようだ．\n",
    "\n",
    "続いて，できれば，レコーディングをスペースキーの操作でやれるようにしたい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やり方をチャットGPTに聞いてみたら．Javascriptでローカルに保存したものをPostメソッドで Streamlitに返すというやり方．とりあえず試す．\n",
    "ChatGPTに聞いてソース吐き出させてやったが，もうそれするなら Streamlitにこだわる必要なくない？って思えてきた．\n",
    "普通にWebサーバを立ててやればできるように思う．FrontEndはJavascriptで．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ともかく統合\n",
    "とりあえず，そのあたりのインタフェースの改善は改めて検討するとして，Voice Chatシステムに統合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            # st.markdown(f\"\"\"\n",
    "            # <div style=\"display: flex; justify-content: flex-end; align-items: center; margin-bottom: 10px;\">\n",
    "            #     <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "            #         {message[\"content\"]}\n",
    "            #     </div>\n",
    "            #     <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-left: 10px;\">\n",
    "            # </div>\n",
    "            # \"\"\", unsafe_allow_html=True)    \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "\n",
    "# 音声録音\n",
    "audio_bytes = audio_recorder(pause_threshold=30)\n",
    "if audio_bytes:\n",
    "    #もしデータの量があまりに少ないなら\n",
    "    if len(audio_bytes) < 1000:\n",
    "        st.write(\"音声データが短すぎます\")\n",
    "        st.stop()\n",
    "\n",
    "    # OpenAI に送信\n",
    "    client = OpenAI()\n",
    "    with NamedTemporaryFile(delete=True, suffix=\".wav\") as f:\n",
    "        f.write(audio_bytes)\n",
    "        f.flush()\n",
    "        with open(f.name, \"rb\") as audio_file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file\n",
    "            )        \n",
    "    # st.write(transcription.text)    \n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": transcription.text})\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とりあえずは動くけど，rerunするたびにマイクの利用制限がかかるのは非常に面倒．．．だけど，rerunしないと表示は変わらない．どうしたものか．\n",
    "\n",
    "単純にrerunをさせずに，その都度の相手からの返信を表示するだけなら，動的な表示の変更が可能なのか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatGPTに聞いた\n",
    "SpeechRecognitionなるものがあるらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in ./.whisper_env/lib/python3.9/site-packages (0.2.14)\n",
      "Collecting speechrecognition\n",
      "  Using cached SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
      "Requirement already satisfied: typing-extensions in ./.whisper_env/lib/python3.9/site-packages (from speechrecognition) (4.12.2)\n",
      "Installing collected packages: speechrecognition\n",
      "Successfully installed speechrecognition-3.14.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/fujinohidenori/dev/project/.whisper_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install  pyaudio speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "\n",
    "# チャット履歴を保存するセッション状態を確保\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = []\n",
    "\n",
    "st.title(\"シンプルチャットアプリ（音声入力対応）\")\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        st.write(\"音声入力を開始...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=15)\n",
    "            text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"音声を認識できませんでした。\"\n",
    "        except sr.RequestError:\n",
    "            return \"音声認識サービスにアクセスできませんでした。\"\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# 音声入力ボタン\n",
    "if st.button(\"🎙️ 音声入力\"):\n",
    "    user_input = recognize_speech()\n",
    "else:\n",
    "    user_input = st.text_input(\"メッセージを入力してください:\", \"\", key=\"user_input\")\n",
    "\n",
    "if user_input:\n",
    "    # ユーザーメッセージを表示\n",
    "    st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # 簡単な応答をする（今回はエコー）\n",
    "    bot_response = f\"あなたはこう言いました: {user_input}\"\n",
    "    st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored in: <module 'threading' from '/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1440, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1053, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1073, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/asyncio/base_events.py\", line 791, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/asyncio/base_events.py\", line 510, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
