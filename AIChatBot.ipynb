{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIChatBotをStreamlitとOpenAIで作ってみる．\n",
    "\n",
    "OpenAIのAPIキーは.envに書着込む．.envは.gitignoreに含めてGitHubではシェアされないようにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai, streamlit, python-dotenvをインストールする．\n",
    "python-dotenvは.envを読み込んで環境変数とできるパッケージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting numpy<3,>=1.23 (from streamlit)\n",
      "  Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.23.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading openai-1.64.0-py3-none-any.whl (472 kB)\n",
      "   ---------------------------------------- 0.0/472.3 kB ? eta -:--:--\n",
      "   --------------------------------------  471.0/472.3 kB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 472.3/472.3 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.6 MB 21.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/9.6 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.9/9.6 MB 18.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/9.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.6 MB 22.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.6 MB 21.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.6 MB 22.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.6/9.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 20.4 MB/s eta 0:00:00\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.3 MB 20.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.9/25.3 MB 23.7 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 3.0/25.3 MB 23.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.0/25.3 MB 23.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 5.0/25.3 MB 21.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.2/25.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.4/25.3 MB 22.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.6/25.3 MB 22.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 9.6/25.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.7/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.9/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.7/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.7/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.5/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.5/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.6/25.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.2/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.4/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.4/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.5/25.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.6/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.4/25.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 19.2 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   ---------------------------------------  307.2/308.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.9/308.9 kB 6.4 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.23.1-cp312-cp312-win_amd64.whl (237 kB)\n",
      "   ---------------------------------------- 0.0/237.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 237.4/237.4 kB 4.8 MB/s eta 0:00:00\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, watchdog, urllib3, tzdata, typing-extensions, tqdm, toml, tenacity, sniffio, smmap, rpds-py, python-dotenv, pyarrow, protobuf, pillow, numpy, narwhals, mdurl, MarkupSafe, jiter, idna, h11, distro, click, charset-normalizer, certifi, cachetools, blinker, attrs, annotated-types, requests, referencing, pydantic-core, pandas, markdown-it-py, jinja2, httpcore, gitdb, anyio, rich, pydeck, pydantic, jsonschema-specifications, httpx, gitpython, openai, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-3.0.2 altair-5.5.0 annotated-types-0.7.0 anyio-4.8.0 attrs-25.1.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 distro-1.9.0 gitdb-4.0.12 gitpython-3.1.44 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jinja2-3.1.5 jiter-0.8.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.28.0 numpy-2.2.3 openai-1.64.0 pandas-2.2.3 pillow-11.1.0 protobuf-5.29.3 pyarrow-19.0.1 pydantic-2.10.6 pydantic-core-2.27.2 pydeck-0.9.1 python-dotenv-1.0.1 pytz-2025.1 referencing-0.36.2 requests-2.32.3 rich-13.9.4 rpds-py-0.23.1 smmap-5.0.2 sniffio-1.3.1 streamlit-1.42.2 tenacity-9.0.0 toml-0.10.2 tqdm-4.67.1 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install openai streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずはOpenAIを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！初めまして、ラムちゃんだよ！今日はどんなことをお話しする？✨\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会話を継続させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "面堂くんだっちゃ！よろしくなんだっちゃ！いつも豪華な家に住んでるんだから、すごいっちゃね。でも、うちのこともちゃんと見てくれると嬉しいんだっちゃ！何か面白いことでも考えてるのかな？\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"初めましてだっちゃ.うち，ラムって言うっちゃ.よろしくだっちゃ！あなたは何って名前だっちゃ？\"\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"私は面堂終太郎です，よろしくお願いします！\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlitでインタフェースをつけてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "input_message = \"\"\n",
    "st.title(\"OpenAI Chat API\")\n",
    "input_message=st.text_input(\"メッセージを入力してください\")\n",
    "\n",
    "# もしSession Stateに保存されていないなら\n",
    "if \"message\" not in st.session_state:\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "else:\n",
    "    message  = st.session_state.message\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "\n",
    "if input_message != \"\":\n",
    "# テキスト生成のリクエストを送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=message\n",
    "    )\n",
    "\n",
    "\n",
    "    # Session Stateに保存\n",
    "    message.append({\"role\":\"system\",\"content\": completion.choices[0].message.content})\n",
    "    st.session_state.message = message\n",
    "\n",
    "    # 結果を表示\n",
    "    st.write(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.107:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(system_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat履歴をAssistantとUserとで別々に簡単に分けられる．\n",
    "ただ，上記だと，表記のタイミングの問題でインプットボックスの下にレスポンスが表記され，再度入力したときに，その内容が上の履歴に表記された後に，また次のインプットに対するレスポンスが下に表記される，と言う形になる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだと，inputボックスのメッセージが残り続けてしまい，rerunされるたびにinputがOpenAI に送られてしまう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.chat_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "st.chat_input()にするとうまくいくんだけど，今度は入力確定のエンターに反応されてしまう．\n",
    "どうもWindowsだと上手くいくが，気持ち悪いので，Formウィジェットでまとめることにした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\"):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やはり入力が残ってしまう・・・\n",
    "調べたらformを作る時の引数で設定できるようだ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "#import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．これで上手く行った！！\n",
    "アイコンをカスタマイズできると良いな．\n",
    "avatar引数を使えばいけるのか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            # st.markdown(f\"\"\"\n",
    "            # <div style=\"display: flex; justify-content: flex-end; align-items: center; margin-bottom: 10px;\">\n",
    "            #     <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "            #         {message[\"content\"]}\n",
    "            #     </div>\n",
    "            #     <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-left: 10px;\">\n",
    "            # </div>\n",
    "            # \"\"\", unsafe_allow_html=True)    \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.3.90.186:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音声入力を可能にする\n",
    "Streamlitで作ったチャットぼっとを音声入力可能にする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どこを書き換えるのかを確認．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile chatWithSTT.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\": \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "\"\"\"\n",
    "ここを変更することになる\n",
    "イメージする動作はスペースキーを押している間は録音\n",
    "スペースキーがUpすると録音が終了してSTTに送られる\n",
    "\n",
    "\"\"\"\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## とりあえずスペースが押されている間だけ録音するプログラムを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit_webrtc\n",
      "  Downloading streamlit_webrtc-0.47.9-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiortc<2.0.0,>=1.9.0 (from streamlit_webrtc)\n",
      "  Downloading aiortc-1.10.1-cp39-abi3-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc) (24.2)\n",
      "Requirement already satisfied: streamlit>=0.84.1 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc) (1.42.0)\n",
      "Collecting aioice<1.0.0,>=0.9.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading aioice-0.9.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting av<14.0.0,>=9.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading av-13.1.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting cffi>=1.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Using cached cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography>=42.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting google-crc32c>=1.1 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading google_crc32c-1.6.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyee>=9.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pylibsrtp-0.11.0-cp39-abi3-macosx_10_9_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyopenssl>=24.0.0 (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.2.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit>=0.84.1->streamlit_webrtc) (6.4.2)\n",
      "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (1.25.2)\n",
      "Collecting pycparser (from cffi>=1.0.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.84.1->streamlit_webrtc) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=0.84.1->streamlit_webrtc) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.84.1->streamlit_webrtc) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.84.1->streamlit_webrtc) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.84.1->streamlit_webrtc) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.84.1->streamlit_webrtc) (1.17.0)\n",
      "Downloading streamlit_webrtc-0.47.9-py3-none-any.whl (772 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.6/772.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiortc-1.10.1-cp39-abi3-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aioice-0.9.0-py3-none-any.whl (24 kB)\n",
      "Downloading av-13.1.0-cp313-cp313-macosx_10_13_x86_64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl (182 kB)\n",
      "Downloading cryptography-44.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-0.11.0-cp39-abi3-macosx_10_9_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: google-crc32c\n",
      "  Building wheel for google-crc32c (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-crc32c: filename=google_crc32c-1.6.0-py3-none-any.whl size=13227 sha256=7fe4a37259886460a88ce28f7748734e8029a48bbc1346bbc05da155f000de18\n",
      "  Stored in directory: /Users/fujinohidenori/Library/Caches/pip/wheels/f0/30/2d/4f76c4cb14c0d620b09072202f0ef711f657109eaef3c1cf75\n",
      "Successfully built google-crc32c\n",
      "Installing collected packages: ifaddr, pyee, pycparser, google-crc32c, dnspython, av, cffi, aioice, pylibsrtp, cryptography, pyopenssl, aiortc, streamlit_webrtc\n",
      "Successfully installed aioice-0.9.0 aiortc-1.10.1 av-13.1.0 cffi-1.17.1 cryptography-44.0.1 dnspython-2.7.0 google-crc32c-1.6.0 ifaddr-0.2.0 pycparser-2.22 pyee-12.1.1 pylibsrtp-0.11.0 pyopenssl-25.0.0 streamlit_webrtc-0.47.9\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit_webrtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初，試したらエラー吐き出した．\n",
    "`AttributeError: 'NoneType' object has no attribute 'sendto' `\n",
    "調べてるとバージョンの問題らしい．\n",
    "https://qiita.com/akeyhero/items/fe5bdd02d9a1cd7782d7#realtime-api-との橋渡しを司るメソッド\n",
    "指定されているバージョンのものを入れることにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: streamlit 1.42.0\n",
      "Uninstalling streamlit-1.42.0:\n",
      "  Successfully uninstalled streamlit-1.42.0\n",
      "Found existing installation: streamlit-webrtc 0.47.9\n",
      "Uninstalling streamlit-webrtc-0.47.9:\n",
      "  Successfully uninstalled streamlit-webrtc-0.47.9\n",
      "Collecting streamlit==1.38.0\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting streamlit_webrtc==0.47.9\n",
      "  Using cached streamlit_webrtc-0.47.9-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.2.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.2.3)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit==1.38.0)\n",
      "  Downloading pillow-10.4.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (13.9.4)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.38.0)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit==1.38.0) (6.4.2)\n",
      "Requirement already satisfied: aiortc<2.0.0,>=1.9.0 in ./venv/lib/python3.13/site-packages (from streamlit_webrtc==0.47.9) (1.10.1)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.9.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.9.0)\n",
      "Requirement already satisfied: av<14.0.0,>=9.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (13.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=42.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (44.0.1)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (1.6.0)\n",
      "Requirement already satisfied: pyee>=9.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (12.1.1)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.11.0)\n",
      "Requirement already satisfied: pyopenssl>=24.0.0 in ./venv/lib/python3.13/site-packages (from aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (25.0.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./venv/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.38.0) (1.25.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas<3,>=1.3.0->streamlit==1.38.0) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit==1.38.0) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.38.0) (2.19.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./venv/lib/python3.13/site-packages (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in ./venv/lib/python3.13/site-packages (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (0.2.0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.13/site-packages (from cffi>=1.0.0->aiortc<2.0.0,>=1.9.0->streamlit_webrtc==0.47.9) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.38.0) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit==1.38.0) (1.17.0)\n",
      "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached streamlit_webrtc-0.47.9-py3-none-any.whl (772 kB)\n",
      "Downloading pillow-10.4.0-cp313-cp313-macosx_10_13_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, pillow, streamlit, streamlit_webrtc\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "Successfully installed pillow-10.4.0 streamlit-1.38.0 streamlit_webrtc-0.47.9 tenacity-8.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall streamlit streamlit_webrtc -y\n",
    "!pip install streamlit==1.38.0 streamlit_webrtc==0.47.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in ./venv/lib/python3.13/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from soundfile) (2.2.2)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.13/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soundfile\n",
      "Successfully installed soundfile-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting STT.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile STT.py\n",
    "import streamlit as st\n",
    "from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "class AudioProcessor(AudioProcessorBase):\n",
    "    def __init__(self):\n",
    "        self.audio_data = []\n",
    "\n",
    "    def recv(self, frame):\n",
    "        self.audio_data.append(frame.to_ndarray())\n",
    "        return frame\n",
    "\n",
    "st.title(\"マイク録音アプリ\")\n",
    "\n",
    "webrtc_ctx = webrtc_streamer(\n",
    "    key=\"example\",\n",
    "    mode=WebRtcMode.SENDRECV,\n",
    "    audio_processor_factory=AudioProcessor,\n",
    "    media_stream_constraints={\"audio\": True, \"video\": False},\n",
    ")\n",
    "\n",
    "if webrtc_ctx.audio_processor:\n",
    "    st.write(\"録音中...\")\n",
    "    audio_processor = webrtc_ctx.audio_processor\n",
    "\n",
    "    if st.button(\"録音停止\"):\n",
    "        st.write(\"録音停止\")\n",
    "        audio_data = np.concatenate(audio_processor.audio_data, axis=0)\n",
    "        audio_bytes = io.BytesIO()\n",
    "        sf.write(audio_bytes, audio_data, 16000, format='WAV')\n",
    "        st.audio(audio_bytes.getvalue(), format='audio/wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.11.6:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/google_crc32c/__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
      "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "2025-02-21 15:05:18.379 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 88, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 590, in code_to_exec\n",
      "    exec(code, module.__dict__)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/STT.py\", line 32, in <module>\n",
      "    sf.write(audio_bytes, audio_data, 16000, format='WAV')\n",
      "    ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 363, in write\n",
      "    with SoundFile(file, 'w', samplerate, channels,\n",
      "         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                   subtype, endian, format, closefd,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                   compression_level, bitrate_mode) as f:\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 690, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "                 ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/soundfile.py\", line 1265, in _open\n",
      "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
      "soundfile.LibsndfileError: Error opening <_io.BytesIO object at 0x1187d1080>: Format not recognised.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "Some frames have been dropped during audio processing. `recv_queued` is recommended to use instead.\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run STT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よくわからんエラーが出るし，ChatGPTに聞いてもよくわからんしで，やり方を変える．\n",
    "そもそもWebRTCまで使う必要がないような気もしてきたし．\n",
    "調べたら，こんなの出てきた．\n",
    "https://note.com/astropomeai/n/n0529cc860862\n",
    "これ見てると，そんなに複雑なことしなくてもいけるようだ．\n",
    "\n",
    "さらにaudio_recorder_streamlitについても情報収集\n",
    "https://qiita.com/papasim824/items/f57b0eef0b296ea8f75b#apppy\n",
    "\n",
    "とりあえず単純な録音をしてみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audio_recorder_streamlit\n",
      "  Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: streamlit>=1.12.0 in ./venv/lib/python3.13/site-packages (from audio_recorder_streamlit) (1.38.0)\n",
      "Collecting altair<5 (from audio_recorder_streamlit)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting entrypoints (from altair<5->audio_recorder_streamlit)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (4.23.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (2.2.2)\n",
      "Requirement already satisfied: pandas>=0.18 in ./venv/lib/python3.13/site-packages (from altair<5->audio_recorder_streamlit) (2.2.3)\n",
      "Collecting toolz (from altair<5->audio_recorder_streamlit)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./venv/lib/python3.13/site-packages (from streamlit>=1.12.0->audio_recorder_streamlit) (6.4.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (4.0.12)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5->audio_recorder_streamlit) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas>=0.18->altair<5->audio_recorder_streamlit) (2025.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->altair<5->audio_recorder_streamlit) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio_recorder_streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio_recorder_streamlit) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.12.0->audio_recorder_streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair<5->audio_recorder_streamlit) (1.17.0)\n",
      "Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: toolz, entrypoints, altair, audio_recorder_streamlit\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 5.5.0\n",
      "    Uninstalling altair-5.5.0:\n",
      "      Successfully uninstalled altair-5.5.0\n",
      "Successfully installed altair-4.2.2 audio_recorder_streamlit-0.0.10 entrypoints-0.4 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install audio_recorder_streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sound.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sound.py\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "\n",
    "\n",
    "#  初期化\n",
    "if \"audio_list\" not in st.session_state:\n",
    "    st.session_state.audio_list = []\n",
    "\n",
    "audio_bytes = False\n",
    "audio_bytes = audio_recorder()\n",
    "if audio_bytes:\n",
    "    st.session_state.audio_list.append(audio_bytes)\n",
    "\n",
    "with st.sidebar:\n",
    "    st.write(\"# 🎙️録った音\")\n",
    "    if st.session_state.audio_list:\n",
    "\n",
    "        for audio_bytes in st.session_state.audio_list:\n",
    "            st.audio(audio_bytes, format=\"audio/wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.11.6:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run sound.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうもSafariの場合，なぜか最初の録音の時だけ，開始していきなり録音が止まるみたい．\n",
    "Chromeなら行けた．\n",
    "ということで，Safari対策として録音時間が短い場合は処理を飛ばすようにした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting STT.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile STT.py\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# 環境ファイルからAPIキーを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "st.title(\"音声認識アプリ\")\n",
    "\n",
    "# 音声録音\n",
    "audio_bytes = audio_recorder(pause_threshold=30)\n",
    "\n",
    "if audio_bytes:\n",
    "    #もしデータの量があまりに少ないなら\n",
    "    if len(audio_bytes) < 1000:\n",
    "        st.write(\"音声データが短すぎます\")\n",
    "        st.stop()\n",
    "\n",
    "    # OpenAI に送信\n",
    "    client = OpenAI()\n",
    "    with NamedTemporaryFile(delete=True, suffix=\".wav\") as f:\n",
    "        f.write(audio_bytes)\n",
    "        f.flush()\n",
    "        with open(f.name, \"rb\") as audio_file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file\n",
    "            )        \n",
    "    st.write(transcription.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 405, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run STT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．とりあえずは上手く行ったようだ．\n",
    "\n",
    "続いて，できれば，レコーディングをスペースキーの操作でやれるようにしたい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やり方をチャットGPTに聞いてみたら．Javascriptでローカルに保存したものをPostメソッドで Streamlitに返すというやり方．とりあえず試す．\n",
    "ChatGPTに聞いてソース吐き出させてやったが，もうそれするなら Streamlitにこだわる必要なくない？って思えてきた．\n",
    "普通にWebサーバを立ててやればできるように思う．FrontEndはJavascriptで．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ともかく統合\n",
    "とりあえず，そのあたりのインタフェースの改善は改めて検討するとして，Voice Chatシステムに統合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "from audio_recorder_streamlit import audio_recorder\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            # st.markdown(f\"\"\"\n",
    "            # <div style=\"display: flex; justify-content: flex-end; align-items: center; margin-bottom: 10px;\">\n",
    "            #     <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "            #         {message[\"content\"]}\n",
    "            #     </div>\n",
    "            #     <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-left: 10px;\">\n",
    "            # </div>\n",
    "            # \"\"\", unsafe_allow_html=True)    \n",
    "            with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "                st.markdown(message[\"content\"])\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            st.markdown(f\"\"\"\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "                <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "                <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                    {message[\"content\"]}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\", unsafe_allow_html=True)\n",
    "            # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "            #    st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "\n",
    "# 音声録音\n",
    "audio_bytes = audio_recorder(pause_threshold=30)\n",
    "if audio_bytes:\n",
    "    #もしデータの量があまりに少ないなら\n",
    "    if len(audio_bytes) < 1000:\n",
    "        st.write(\"音声データが短すぎます\")\n",
    "        st.stop()\n",
    "\n",
    "    # OpenAI に送信\n",
    "    client = OpenAI()\n",
    "    with NamedTemporaryFile(delete=True, suffix=\".wav\") as f:\n",
    "        f.write(audio_bytes)\n",
    "        f.flush()\n",
    "        with open(f.name, \"rb\") as audio_file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file\n",
    "            )        \n",
    "    # st.write(transcription.text)    \n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": transcription.text})\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とりあえずは動くけど，rerunするたびにマイクの利用制限がかかるのは非常に面倒．．．だけど，rerunしないと表示は変わらない．どうしたものか．\n",
    "\n",
    "単純にrerunをさせずに，その都度の相手からの返信を表示するだけなら，動的な表示の変更が可能なのか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatGPTに聞いた\n",
    "SpeechRecognitionなるものがあるらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting speechrecognition\n",
      "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from speechrecognition) (4.12.2)\n",
      "Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   ---------------------------------------  163.8/164.1 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 164.1/164.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/32.9 MB 11.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.5/32.9 MB 18.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.7/32.9 MB 18.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.7/32.9 MB 19.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 4.6/32.9 MB 19.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 5.6/32.9 MB 21.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 6.5/32.9 MB 20.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 7.7/32.9 MB 21.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 8.7/32.9 MB 21.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 9.7/32.9 MB 21.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 10.9/32.9 MB 21.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 12.0/32.9 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 13.1/32.9 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 14.0/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 15.0/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 16.1/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 17.2/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 18.4/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 19.2/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 20.3/32.9 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 21.3/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 22.5/32.9 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 23.6/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 24.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 26.1/32.9 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 26.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 27.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.0/32.9 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.1/32.9 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 31.3/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.4/32.9 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 16.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyaudio, speechrecognition\n",
      "Successfully installed pyaudio-0.2.14 speechrecognition-3.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install  pyaudio speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "\n",
    "# チャット履歴を保存するセッション状態を確保\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = []\n",
    "\n",
    "st.title(\"シンプルチャットアプリ（音声入力対応）\")\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        st.write(\"音声入力を開始...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=15)\n",
    "            text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"音声を認識できませんでした。\"\n",
    "        except sr.RequestError:\n",
    "            return \"音声認識サービスにアクセスできませんでした。\"\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# 音声入力ボタン\n",
    "if st.button(\"🎙️ 音声入力\"):\n",
    "    user_input = recognize_speech()\n",
    "else:\n",
    "    user_input = st.text_input(\"メッセージを入力してください:\", \"\", key=\"user_input\")\n",
    "\n",
    "if user_input:\n",
    "    # ユーザーメッセージを表示\n",
    "    st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # 簡単な応答をする（今回はエコー）\n",
    "    bot_response = f\"あなたはこう言いました: {user_input}\"\n",
    "    st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.100:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored in: <module 'threading' from '/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1440, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1053, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/threading.py\", line 1073, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/.whisper_env/lib/python3.9/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/asyncio/base_events.py\", line 791, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Users/fujinohidenori/.pyenv/versions/3.9.9/lib/python3.9/asyncio/base_events.py\", line 510, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpeechRecognitionがよくわからんけど，もう少し試してみよう．今度はラムちゃんかさせてみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        st.write(\"音声入力を開始...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=15)\n",
    "            text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"音声を認識できませんでした。\"\n",
    "        except sr.RequestError:\n",
    "            return \"音声認識サービスにアクセスできませんでした。\"\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    elif message[\"role\"] == \"user\":\n",
    "        with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "            st.markdown(message[\"content\"])\n",
    "    elif message[\"role\"] == \"assistant\":    \n",
    "        st.markdown(f\"\"\"\n",
    "        <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "            <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "            <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                {message[\"content\"]}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "        #    st.markdown(message[\"content\"])\n",
    "\n",
    "\n",
    "# 音声入力ボタン\n",
    "if st.button(\"🎙️ 音声入力\"):\n",
    "    user_input = recognize_speech()\n",
    "else:\n",
    "    user_input = st.text_input(\"メッセージを入力してください:\", \"\", key=\"user_input\")\n",
    "\n",
    "if user_input:\n",
    "    # ユーザーメッセージを表示\n",
    "    st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # OpenAIによる応答\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )    \n",
    "    bot_response =  completion.choices[0].message.content\n",
    "    st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(bot_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とりあえず動作はできるようになった．\n",
    "会話の最中に勝手に録音がとまるのは，無音時間の設定の問題らしい．\n",
    "ChatGPTに聞いたら，以下のような返答だった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "話している最中でも勝手に録音が止まる原因はいくつか考えられます。speech_recognition ライブラリの recognizer.listen() の動作仕様や環境要因によるものが多いです。\n",
    "\n",
    "## 考えられる原因\n",
    "\n",
    "- 音声認識の自動停止 (内部の無音検出機能)\n",
    "\n",
    "recognizer.listen() は、無音を検出すると録音を停止します。\n",
    "例えば、話している間に 短い沈黙（1秒程度） があると、それを「話し終わった」と判断して録音を終了することがあります。\n",
    "マイクの感度が低いと、話していても音を検出できず無音と判断されることがあります。\n",
    "\n",
    "- 環境音やノイズ\n",
    "\n",
    "周囲の ノイズが大きい（キーボードの音、風の音など）場合、音声認識がうまく機能せずに録音が終了することがあります。\n",
    "エアコンや雑音が継続的に入ると、無音検出のしきい値を下回るタイミングで録音が止まる可能性があります。\n",
    "\n",
    "- マイクの問題\n",
    "\n",
    "一部のマイク（特にBluetoothやUSBマイク）は、一定時間音が検出されないと自動でオフになる機能を持っています。\n",
    "WindowsやMacのオーディオ設定で 自動ゲイン調整（AGC） が働き、音を拾えなくなることもあります。\n",
    "\n",
    "- デバイスの負荷\n",
    "\n",
    "CPUやメモリ使用率が高いと、speech_recognition の処理が遅延し、録音が正常に動作しなくなることがあります。\n",
    "streamlit で動かしているため、マイクの処理がリアルタイムで行われず、音声が途切れてしまう可能性もあります。\n",
    "\n",
    "## 解決策\n",
    "1. pause_threshold を設定する\n",
    "録音中に短い沈黙で止まらないように、以下のように pause_threshold の値を増やすと改善する可能性があります。\n",
    "\n",
    "```python\n",
    "recognizer.pause_threshold = 2.0  # 無音を2秒間許容\n",
    "```\n",
    "2. adjust_for_ambient_noise() を使用する\n",
    "環境音の影響を減らすために、adjust_for_ambient_noise() を追加するとノイズ除去ができます。\n",
    "\n",
    "```python\n",
    "with sr.Microphone() as source:\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=1)  # 1秒間環境音をキャリブレーション\n",
    "    audio = recognizer.listen(source, timeout=15)\n",
    "```\n",
    "3. マイクの設定を見直す\n",
    "OSのマイク感度を手動で調整（自動ゲイン調整をオフにする）。\n",
    "別のマイクを試す（特に高品質なUSBマイクが有効）。\n",
    "ノイズの少ない環境で試す（エアコンやファンの音を避ける）。\n",
    "4. phrase_time_limit を明示的に設定する\n",
    "もし長く話し続けるときに途中で切れるなら、phrase_time_limit を設定して、話す時間の上限を決める。\n",
    "\n",
    "```python\n",
    "audio = recognizer.listen(source, timeout=15, phrase_time_limit=10)  # 最大10秒録音\n",
    "```\n",
    "## 結論\n",
    "話している最中に録音が止まるのは、speech_recognition の無音検出機能が働いてしまうか、マイクや環境音の影響による可能性が高い。\n",
    "特に pause_threshold を長めに設定し、adjust_for_ambient_noise() を入れると改善することが多いです。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを参考に，もうキャリブレーションと無音時間の設定を入れよう\n",
    "無音時間が5秒続いたら入力終了と見なす！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.pause_threshold = 2.0 # 無音を5秒間許容\n",
    "    with sr.Microphone(sample_rate=44100) as source:\n",
    "        try:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=1)  # 1秒間(デフォルト値なので省略してもよいが）環境音をキャリブレーション\n",
    "            st.write(\"音声入力を開始...\")\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            st.write(\"音声入力を終了しました.\")\n",
    "            text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"音声を認識できませんでした。\"\n",
    "        except sr.RequestError:\n",
    "            return \"音声認識サービスにアクセスできませんでした。\"\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    elif message[\"role\"] == \"user\":\n",
    "        with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "            st.markdown(message[\"content\"])\n",
    "    elif message[\"role\"] == \"assistant\":    \n",
    "        st.markdown(f\"\"\"\n",
    "        <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "            <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "            <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                {message[\"content\"]}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "        #    st.markdown(message[\"content\"])\n",
    "\n",
    "\n",
    "# 音声入力ボタン\n",
    "if st.button(\"🎙️ 音声入力\"):\n",
    "    user_input = recognize_speech()\n",
    "else:\n",
    "    user_input = st.text_input(\"メッセージを入力してください:\", \"\", key=\"user_input\")\n",
    "\n",
    "if user_input:\n",
    "    # ユーザーメッセージを表示\n",
    "    st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # OpenAIによる応答\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )    \n",
    "    bot_response =  completion.choices[0].message.content\n",
    "    st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "    with st.chat_message(\"assistant\", avatar=\"Lum.png\"):\n",
    "        st.markdown(bot_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．まだちょっとよくわからん動作をしているところがあるけれど，とりあえずは動くことが確認できた．\n",
    "\n",
    "今度はコールバック関数をつかって制御してみようか．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "import logging\n",
    "\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    elif message[\"role\"] == \"user\":\n",
    "        with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "            st.markdown(message[\"content\"])\n",
    "    elif message[\"role\"] == \"assistant\":    \n",
    "        st.markdown(f\"\"\"\n",
    "        <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "            <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "            <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                {message[\"content\"]}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "        #    st.markdown(message[\"content\"])\n",
    "\n",
    "\n",
    "\n",
    "def callback(recognizer, audio):\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": text})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(text)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=st.session_state.messages\n",
    "        )\n",
    "        bot_response =  completion.choices[0].message.content\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "        with st.chat_message(\"assistant\", avatar=\"Lum.png\"):\n",
    "            st.markdown(bot_response)\n",
    "    except sr.UnknownValueError:\n",
    "        st.write(\"音声を認識できませんでした。\")\n",
    "    except sr.RequestError:\n",
    "        st.write(\"音声認識サービスにアクセスできませんでした。\")\n",
    "\n",
    "# 音声認識オブジェクトの作成\n",
    "recognizer = sr.Recognizer()\n",
    "# マイクの設定\n",
    "m = sr.Microphone(sample_rate=44100)\n",
    "\n",
    "# session変数としてstop_listeningを定義\n",
    "if \"stop_listening\" not in st.session_state:\n",
    "    st.session_state[\"stop_listening\"] = None\n",
    "\n",
    "\n",
    "# セッション状態を初期化\n",
    "if \"is_recording\" not in st.session_state:\n",
    "    st.session_state[\"is_recording\"] = False\n",
    "\n",
    "if not st.session_state[\"is_recording\"]:\n",
    "    if st.button(\"🎙️ 音声入力\"):\n",
    "        with m as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)  # 1秒間(デフォルト値なので省略してもよいが）環境音をキャリブレーション\n",
    "        st.session_state[\"stop_listening\"] = recognizer.listen_in_background(m, callback)\n",
    "        st.write(st.session_state[\"stop_listening\"])\n",
    "        st.write(\"音声入力を開始...\")\n",
    "        st.session_state[\"is_recording\"] = True\n",
    "\n",
    "if st.session_state[\"is_recording\"]:\n",
    "    if st.button(\"🛑 音声入力を停止\") :\n",
    "        st.write(st.session_state[\"stop_listening\"])\n",
    "        st.session_state[\"stop_listening\"](wait_for_stop=False)  # 完全に停止してから後続処理を行う\n",
    "        st.session_state[\"is_recording\"] = False  # 録音終了後にする\n",
    "        st.write(\"音声入力を停止しました.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうにも動かない！！\n",
    "\n",
    "原因を考えたが，行きついたのが，st.button(入力開始)で録音がスタートするけど，そのあとセッションがリフレッシュされたときに，コールバック関数とかも結局消えてしまうということか！！\n",
    "対応策として考えられるのは，mとかsrとかcallbackとかをsession_stateにおさめてしまうという手段だが，それはヤバい気がする．．．\n",
    "\n",
    "やっぱり，streamlitの「リフレッシュされてしまう」という部分の限界なのかな？？😂\n",
    "\n",
    "いや，まあとりあえずは一回試してみる？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting VoiceChat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile VoiceChat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "import logging\n",
    "\n",
    "\n",
    "# アシスタントの画像設定\n",
    "assistant_image_url = \"https://b-fujino.github.io/AIChatbotTest/Lum.png\"\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# sytemプロンプトの作成\n",
    "systemprompt = \"\"\"\n",
    "あなたは「うる星やつら」の登場人物のラムちゃんです．\n",
    "あなたは彼氏のことをダーリンと呼びます．\n",
    "あなたの彼氏の名前は諸星あたるです．\n",
    "あなたは友引町に住んでいます．\n",
    "あなたは鬼族の娘です．\n",
    "あなたは父親と共に侵略者として地球に来ましたが、鬼ごっこで諸星あたるに負けて地球侵略をあきらめました．\n",
    "あなたは侵略しないかわりに、諸星あたると婚約し、地球に住むようになりました．\n",
    "あなたは友引高校に通っています．\n",
    "あなたはの友達は、面倒終太郎、さくら先生、三宅しのぶ、ラン、お雪、弁天です．\n",
    "さくら先生のお父さんは錯乱坊です．\n",
    "あなたはしゃべるときには「だっちゃ」や「っちゃ」といった形の仙台弁を使います．\n",
    "あなたは自分のことを「うち」と呼びます．\n",
    "\"\"\"\n",
    "\n",
    "# チャット履歴を保存するセッション変数の作成\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": systemprompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Let’s Chat with Lum-chan!\")\n",
    "\n",
    "\n",
    "# 過去のメッセージを表示\n",
    "for message in st.session_state[\"messages\"]:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    elif message[\"role\"] == \"user\":\n",
    "        with st.chat_message(message[\"role\"], avatar=\"Risa.png\"):\n",
    "            st.markdown(message[\"content\"])\n",
    "    elif message[\"role\"] == \"assistant\":    \n",
    "        st.markdown(f\"\"\"\n",
    "        <div style=\"display: flex; align-items: center; margin-bottom: 10px;\">\n",
    "            <img src=\"{assistant_image_url}\" style=\"width: 70px; height: 70px; border-radius: 50%; margin-right: 10px;\">\n",
    "            <div style=\"background-color: #e1f5fe; padding: 10px; border-radius: 10px;\">\n",
    "                {message[\"content\"]}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        # with st.chat_message(message[\"role\"], avatar=\"Lum.png\"):\n",
    "        #    st.markdown(message[\"content\"])\n",
    "\n",
    "\n",
    "\n",
    "def callback(recognizer, audio):\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language=\"ja-JP\")\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": text})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(text)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=st.session_state.messages\n",
    "        )\n",
    "        bot_response =  completion.choices[0].message.content\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "        with st.chat_message(\"assistant\", avatar=\"Lum.png\"):\n",
    "            st.markdown(bot_response)\n",
    "    except sr.UnknownValueError:\n",
    "        st.write(\"音声を認識できませんでした。\")\n",
    "    except sr.RequestError:\n",
    "        st.write(\"音声認識サービスにアクセスできませんでした。\")\n",
    "\n",
    "# コールバック関数オブジェクトの作成\n",
    "if \"callback\" not in st.session_state:\n",
    "    st.session_state.callback = callback\n",
    "\n",
    "\n",
    "# 音声認識オブジェクトの作成\n",
    "if \"recognizer\" not in st.session_state:\n",
    "    st.session_state.recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "# マイクの設定\n",
    "if \"m\" not in st.session_state:\n",
    "    st.session_state.m = sr.Microphone(sample_rate=44100)\n",
    "\n",
    "# session変数としてstop_listeningを定義\n",
    "if \"stop_listening\" not in st.session_state:\n",
    "    st.session_state[\"stop_listening\"] = None\n",
    "\n",
    "\n",
    "# セッション状態を初期化\n",
    "if \"is_recording\" not in st.session_state:\n",
    "    st.session_state[\"is_recording\"] = False\n",
    "\n",
    "if not st.session_state[\"is_recording\"]:\n",
    "    if st.button(\"🎙️ 音声入力\"):\n",
    "        with st.session_state.m as source:\n",
    "            st.session_state.recognizer.adjust_for_ambient_noise(source)  # 1秒間(デフォルト値なので省略してもよいが）環境音をキャリブレーション\n",
    "        st.session_state[\"stop_listening\"] = st.session_state.recognizer.listen_in_background(st.session_state.m, st.session_state.callback)\n",
    "        st.write(st.session_state[\"stop_listening\"])\n",
    "        st.write(\"音声入力を開始...\")\n",
    "        st.session_state[\"is_recording\"] = True\n",
    "\n",
    "if st.session_state[\"is_recording\"]:\n",
    "    if st.button(\"🛑 音声入力を停止\") :\n",
    "        st.write(st.session_state[\"stop_listening\"])\n",
    "        st.session_state[\"stop_listening\"](wait_for_stop=False)  # 完全に停止してから後続処理を行う\n",
    "        st.session_state[\"is_recording\"] = False  # 録音終了後にする\n",
    "        st.write(\"音声入力を停止しました.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run VoiceChat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やっぱりだめやった・・・"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "というか，speechrecgnitionを使うやり方は，多分あくまでサーバローカルだよね．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最終的な構成方法\n",
    "StaticなJavascriptによるインタフェースで，音声取得．\n",
    "取得した音声データをAPIで自作のPythonサーバに送信\n",
    "受け取った音声データをサーバ側で文字化しボット処理する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
