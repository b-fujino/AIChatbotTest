{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIChatBotをStreamlitとOpenAIで作ってみる．\n",
    "\n",
    "OpenAIのAPIキーは.envに書着込む．.envは.gitignoreに含めてGitHubではシェアされないようにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai, streamlit, python-dotenvをインストールする．\n",
    "python-dotenvは.envを読み込んで環境変数とできるパッケージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずはOpenAIを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！初めまして、ラムちゃんだよ！今日はどんなことをお話しする？✨\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会話を継続させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "面堂くんだっちゃ！よろしくなんだっちゃ！いつも豪華な家に住んでるんだから、すごいっちゃね。でも、うちのこともちゃんと見てくれると嬉しいんだっちゃ！何か面白いことでも考えてるのかな？\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルから読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# テキスト生成のリクエストを送信\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"こんにちは.初めまして\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"初めましてだっちゃ.うち，ラムって言うっちゃ.よろしくだっちゃ！あなたは何って名前だっちゃ？\"\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"私は面堂終太郎です，よろしくお願いします！\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlitでインタフェースをつけてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "input_message = \"\"\n",
    "st.title(\"OpenAI Chat API\")\n",
    "input_message=st.text_input(\"メッセージを入力してください\")\n",
    "\n",
    "# もしSession Stateに保存されていないなら\n",
    "if \"message\" not in st.session_state:\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "else:\n",
    "    message  = st.session_state.message\n",
    "    message.append({\"role\": \"user\", \"content\": input_message})\n",
    "\n",
    "\n",
    "if input_message != \"\":\n",
    "# テキスト生成のリクエストを送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=message\n",
    "    )\n",
    "\n",
    "\n",
    "    # Session Stateに保存\n",
    "    message.append({\"role\":\"system\",\"content\": completion.choices[0].message.content})\n",
    "    st.session_state.message = message\n",
    "\n",
    "    # 結果を表示\n",
    "    st.write(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.107:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored on threading shutdown:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1534, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1505, in <lambda>\n",
      "    _threading_atexits.append(lambda: func(*arg, **kwargs))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py\", line 1092, in join\n",
      "    self._handle.join(timeout)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/web/server/server.py\", line 470, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 878, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py\", line 556, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(system_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat履歴をAssistantとUserとで別々に簡単に分けられる．\n",
    "ただ，上記だと，表記のタイミングの問題でインプットボックスの下にレスポンスが表記され，再度入力したときに，その内容が上の履歴に表記された後に，また次のインプットに対するレスポンスが下に表記される，と言う形になる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.text_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだと，inputボックスのメッセージが残り続けてしまい，rerunされるたびにinputがOpenAI に送られてしまう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "if user_input := st.chat_input(\"メッセージを入力してください:\"):\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 表示\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # システムの応答 (ここでは仮の応答)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "st.chat_input()にするとうまくいくんだけど，今度は入力確定のエンターに反応されてしまう．\n",
    "どうもWindowsだと上手くいくが，気持ち悪いので，Formウィジェットでまとめることにした．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\"):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やはり入力が残ってしまう・・・\n",
    "調べたらformを作る時の引数で設定できるようだ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chat.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 環境ファイルからOPENAI_APIを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI のクライアントを取得\n",
    "client = OpenAI()\n",
    "\n",
    "# チャット履歴をセッションに保存\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは「うる星やつら」の登場人物のラムちゃんです.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "st.title(\"Chat App with Streamlit\")\n",
    "\n",
    "# チャット履歴を表示\n",
    "last_role = \"\"\n",
    "with st.container():\n",
    "    for message in st.session_state.messages:\n",
    "        if message[\"role\"] == \"system\":continue # systemプロンプトは表示しない\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "        last_role = message[\"role\"]\n",
    "\n",
    "\n",
    "# もし最後のメッセージがuserだったらOpenAI に送信\n",
    "if last_role == \"user\":\n",
    "    # OpenAI に送信\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=st.session_state.messages\n",
    "    )\n",
    "    system_response = completion.choices[0].message.content\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": system_response})\n",
    "\n",
    "    # 表示\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# ユーザーの入力を受け取る\n",
    "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
    "    user_input = st.text_area(\"メッセージを入力してください:\", key = \"input\")\n",
    "    submit_button = st.form_submit_button(label=\"送信\")\n",
    "\n",
    "if submit_button:\n",
    "    # ユーザーのメッセージを追加\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．これで上手く行った！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.3.90.186:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chat.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
