{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask ã‚’ä½¿ã£ãŸç°¡æ˜“Webã‚¢ãƒ—ãƒª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã¯å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask (from -r requirements.txt (line 1))\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting flask_cors (from -r requirements.txt (line 2))\n",
      "  Using cached flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Collecting speechrecognition (from -r requirements.txt (line 3))\n",
      "  Using cached SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting openai (from -r requirements.txt (line 4))\n",
      "  Using cached openai-1.65.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 5))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting flask-socketio (from -r requirements.txt (line 6))\n",
      "  Using cached Flask_SocketIO-5.5.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting requests (from -r requirements.txt (line 7))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ã€€ã¨ã‚Šã‚ãˆãšéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>Voice Chat App</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Voice Chat App</h1>\n",
    "    <button id=\"start\">é–‹å§‹</button>\n",
    "    <button id=\"stop\" disabled>åœæ­¢</button>\n",
    "    <p><strong>æ–‡å­—èµ·ã“ã—:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIã®å¿œç­”:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const startButton = document.getElementById(\"start\");\n",
    "        const stopButton = document.getElementById(\"stop\");\n",
    "        const transcriptionElement = document.getElementById(\"transcription\");\n",
    "        const aiResponseElement = document.getElementById(\"aiResponse\");\n",
    "        let mediaRecorder;\n",
    "        let audioChunks = [];\n",
    "\n",
    "        startButton.addEventListener(\"click\", async () => {\n",
    "          const stream = await navigator.mediaDevices.getUserMedia({\n",
    "            audio: true,\n",
    "          });\n",
    "          mediaRecorder = new MediaRecorder(stream);\n",
    "\n",
    "          mediaRecorder.ondataavailable = (event) => {\n",
    "            audioChunks.push(event.data);\n",
    "          };\n",
    "\n",
    "          mediaRecorder.onstop = async () => {\n",
    "            const audioBlob = new Blob(audioChunks, { type: \"audio/webm\" });\n",
    "            audioChunks = [];\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"audio\", audioBlob, \"recording.webm\");\n",
    "\n",
    "            fetch(\"/upload\", {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                transcriptionElement.textContent =\n",
    "                  data.text || \"èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\";\n",
    "                aiResponseElement.textContent =\n",
    "                  data.ai_response || \"AIã®å¿œç­”ãªã—ã€‚\";\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\", error);\n",
    "                transcriptionElement.textContent = \"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\";\n",
    "                aiResponseElement.textContent = \"\";\n",
    "              });\n",
    "          };\n",
    "\n",
    "          mediaRecorder.start();\n",
    "          startButton.disabled = true;\n",
    "          stopButton.disabled = false;\n",
    "        });\n",
    "\n",
    "        stopButton.addEventListener(\"click\", () => {\n",
    "          mediaRecorder.stop();\n",
    "          startButton.disabled = false;\n",
    "          stopButton.disabled = true;\n",
    "        });\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app01.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app01.py\n",
    "\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "import os\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"audio\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"audio\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼ã¨ã‚Šã‚ãˆãšéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«.webmã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸï¼\n",
    "ãŸã speech_recgnitionã§ã¯webmã¯å—ã‘å…¥ã‚Œãªã„ã®ã§ï¼Œwavãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼’ã€€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Wavãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app02.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app02.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®HTMLã‚’è¡¨ç¤º\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"audio\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"audio\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    convert_webm_to_wav(audio_path, \"uploads/output.wav\")\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "\n",
    "def convert_webm_to_wav(input_path, output_path):\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_path,  # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "        \"-ar\", \"16000\",  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ 16kHz\n",
    "        \"-ac\", \"1\",  # ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›\n",
    "        \"-preset\", \"ultrafast\",  # é€Ÿåº¦æœ€å„ªå…ˆ\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "# ä½¿ã„æ–¹\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤‰æ›ã«å°‘ã€…æ™‚é–“å–ã‚‰ã‚Œã‚‹ãªï¼ï¼ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼“ã€€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ç›´æ¥Wavãƒ•ã‚¡ã‚¤ãƒ«ã«ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤‰æ›ã«å°‘ã€…æ™‚é–“ãŒã‹ã‹ã‚‹ã®ãŒæ°—ã«ãªã‚‹ã®ã§ï¼Œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®æ®µéšã§ç›´æ¥Wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ã§ããªã„ã‹æ¢ã£ã¦ã¿ãŸã‚‰ï¼ŒRecord.jsãªã‚‹ã‚‚ã®ãŒã‚ã‚‹ã‚ˆã†ã ï¼\n",
    "https://github.com/mattdiamond/Recorderjs\n",
    "Recorder.jsã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦\n",
    "ã“ã‚Œã‚’htmlã«çµ„ã¿è¾¼ã‚“ã§ã¿ã‚‹ï¼\n",
    "\n",
    "ã‘ã©ï¼Œæœ€åˆã‚„ã£ã¦ã¿ãŸã‚‰ï¼Œrecorder.jsã§ã‚¨ãƒ©ãƒ¼ã§ãŸï¼\n",
    "CDNãŒã‚ã‚‹ã‚ˆã†ãªã®ã§ï¼Œãã¡ã‚‰ã§ã‚„ã£ãŸã‚‰ã†ã¾ãè¡Œã£ãŸï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "    <!-- <script src=\"recorder.js\"></script> --> \n",
    "    \n",
    "</head>\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\" disabled>éŒ²éŸ³åœæ­¢</button>\n",
    "    <!-- <audio id=\"audioPlayback\" controls></audio> -->\n",
    "    <!-- <button id=\"uploadAudio\" disabled>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</button> -->\n",
    "    <p><strong>æ–‡å­—èµ·ã“ã—:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIã®å¿œç­”:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "        let audioContext;\n",
    "        let recorder;\n",
    "        let audioBlob;\n",
    "                \n",
    "\n",
    "        document.getElementById(\"startRecording\").addEventListener(\"click\", async () => {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"stopRecording\").addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "                audioBlob = blob;\n",
    "\n",
    "                if (!audioBlob) {\n",
    "                    console.error(\"No audio to upload\");    \n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                const formData = new FormData();\n",
    "                formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                fetch(\"/upload\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    document.getElementById(\"transcription\").textContent =\n",
    "                    data.text || \"èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\";\n",
    "                    document.getElementById(\"aiResponse\").textContent =\n",
    "                    data.ai_response || \"AIã®å¿œç­”ãªã—ã€‚\";\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                    console.error(\"Upload failed:\");\n",
    "                    document.getElementById(\"transcription\").textContent = \"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\";\n",
    "                    document.getElementById(\"aiResponse\").textContent = \"\";\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = false;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "\n",
    "\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app01.pyã§å®Ÿè¡Œï¼\n",
    "CORSã®å•é¡Œã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§å¼¾ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã ï¼ï¼ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flask_corsã‚’ä½¿ã£ã¦ï¼Œã‚µãƒ¼ãƒã®å´ã§CORSå•é¡Œã‚’ç„¡è¦–ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask_cors\n",
      "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Requirement already satisfied: flask>=0.9 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask_cors) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask_cors) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from Werkzeug>=0.7->flask_cors) (3.0.2)\n",
      "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: flask_cors\n",
      "Successfully installed flask_cors-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app03.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app03.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚ˆã—ï¼Œã¨ã‚Šã‚ãˆãšå•é¡Œã¯è§£æ±ºã—ãŸï¼\n",
    "ãƒãƒã£ãŸç†ç”±ã¯ï¼Œfetchã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ãƒ•ã‚©ãƒ«ãƒ€åã¨å‹˜é•ã„ã—ã¦ã„ãŸã“ã¨ï¼ã¤ã¾ã‚Šï¼Œapp.routeã§ã¯/uploadã¨ã—ã¦ã„ã‚‹ã®ã«ï¼Œjavascriptã®æ–¹ã§/uploadsã¨ã—ã¦ã„ãŸï¼ã“ã‚Œã«ã‚ˆã‚Šå½“ç„¶ãªãŒã‚‰ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ãŒãªã„ã‚ã‘ã§ï¼”ï¼ï¼”ã‚¨ãƒ©ãƒ¼ãŒè¿”ã•ã‚Œã‚Œã‚‹ã¨ã„ã†ã“ã¨ã«ãªã£ã¦ã„ãŸï¼åˆ†ã‚Œã°é¦¬é¹¿é¦¬é¹¿ã—ã„å‹˜é•ã„ã‚„ã£ãŸğŸ˜‚\n",
    "\n",
    "ã‚ã¨ï¼Œãƒ‡ãƒãƒƒã‚°ç’°å¢ƒã§ã¯ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒprojectã«ãªã‚‹ã¨ã„ã†ã¨ã“ã‚ã‚‚ãƒãƒã£ãŸğŸ˜‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼”ã€€Speech Recognitionã«ã‹ã‘ã‚‹\n",
    "ã‚ˆã—ï¼Œã“ã“ã‹ã‚‰ã¯pythonã®å´ã®å‡¦ç†ã«é›†ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app04.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app04.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            print(text)\n",
    "            \n",
    "        ai_response = \"test\"\n",
    "        return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼ã“ã‚Œã§ã¨ã‚Šã‚ãˆãšï¼ŒéŸ³å£°èªè­˜çµæœã‚’è¿”ã›ã‚‹ã‚ˆã†ã«ãªã£ãŸï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼•ã€€ openai ã®ã€€Chatï¼¿Compelationã‚’ä½¿ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app05.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app05.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            print(text)\n",
    "\n",
    "        # AIã®å¿œç­”\n",
    "        client = OpenAI()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ]\n",
    "        )\n",
    "        ai_response = completion.choices[0].message.content\n",
    "        return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼ã¨ã‚Šã‚ãˆãšã¯å˜ç™ºä¼šè©±ã¯ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸï¼\n",
    "ç¾æ™‚ç‚¹ã®é•å’Œæ„Ÿãƒ»ä¿®æ­£ã—ãŸã„ç‚¹ã¯\n",
    "ç¾çŠ¶ã ã¨ï¼Œå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒåŒæ™‚ã«å¸°ã£ã¦ãã¦ã—ã¾ã†ï¼\n",
    "ã©ã†ã«ã‹ï¼Œãã®éƒ¨åˆ†ã‚’ã„ã˜ã‚Œãªã„ã‹ï¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã¾ãŸã¤ã«å…ˆã«å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã—ã¦ï¼Œç”»é¢ã«è¡¨ç¤ºã•ã›ã¦ãŠã„ã¦ï¼Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå¸°ã£ã¦ããŸã‚‰ï¼Œæ”¹ã‚ã¦ãã‚Œã‚’è¿”ã™ã¨ã„ã†æ„Ÿã˜ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®6ã€€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆ†ã‘ã¦è¡¨è¨˜ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
    "ã‚„ã‚‹ã¨ã—ãŸã‚‰ï¼Œpostã‚’2å›ã«åˆ†ã‘ã‚‹å½¢ã‹ãªï¼Ÿ\n",
    "Copilotã«èã„ã¦ã¿ãŸã‚‰Web Socketã‚’ä½¿ãˆã°ã§ãã‚‹ã¨ãªï¼ï¼ï¼\n",
    "ã¨ã‚Šã‚ãˆãšã‚„ã£ã¦ã¿ã‚‹ã‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask-socketio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app06.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app06.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index06.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            print(text)\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    threading.Thread(target=get_ai_response, args=(text,)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index06.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index06.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    \n",
    "</head>\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\" disabled>éŒ²éŸ³åœæ­¢</button>\n",
    "    <!-- <audio id=\"audioPlayback\" controls></audio> -->\n",
    "    <!-- <button id=\"uploadAudio\" disabled>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</button> -->\n",
    "    <p><strong>æ–‡å­—èµ·ã“ã—:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIã®å¿œç­”:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "        let audioContext;\n",
    "        let recorder;\n",
    "        let audioBlob;\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            const socket = io();\n",
    "\n",
    "            socket.on('ai_response', (data) => {\n",
    "                document.getElementById(\"aiResponse\").textContent = data.ai_response;\n",
    "            });\n",
    "        });        \n",
    "\n",
    "        document.getElementById(\"startRecording\").addEventListener(\"click\", async () => {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"stopRecording\").addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "                audioBlob = blob;\n",
    "\n",
    "                if (!audioBlob) {\n",
    "                    console.error(\"No audio to upload\");    \n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                const formData = new FormData();\n",
    "                formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                fetch(\"/upload\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    document.getElementById(\"transcription\").textContent =\n",
    "                    data.text || \"èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\";\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                    console.error(\"Upload failed:\");\n",
    "                    document.getElementById(\"transcription\").textContent = \"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\";\n",
    "                    document.getElementById(\"aiResponse\").textContent = \"\";\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = false;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "\n",
    "\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼å…¥åŠ›ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆ¥ã€…ã«è¡¨è¨˜ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼—ã€€ç¶™ç¶šçš„ãªä¼šè©±ã‚’å‡ºæ¥ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼\n",
    "ã¨ã‚Šã‚ãˆãšï¼Œãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ãƒ­ã‚°ã‚’è¨˜è¼‰ã™ã‚‹éƒ¨åˆ†ã«ã¤ã„ã¦ã¯åˆ¥ã«è€ƒãˆã¦ï¼Œã¾ãšã¯ãƒ‘ã‚¤ã‚½ãƒ³ã§å‹•ã‹ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app07.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app07.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index06.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            print(text)\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    threading.Thread(target=get_ai_response, args=(text,)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼ç¶™ç¶šæ€§ã®ã‚ã‚‹ä¼šè©±ã‚‚ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸï¼\n",
    "ã˜ã‚ƒã‚æ¬¡ã¯ï¼ŒTTSã‚’çµ„ã¿è¾¼ã¿ãŸã„ã­ï¼\n",
    "\n",
    "èª¿ã¹ãŸã‚‰Voice Voxã§ã‚ã‚Œã°APIãŒä½¿ãˆã‚‹ã¨ã®ã“ã¨ï¼ãŸã ï¼Œã“ã®APIã¯ã‚ãã¾ã§ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒã§å‹•ãã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ï¼\n",
    "ãƒ­ãƒ¼ã‚«ãƒ«ã§ã©ã‚Œãã‚‰ã„å‹•ä½œæ™‚é–“ã‹ã‹ã‚‹ã‚“ã‚„ã‚ï¼Ÿï¼Ÿ\n",
    "ã¨ã‚Šã‚ãˆãšè©¦ã™ã‹ãƒ»ãƒ»ãƒ»ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®8ã€€éŸ³å£°åˆæˆæ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã¿ã‚‹\n",
    "VoiceVox GUIã‚’ç«‹ã¡ä¸Šã’ã¦ãŠãï¼ã“ã‚Œã«ã‚ˆã‚Šãƒ­ãƒ¼ã‚«ãƒ«ã«VoiceVoxãŒç«‹ã¡ä¸ŠãŒã‚ŠAPIãŒä½¿ãˆã‚‹ï¼\n",
    "ãã®ã¾ã¾é–¢æ•°ã‚’ä½œã£ã¦ãã‚Œã¦ã„ã‚‹äººãŒã„ãŸã®ã§æ‹å€Ÿ\n",
    "\n",
    "https://zenn.dev/zenn24yykiitos/articles/fff3c954ddf42c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (2.32.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\work\\vscode\\aichatbot\\.venv\\lib\\site-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app08.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app08.py\n",
    "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index08.html\")\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            print(text)\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    threading.Thread(target=get_ai_response, args=(text,)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/audio/<filename>\")\n",
    "def get_audio(filename):\n",
    "    return send_file(os.path.join(\"uploads\",filename))\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•° \n",
    "def get_ai_response(text):\n",
    "    \n",
    "    # ç¾åœ¨ã®æ™‚åˆ»å–å¾—\n",
    "    start = time.time()\n",
    "\n",
    "    # OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    ai_time = time.time() - start\n",
    "    print(f\"å‡¦ç†æ™‚é–“: {ai_time} [sec]\") \n",
    "\n",
    "    # éŸ³å£°åˆæˆ\n",
    "    filename = synthesize_voice(ai_response)\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    voice_time = time.time() - start - ai_time\n",
    "    print(f\"éŸ³å£°åˆæˆæ™‚é–“: {voice_time} [sec]\")\n",
    "    \n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response, 'audio': filename})\n",
    "\n",
    "\n",
    "\n",
    "# éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker=1, filename=\"uploads/output.wav\"):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'http://localhost:50021/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'http://localhost:50021/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(synthesis_response.content)\n",
    "        print(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        return \"output.wav\"\n",
    "    else:\n",
    "        print(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index08.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index08.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    \n",
    "</head>\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\" disabled>éŒ²éŸ³åœæ­¢</button>\n",
    "    <!-- <audio id=\"audioPlayback\" controls></audio> -->\n",
    "    <!-- <button id=\"uploadAudio\" disabled>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</button> -->\n",
    "    <p><strong>æ–‡å­—èµ·ã“ã—:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIã®å¿œç­”:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "        let audioContext;\n",
    "        let recorder;\n",
    "        let audioBlob;\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            const socket = io();\n",
    "\n",
    "            socket.on('ai_response', (data) => {\n",
    "                document.getElementById(\"aiResponse\").textContent = data.ai_response;\n",
    "                \n",
    "                // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "                if (data.audio) {\n",
    "                    const audio = new Audio(`/audio/${data.audio}`);\n",
    "                    audio.play();\n",
    "                }    \n",
    "            });\n",
    "        });        \n",
    "\n",
    "        document.getElementById(\"startRecording\").addEventListener(\"click\", async () => {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"stopRecording\").addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "                audioBlob = blob;\n",
    "\n",
    "                if (!audioBlob) {\n",
    "                    console.error(\"No audio to upload\");    \n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                const formData = new FormData();\n",
    "                formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                fetch(\"/upload\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    document.getElementById(\"transcription\").textContent =\n",
    "                    data.text || \"èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\";\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                    console.error(\"Upload failed:\");\n",
    "                    document.getElementById(\"transcription\").textContent = \"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\";\n",
    "                    document.getElementById(\"aiResponse\").textContent = \"\";\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = false;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "\n",
    "\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¨ã‚Šã‚ãˆãšå‹•ãå½¢ã«ã¯ã§ããŸï¼ï¼\n",
    "ãŸã ï¼Œã©ã†ã—ã¦ã‚‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯é…ã„ï¼ï¼ï¼ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼™ï¼šloggingãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã¤ã‹ã£ã¦ã¿ã‚‹ã“ã¨ã«ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting voicecahtapp09.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicecahtapp09.py\n",
    "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#--------------------------------------------------\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\"\n",
    ")\n",
    "#--------------------------------------------------\n",
    "\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index08.html\")\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    logging.info(\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\")\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\")\n",
    "    logging.debug(f\"Saving audio file to {audio_path}\")\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ\n",
    "            logging.debug(text)\n",
    "            print(text)\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    threading.Thread(target=get_ai_response, args=(text,)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/audio/<filename>\")\n",
    "def get_audio(filename):\n",
    "    return send_file(os.path.join(\"output\",filename))\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•° \n",
    "def get_ai_response(text):\n",
    "    \n",
    "    # ç¾åœ¨ã®æ™‚åˆ»å–å¾—\n",
    "    start = time.time()\n",
    "\n",
    "    # OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    ai_time = time.time() - start\n",
    "    logging.debug(f\"å‡¦ç†æ™‚é–“: {ai_time} [sec]\")\n",
    "    print(f\"AIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {ai_time} [sec]\") \n",
    "\n",
    "    # éŸ³å£°åˆæˆ\n",
    "    filename = synthesize_voice(ai_response)\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    voice_time = time.time() - start - ai_time\n",
    "    logging.debug(f\"éŸ³å£°åˆæˆæ™‚é–“: {voice_time} [sec]\")\n",
    "    print(f\"éŸ³å£°åˆæˆæ™‚é–“: {voice_time} [sec]\")\n",
    "    \n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response, 'audio': filename})\n",
    "\n",
    "\n",
    "\n",
    "# éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker=1):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'http://localhost:50021/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'http://localhost:50021/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "        filename = f\"output_{len(messages)}.wav\"\n",
    "        file_path = \"output/\" + filename\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(synthesis_response.content)\n",
    "        logging.debug(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        print(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        return filename\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        print(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼ï¼šhtmlã‚’ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ãŒæ®‹ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting voicecahtapp10.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicecahtapp10.py\n",
    "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#--------------------------------------------------\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "#--------------------------------------------------\n",
    "\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index10.html\")\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    logging.info(\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\")\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\")\n",
    "    audio_file.save(audio_path)\n",
    "    logging.info(f\"Saved audio file to {audio_path}\")\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    start_time = time.time()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    logging.info(f\"éŸ³å£°èªè­˜çµæœ: {text}\")\n",
    "    logging.info(f\"éŸ³å£°èªè­˜æ™‚é–“: {time.time() - start_time} [sec]\")\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    threading.Thread(target=get_ai_response, args=(text,)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/audio/<filename>\")\n",
    "def get_audio(filename):\n",
    "    logging.info(f\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« {filename} ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_file(os.path.join(\"output\",filename))\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "# AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•° \n",
    "def get_ai_response(text):\n",
    "    \n",
    "    # ç¾åœ¨ã®æ™‚åˆ»å–å¾—\n",
    "    start = time.time()\n",
    "\n",
    "    # OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    ai_time = time.time() - start\n",
    "    logging.info(f\"AIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {ai_time} [sec]\")\n",
    "\n",
    "    # éŸ³å£°åˆæˆ\n",
    "    filename = synthesize_voice(ai_response)\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    voice_time = time.time() - start - ai_time\n",
    "    logging.info(f\"éŸ³å£°åˆæˆæ™‚é–“: {voice_time} [sec]\")\n",
    "    \n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response, 'audio': filename})\n",
    "\n",
    "\n",
    "\n",
    "# éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker=1):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'http://localhost:50021/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'http://localhost:50021/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "        filename = f\"output_{len(messages)}.wav\"\n",
    "        file_path = \"output/\" + filename\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(synthesis_response.content)\n",
    "        logging.info(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        print(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        return filename\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        print(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index10.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index10.html\n",
    "\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\">\n",
    "\n",
    "    \n",
    "</head>\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\" disabled>éŒ²éŸ³åœæ­¢</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "        let audioContext;\n",
    "        let recorder;\n",
    "        let audioBlob;\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            const socket = io();\n",
    "\n",
    "            socket.on('ai_response', (data) => {\n",
    "                const markdownText = data.ai_response;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                document.getElementById(\"h_chatlog\").innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "                \n",
    "                // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "                if (data.audio) {\n",
    "                    const audio = new Audio(`/audio/${data.audio}`);\n",
    "                    audio.play();\n",
    "                }\n",
    "                document.getElementById(\"startRecording\").disabled = false;\n",
    "                document.getElementById(\"stopRecording\").disabled = true;                    \n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keydown\", (event) => {\n",
    "                if(document.getElementById(\"startRecording\").disabled){ \n",
    "                    console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    document.getElementById(\"startRecording\").click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keyup\", (event) => {\n",
    "                if(document.getElementById(\"stopRecording\").disabled){\n",
    "                    console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    document.getElementById(\"stopRecording\").click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "        });        \n",
    "\n",
    "        document.getElementById(\"startRecording\").addEventListener(\"click\", async () => {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"stopRecording\").addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "                audioBlob = blob;\n",
    "\n",
    "                if (!audioBlob) {\n",
    "                    console.error(\"No audio to upload\");    \n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                const formData = new FormData();\n",
    "                formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                fetch(\"/upload\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    if(data.text){\n",
    "                         document.getElementById(\"h_chatlog\").innerHTML += `<div class=\"user\">${marked.parse(data.text)}</div>`;\n",
    "                    }\n",
    "                    else console.log(\"Error: éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\");\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                    console.error(\"Upload failed:\");\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "        });\n",
    "\n",
    "\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¦‚ã­ä¸Šæ‰‹ãè¡Œãã‚ˆã†ã«ã§ããŸï¼\n",
    "å¾Œã®å•é¡Œã¯ï¼ŒAIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã«ãªã£ã¦ã„ã‚‹ã®ã‚’ã†ã¾ãè¡¨è¨˜ã™ã‚‹ã“ã¨ã‹ãªï¼\n",
    "\n",
    "-> å¯¾å¿œã—ãŸã€€marked.jsãªã‚“ã¦ã®ãŒã‚ã‚‹ã‚“ã‚„ï¼ã“ã‚Œä½¿ãˆã°ç°¡å˜ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼‘ã€€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒœã‚¤ã‚¹ã®é¸æŠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zenn.dev/zenn24yykiitos/articles/f3e983fe650e08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã‚’å‚è€ƒã«ï¼Œãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting voicechatapp11.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicechatapp11.py\n",
    "\n",
    "from flask import Flask, request, jsonify, send_from_directory, send_file\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index11.html\")\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    logging.info(\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\")\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    #audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "    logging.info(f\"Saved audio file to {audio_path}\")\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    r = sr.Recognizer()\n",
    "    start_time = time.time()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    logging.info(f\"éŸ³å£°èªè­˜çµæœ: {text}\")\n",
    "    logging.info(f\"éŸ³å£°èªè­˜æ™‚é–“: {time.time() - start_time} [sec]\")\n",
    "\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    response = jsonify({\"text\": text})\n",
    "    \n",
    "    # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§AIã®å¿œç­”ã‚’å–å¾—\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    logging.info(f\"AIã®å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚éŸ³å£°åˆæˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ID: {speaker}\")\n",
    "    threading.Thread(target=get_ai_response, args=(text, speaker)).start()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/audio/<filename>\")\n",
    "def get_audio(filename):\n",
    "    logging.info(f\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« {filename} ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_file(os.path.join(\"output\",filename))\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = \"http://localhost:50021/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    filename = synthesize_voice(text, speaker)\n",
    "    return jsonify({\"audio\": filename})\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•° \n",
    "def get_ai_response(text, speaker):\n",
    "    \n",
    "    # ç¾åœ¨ã®æ™‚åˆ»å–å¾—\n",
    "    start = time.time()\n",
    "\n",
    "    # OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    ai_time = time.time() - start\n",
    "    logging.info(f\"AIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {ai_time} [sec]\")\n",
    "\n",
    "    # éŸ³å£°åˆæˆ\n",
    "    filename = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "    # å‡¦ç†æ™‚é–“ã®è¨ˆç®—\n",
    "    voice_time = time.time() - start - ai_time\n",
    "    logging.info(f\"éŸ³å£°åˆæˆæ™‚é–“: {voice_time} [sec]\")\n",
    "    \n",
    "    # WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('ai_response', {'ai_response': ai_response, 'audio': filename})\n",
    "\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'http://localhost:50021/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'http://localhost:50021/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "        #filename = f\"output_{len(messages)}.wav\" #åˆæˆéŸ³å£°ã‚’å…¨éƒ¨æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’ON\n",
    "        filename = \"output.wav\" #åˆæˆéŸ³å£°ã‚’å…¨éƒ¨æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’ON\n",
    "        file_path = \"output/\" + filename\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(synthesis_response.content)\n",
    "        logging.info(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        return filename\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index11.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index11.html\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\" disabled>éŒ²éŸ³åœæ­¢</button>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "      navigator.mediaDevices\n",
    "        .getUserMedia({ audio: true })\n",
    "        .then((stream) => {\n",
    "          window.stream = stream;\n",
    "        })\n",
    "        .catch((error) => {\n",
    "          console.error(\"Error accessing the microphone: \" + error);\n",
    "        });\n",
    "      let audioContext;\n",
    "      let recorder;\n",
    "      let audioBlob;\n",
    "\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const socket = io();\n",
    "\n",
    "        // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        fetch(\"/speaker_ids\")\n",
    "          .then((response) => response.json())\n",
    "          .then((data) => {\n",
    "            const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "            h_speakerSelect.innerHTML = data.join(\"\");\n",
    "          });\n",
    "\n",
    "        // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "        socket.on(\"ai_response\", (data) => {\n",
    "          const markdownText = data.ai_response;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          document.getElementById(\n",
    "            \"h_chatlog\"\n",
    "          ).innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "\n",
    "          // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "          console.log(\"audioãƒªã‚¯ã‚¨ã‚¹ãƒˆ\");\n",
    "          const audio = new Audio(`/audio/${data.audio}`);\n",
    "          console.log(\"audioå—ä¿¡ã—ã¾ã—ãŸ\", audio);\n",
    "          audio.play();\n",
    "\n",
    "          document.getElementById(\"startRecording\").disabled = false;\n",
    "          document.getElementById(\"stopRecording\").disabled = true;\n",
    "          document.getElementById(\"selectSpeaker\").disabled = false;\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keydown\", (event) => {\n",
    "          if (document.getElementById(\"startRecording\").disabled) {\n",
    "            console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            document.getElementById(\"startRecording\").click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keyup\", (event) => {\n",
    "          if (document.getElementById(\"stopRecording\").disabled) {\n",
    "            console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            document.getElementById(\"stopRecording\").click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"speakerTest\").addEventListener(\"click\", () => {\n",
    "          const speaker = document.getElementById(\"h_speakerSelect\").value;\n",
    "          fetch(\"/speaker_test\", {\n",
    "            method: \"POST\",\n",
    "            headers: {\n",
    "              \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            body: JSON.stringify({ speaker }),\n",
    "          })\n",
    "            .then((response) => response.json())\n",
    "            .then((data) => {\n",
    "              const audio = new Audio(`/audio/${data.audio}`);\n",
    "              audio.play();\n",
    "            });\n",
    "        });\n",
    "\n",
    "        document\n",
    "          .getElementById(\"startRecording\")\n",
    "          .addEventListener(\"click\", () => {\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(window.stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "            document.getElementById(\"selectSpeaker\").disabled = true;\n",
    "          });\n",
    "\n",
    "        document\n",
    "          .getElementById(\"stopRecording\")\n",
    "          .addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "              audioBlob = blob;\n",
    "\n",
    "              if (!audioBlob) {\n",
    "                console.error(\"No audio to upload\");\n",
    "                return;\n",
    "              }\n",
    "\n",
    "              const formData = new FormData();\n",
    "              formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "              const speaker = document.getElementById(\"h_speakerSelect\").value;\n",
    "              formData.append(\"speaker\", speaker);\n",
    "\n",
    "              fetch(\"/upload\", {\n",
    "                method: \"POST\",\n",
    "                body: formData,\n",
    "              })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                  if (data.text) {\n",
    "                    document.getElementById(\n",
    "                      \"h_chatlog\"\n",
    "                    ).innerHTML += `<div class=\"user\">${marked.parse(\n",
    "                      data.text\n",
    "                    )}</div>`;\n",
    "                  } else console.log(\"Error: éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\");\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                  console.error(\"Upload failed:\");\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "          });\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼’ã€€ã‚ˆã‚Šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒ–ã—ãŸã„\n",
    "ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥ç‚¹ã‚„æ„Ÿå˜†ç¬¦ãªã©ã®å¥å˜ä½ã«åŒºåˆ‡ã‚Šï¼Œãã‚Œã‚’flaskå´ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§éŸ³å£°åˆæˆã—ï¼Œãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸã§è¿”ã™ï¼ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ã¯å—ã‘å–ã£ãŸã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†ç”Ÿã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing voicechatapp12.py\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from flask_socketio import SocketIO, emit\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index12.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = \"http://localhost:50021/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    filename = synthesize_voice(text, speaker)\n",
    "    return jsonify({\"audio\": filename})\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) #, 'audio': filename})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "\n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    filename = synthesize_voice(ai_response, speaker)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if filename:\n",
    "        socketio.emit('play_audio', {'audio': filename})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/audio/<filename>\")\n",
    "def get_audio(filename):\n",
    "    return send_file(os.path.join(\"output\",filename))\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    # éŸ³å£°èªè­˜ã®çµæœã‚’æœ€åˆã«è¿”ã™\n",
    "    socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    \n",
    "    # ç¶šã‘ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§éŸ³å£°åˆæˆ\n",
    "    ## ã¾ãšã¯ openai ã§å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    socketio.emit(\"AIResponse\", {\"ai_response\": ai_response})\n",
    "\n",
    "    ## éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    logging.info(f\"AIã®å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚éŸ³å£°åˆæˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ID: {speaker}\")    \n",
    "    \n",
    "\n",
    "    def generate():\n",
    "        yield from synthesize_streaming(ai_response, speaker)\n",
    "\n",
    "    socketio.emit(\"Streaming\", {\n",
    "        \"Response\": Response(\n",
    "            stream_with_context(generate()),\n",
    "            content_type=\"application/octet-stream\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'http://localhost:50021/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'http://localhost:50021/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "        filename = f\"output_{len(messages)}.wav\" #åˆæˆéŸ³å£°ã‚’å…¨éƒ¨æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’ON\n",
    "        #filename = \"output.wav\" #åˆæˆéŸ³å£°ã‚’å…¨éƒ¨æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’ON\n",
    "        file_path = \"output/\" + filename\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(synthesis_response.content)\n",
    "        logging.info(f\"éŸ³å£°ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        return filename\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "def preprocess_text(text):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†\n",
    "    text = re.sub(r\"[ã€‚ï¼.]\", \"ã€‚\\n\", text)\n",
    "    text = re.sub(r\"[ï¼Ÿ?]\", \"ï¼Ÿ\\n\", text)\n",
    "    text = re.sub(r\"[ï¼!]\", \"ï¼\\n\", text)\n",
    "    return text\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥ã”ã¨ã«éŸ³å£°åˆæˆã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°\n",
    "def synthesize_streaming(text, speaker):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "    logging.debug(\"ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚Šã¾ã™ã€‚\")\n",
    "    text = preprocess_text(text)\n",
    "    sentences = text.split(\"\\n\")\n",
    "\n",
    "    # å¥ã”ã¨ã«éŸ³å£°åˆæˆ\n",
    "    for sentence in sentences:\n",
    "        if sentence == \"\": continue\n",
    "        \n",
    "        ## ã‚¯ã‚¨ãƒª\n",
    "        query_response = requests.post(\n",
    "            f'http://localhost:50021/audio_query', \n",
    "            params={'text': sentence, 'speaker': speaker}\n",
    "        )\n",
    "        if query_response.status_code != 200:\n",
    "            logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "            return\n",
    "        \n",
    "        ## éŸ³å£°åˆæˆ\n",
    "        logging.debug(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\")\n",
    "        with requests.post(\n",
    "            f'http://localhost:50021/synthesis', \n",
    "            params={'speaker': speaker}, \n",
    "            json=query_response.json(), \n",
    "            stream=True\n",
    "        ) as synthesis_response:\n",
    "            if synthesis_response.status_code != 200:\n",
    "                logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "                return\n",
    "            yield \"---start---\\n\".encode(\"utf-8\")\n",
    "            for chunk in synthesis_response.iter_content(chunk_size=1024):\n",
    "                logging.info(\"ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆ\")\n",
    "                yield chunk\n",
    "            yield \"---end---\\n\".encode(\"utf-8\")\n",
    "\n",
    "            time.sleep(0.2)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing static/index12.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index12.html\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <h1>WAVéŒ²éŸ³ï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <button id=\"stopRecordingWithStreaming\">åœæ­¢ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†</button>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "      navigator.mediaDevices\n",
    "        .getUserMedia({ audio: true })\n",
    "        .then((stream) => {\n",
    "          window.stream = stream;\n",
    "        })\n",
    "        .catch((error) => {\n",
    "          console.error(\"Error accessing the microphone: \" + error);\n",
    "        });\n",
    "      let audioContext;\n",
    "      let recorder;\n",
    "      let audioBlob;\n",
    "\n",
    "      // ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ å–å¾—\n",
    "      const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "      const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "      const stopRecwithStreamingButton = document.getElementById(\n",
    "        \"stopRecordingWithStreaming\"\n",
    "      );\n",
    "      const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "      const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "\n",
    "      // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "      function setBtnonStart() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = false;\n",
    "        stopRecwithStreamingButton.disabled = false;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "      function setBtnunderProcessing() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        stopRecwithStreamingButton.disabled = true;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "      function setBtnonRestart() {\n",
    "        h_startRecButton.disabled = false;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        stopRecwithStreamingButton.disabled = true;\n",
    "        h_speakerSelect.disabled = false;\n",
    "        h_speakerTestButton.disabled = false;\n",
    "      }\n",
    "\n",
    "      // éŸ³å£°åˆæˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†\n",
    "      async function playSnetence(chunks, audioContext) {\n",
    "        const combined = new Uint8Array(\n",
    "          chunks.reduce((acc, chunk) => [...acc, ...chunk], [])\n",
    "        );\n",
    "        const audioBuffer = await audioContext.decodeAudioData(combined.buffer);\n",
    "        const source = audioContext.createBufferSource();\n",
    "        source.buffer = audioBuffer;\n",
    "        source.connect(audioContext.destination);\n",
    "        source.start();\n",
    "\n",
    "        await new Promise((resolve) => {\n",
    "          source.onended = resolve;\n",
    "        });\n",
    "      }\n",
    "\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const socket = io();\n",
    "\n",
    "        // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        fetch(\"/speaker_ids\")\n",
    "          .then((response) => response.json())\n",
    "          .then((data) => {\n",
    "            h_speakerSelect.innerHTML = data.join(\"\");\n",
    "          });\n",
    "\n",
    "        // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "        socket.on(\"SpeechRecognition\", (data) => {\n",
    "          const markdownText = data.text;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          document.getElementById(\n",
    "            \"h_chatlog\"\n",
    "          ).innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "        socket.on(\"ai_response\", (data) => {\n",
    "          const markdownText = data.ai_response;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          document.getElementById(\n",
    "            \"h_chatlog\"\n",
    "          ).innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "        socket.on(\"play_audio\", (data) => {\n",
    "          const audio = new Audio(`/audio/${data.audio}`);\n",
    "          audio.play();\n",
    "        });\n",
    "\n",
    "        //Stremingã§éŸ³å£°åˆæˆã®çµæœã‚’å—ä¿¡\n",
    "        socket.on(\"Streaming\", async (data) => {\n",
    "          const reader = data.Response.body.getReader();\n",
    "          const audioContext = new AudioContext();\n",
    "          let chunks = [];\n",
    "          let proccesing = false;\n",
    "\n",
    "          while (true) {\n",
    "            const { done, value } = await reader.read();\n",
    "            if (done) break;\n",
    "            const textChunk = new TextDecorder(\"utf-8\").decode(value);\n",
    "            if (textChunk.include(\"---start---\")) {\n",
    "              if (chunks.length > 0 && !proccesing) {\n",
    "                proccesing = true;\n",
    "                await playSnetence(chunks, audioContext);\n",
    "                chunks = [];\n",
    "                proccesing = false;\n",
    "              }\n",
    "            } else if (textChunk.include(\"---end---\")) {\n",
    "              proccesing = true;\n",
    "              await playSnetence(chunks, audioContext);\n",
    "              chunks = [];\n",
    "              proccesing = false;\n",
    "            } else {\n",
    "              chunks.push(value);\n",
    "            }\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keydown\", (event) => {\n",
    "          if (h_startRecButton.disabled) {\n",
    "            console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_startRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keyup\", (event) => {\n",
    "          if (h_stopRecButton.disabled) {\n",
    "            console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_stopRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "        h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "          const speaker = h_speakerSelect.value;\n",
    "          fetch(\"/speaker_test\", {\n",
    "            method: \"POST\",\n",
    "            headers: {\n",
    "              \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            body: JSON.stringify({ speaker }),\n",
    "          })\n",
    "            .then((response) => response.json())\n",
    "            .then((data) => {\n",
    "              const audio = new Audio(`/audio/${data.audio}`);\n",
    "              audio.play();\n",
    "            });\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_startRecButton.addEventListener(\"click\", () => {\n",
    "          audioContext = new AudioContext();\n",
    "          const source = audioContext.createMediaStreamSource(window.stream);\n",
    "          recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "          recorder.record();\n",
    "\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnonStart();\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_stopRecButton.addEventListener(\"click\", () => {\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnunderProcessing();\n",
    "\n",
    "          // éŒ²éŸ³ã‚’åœæ­¢\n",
    "          recorder.stop();\n",
    "\n",
    "          // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "          recorder.exportWAV((blob) => {\n",
    "            audioBlob = blob;\n",
    "\n",
    "            if (!audioBlob) {\n",
    "              console.error(\"No audio to upload\");\n",
    "              return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "            const speaker = h_speakerSelect.value;\n",
    "            formData.append(\"speaker\", speaker);\n",
    "\n",
    "            fetch(\"/upload\", {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                console.log(data);\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\");\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              });\n",
    "          });\n",
    "        });\n",
    "\n",
    "        stopRecwithStreamingButton.addEventListener(\"click\", () => {\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnunderProcessing();\n",
    "\n",
    "          // éŒ²éŸ³ã‚’åœæ­¢\n",
    "          recorder.stop();\n",
    "\n",
    "          // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "          recorder.exportWAV((blob) => {\n",
    "            audioBlob = blob;\n",
    "\n",
    "            if (!audioBlob) {\n",
    "              console.error(\"No audio to upload\");\n",
    "              return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "            const speaker = h_speakerSelect.value;\n",
    "            formData.append(\"speaker\", speaker);\n",
    "\n",
    "            fetch(\"/streaming\", {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                console.log(data);\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\");\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              });\n",
    "          });\n",
    "        });\n",
    "\n",
    "        // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "        setBtnonRestart();\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ã ã‚¹ãƒˆãƒªãƒ¼ãƒ å†ç”Ÿã¯ã§ãã¦ã„ãªã„ï¼\n",
    "ã‘ã©ï¼Œã‚½ã‚±ãƒƒãƒˆé€šä¿¡ã§Pushå‹ã§å‹•ãã‚ˆã†ã«ã—ãŸï¼\n",
    "ãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„ã«ã¯ã ã„ã¶ç¶ºéº—ã«ã¯ãªã£ãŸã¨ã¯æ€ã†ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼“ã€€æ”¹ã‚ã¦éŸ³å£°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å—ã‘å–ã‚‹å½¢ã«ã™ã‚‹\n",
    "GPTã®å‡ºåŠ›ã‚’æ–‡ã”ã¨ã«åˆ‡ã‚Šåˆ†ã‘ã¦ï¼Œ1æ–‡ãšã¤Voice Voxã«é€ã‚Šï¼Œåˆæˆã•ã‚ŒãŸéŸ³å£°ã‚’é †æ¬¡mpï¼“ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ã‚‹ï¼\n",
    "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã¯å—ã‘å–ã£ãŸéŸ³å£°ã‚’é †æ¬¡ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦ã„ãï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile voicechatapp13.py\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index13.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    synthesize_response = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) #, 'audio': filename})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "\n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    synthesize_response = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) #, 'audio': filename})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "\n",
    "    ## éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "    logging.debug(\"ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚Šã¾ã™ã€‚\")\n",
    "    text = preprocess_text(ai_response)\n",
    "    sentences = text.split(\"\\n\")\n",
    "\n",
    "    # å¥ã”ã¨ã«éŸ³å£°åˆæˆ\n",
    "    for sentence in sentences:\n",
    "        if sentence == \"\": continue\n",
    "        \n",
    "        ## éŸ³å£°åˆæˆ\n",
    "        synthesize_response=synthesize_voice(sentence, speaker)\n",
    "        if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "\n",
    "        ## åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "        audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "        mp3_data  = BytesIO()\n",
    "        audio.export(mp3_data , format=\"mp3\")\n",
    "        mp3_data .seek(0)\n",
    "\n",
    "        ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "        socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "def preprocess_text(text):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†\n",
    "    text = re.sub(r\"[ã€‚ï¼.]\", \"ã€‚\\n\", text)\n",
    "    text = re.sub(r\"[ï¼Ÿ?]\", \"ï¼Ÿ\\n\", text)\n",
    "    text = re.sub(r\"[ï¼!]\", \"ï¼\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "%%witefile /static/index13.html\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/upload\" checked>ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\" >ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "      navigator.mediaDevices\n",
    "        .getUserMedia({ audio: true })\n",
    "        .then((stream) => {\n",
    "          window.stream = stream;\n",
    "        })\n",
    "        .catch((error) => {\n",
    "          console.error(\"Error accessing the microphone: \" + error);\n",
    "        });\n",
    "\n",
    "      let audioContext;\n",
    "      let recorder;\n",
    "      let audioBlob;\n",
    "      let audioQueue = [];\n",
    "      let isPlaying = false;\n",
    "\n",
    "      // ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ å–å¾—\n",
    "      const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "      const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "      const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "      const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "\n",
    "      // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "      function setBtnonStart() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = false;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "      function setBtnunderProcessing() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "      function setBtnonRestart() {\n",
    "        h_startRecButton.disabled = false;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        h_speakerSelect.disabled = false;\n",
    "        h_speakerTestButton.disabled = false;\n",
    "      }\n",
    "\n",
    "\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const socket = io();\n",
    "\n",
    "        // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        fetch(\"/speaker_ids\")\n",
    "          .then((response) => response.json())\n",
    "          .then((data) => {\n",
    "            h_speakerSelect.innerHTML = data.join(\"\");\n",
    "          });\n",
    "\n",
    "        // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "        socket.on(\"SpeechRecognition\", (data) => {\n",
    "          const markdownText = data.text;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          document.getElementById(\n",
    "            \"h_chatlog\"\n",
    "          ).innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "        socket.on(\"ai_response\", (data) => {\n",
    "          const markdownText = data.ai_response;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          document.getElementById(\n",
    "            \"h_chatlog\"\n",
    "          ).innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "        socket.on(\"play_audio\", async(data) => {\n",
    "            const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "            const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "            // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "            audioQueue.push(audioUrl);\n",
    "\n",
    "            // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "            if (!isPlaying) {\n",
    "                playAudio();\n",
    "            }\n",
    "            // const audio = new Audio(audioUrl);\n",
    "            // audio.play();\n",
    "        });\n",
    "\n",
    "        // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "        async function playAudio() {\n",
    "            // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "            if (audioQueue.length === 0) {\n",
    "                isPlaying = false;\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            isPlaying = true;\n",
    "            const audioUrl = audioQueue.shift();\n",
    "            const audio = new Audio(audioUrl);\n",
    "            audio.play();\n",
    "\n",
    "            // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "            audio.onended = () => {\n",
    "                playAudio();\n",
    "            };\n",
    "        }\n",
    "\n",
    "        // //Stremingã§éŸ³å£°åˆæˆã®çµæœã‚’å—ä¿¡\n",
    "        // socket.on(\"Streaming\", async (data) => {\n",
    "\n",
    "        // });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keydown\", (event) => {\n",
    "          if (h_startRecButton.disabled) {\n",
    "            console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_startRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keyup\", (event) => {\n",
    "          if (h_stopRecButton.disabled) {\n",
    "            console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_stopRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "        h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "          const speaker = h_speakerSelect.value;\n",
    "          fetch(\"/speaker_test\", {\n",
    "            method: \"POST\",\n",
    "            headers: {\n",
    "              \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            body: JSON.stringify({ speaker }),\n",
    "          })\n",
    "            .then((response) => response.json())\n",
    "            .then((data) => {\n",
    "              console.log(data);\n",
    "            });\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_startRecButton.addEventListener(\"click\", () => {\n",
    "          audioContext = new AudioContext();\n",
    "          const source = audioContext.createMediaStreamSource(window.stream);\n",
    "          recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "          recorder.record();\n",
    "\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnonStart();\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_stopRecButton.addEventListener(\"click\", () => {\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnunderProcessing();\n",
    "\n",
    "          // éŒ²éŸ³ã‚’åœæ­¢\n",
    "          recorder.stop();\n",
    "\n",
    "          // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "          recorder.exportWAV((blob) => {\n",
    "            audioBlob = blob;\n",
    "            if (!audioBlob) {\n",
    "              console.error(\"No audio to upload\");\n",
    "              return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "            const speaker = h_speakerSelect.value;\n",
    "            formData.append(\"speaker\", speaker);\n",
    "\n",
    "            const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "            fetch(method, {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                console.log(data);\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\");\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              });\n",
    "          });\n",
    "        });\n",
    "\n",
    "        // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "        setBtnonRestart();\n",
    "      });\n",
    "\n",
    "      // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "      window.addEventListener(\"beforeunload\", () => {\n",
    "        if (window.stream) {\n",
    "          window.stream.getTracks().forEach((track) => {\n",
    "            track.stop();\n",
    "          });\n",
    "        }\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã ã„ã¶è‹¦åŠ´ã—ãŸã‘ã©ï¼Œå°‘ã—ãšã¤å½¢ã«ãªã£ã¦ããŸï¼\n",
    "ã“ã®ã‚ã¨ã¯GPTã‹ã‚‰ã®è¿”ç­”ã‚‚ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å—ã‘å–ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼”ã€€GPTã‹ã‚‰ã®è¿”ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å—ã‘å–ã‚‹ï¼\n",
    "ã“ã‚Œã®å ´åˆï¼ŒGPTã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡ºåŠ›ã‚’ä¸€æ—¦ã‚­ãƒ¼ãƒ—ã—ã¦æ–‡æœ«ã«æ¥ãŸã¨ã“ã‚ã§ä¸€æ°—ã«å‡¦ç†ã‚’ã‹ã‘ã‚‹ã¨ã„ã†å‡¦ç†ã«ãªã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing voicechatapp14.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicechatapp14.py\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index14.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    synthesize_response = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # # AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆ\n",
    "    # socketio.emit('ai_response', {'ai_response': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    # for ai_response in generate_ai_response(text):\n",
    "    #     ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    #     if ai_response:\n",
    "    #         socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    #     else:\n",
    "    #         return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    # socketio.emit('ai_response', {'ai_response': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    synthesize_response = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å¥å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹ã¨ã¨ã‚‚ã«ï¼å¥å˜ä½ã§éŸ³å£°åˆæˆã‚‚ã—ã¦ã„ã\n",
    "    \"\"\"\n",
    "    ç¾çŠ¶ã§ã¯ï¼Œå¤šåˆ†å¥ã®è¡¨ç¤ºã¨éŸ³å£°ãŒåŒæœŸã—ãªã„ï¼å¥ã¯é †ã«è¡¨ç¤ºã•ã‚Œã¦ã„ãã‘ã©ï¼ŒéŸ³å£°ã¯ã‚­ãƒ¥ãƒ¼ã«å…¥ã£ã¦é †ã«å†ç”Ÿã•ã‚Œã‚‹ã®ã§ï¼\n",
    "    ã“ã‚Œã‚’åŒæœŸã•ã›ã‚ˆã†ã¨æ€ã†ã¨ï¼ŒJavascriptã«å¥ã‚’é€ã£ãŸã‚‚ã®ã‚‚ä¸€æ—¦ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦ï¼ŒéŸ³å£°ã¨å¥ã‚’åŒæ™‚ã«å‡¦ç†ã™ã‚‹ã‚ˆã†ã«ã—ãªã„ã¨ã„ã‘ãª\n",
    "    ã„ï¼\n",
    "    ã§ããªãã¯ãªã„ã‹ãƒ»ãƒ»ãƒ»\n",
    "    \"\"\"\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    socketio.emit('ai_stream', {'ai_stream': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    for sentence in generate_ai_response(text):\n",
    "        ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "        if sentence:\n",
    "            # éŸ³å£°åˆæˆ\n",
    "            synthesize_response=synthesize_voice(sentence, speaker)\n",
    "            if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "            ## åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "            audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "            mp3_data  = BytesIO()\n",
    "            audio.export(mp3_data , format=\"mp3\")\n",
    "            mp3_data .seek(0)\n",
    "            ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "            socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "            socketio.emit('ai_stream', {'ai_stream': sentence})\n",
    "            ## 0.5ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹ï¼ã“ã‚Œã§å¥ã®åˆ‡ã‚Šåˆ†ã‘ãŒèãã‚„ã™ããªã‚‹ã¨æ€ã†ï¼\n",
    "            silent_audio = AudioSegment.silent(duration=500)\n",
    "            mp3_data  = BytesIO()\n",
    "            silent_audio.export(mp3_data , format=\"mp3\")\n",
    "            mp3_data .seek(0)\n",
    "            socketio.emit('play_audio', {'audio': mp3_data.getvalue()}) \n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    socketio.emit('ai_stream', {'ai_stream': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
    "def generate_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    sentens = \"\" # å¥ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    message = \"\" # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŸã‚ã«ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã•ã›ã‚‹ãŸã‚ã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    for chunk in completion:\n",
    "        # ãã¡ã‚“ã¨ã—ãŸãƒãƒ£ãƒ³ã‚¯ãŒå¸°ã£ã¦ãã¦ã„ã‚‹ã‹ã®ãƒã‚§ãƒƒã‚¯\n",
    "        if \"choices\" in chunk.to_dict() and len(chunk.choices) > 0: #to_dictï¼šè¾æ›¸å‹ã«å¤‰ãˆãªã„ã¨â€choicesâ€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ãªã®ã§\n",
    "            content  = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                message += content\n",
    "                # 1æ–‡å­—ãšã¤å–ã‚Šå‡ºã—ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹\n",
    "                for i in range(len(content)):\n",
    "                    char = content[i]\n",
    "                    sentens += char\n",
    "                    if char in \"ã€‚ï¼.ï¼Ÿ?ï¼!\\n\": #ä»Šè¦‹ã¦ã„ã‚‹ã®ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã ã£ãŸå ´åˆ\n",
    "                        if i < len(content)-1: # i ãŒæœ€å¾Œã®æ–‡å­—ã§ãªã„ãªã‚‰ï¼Œæ¬¡ã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                            if content[i+1] not in \"ã€‚ï¼.ï¼Ÿ?ï¼!\\n\": #æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã§ãªã„ãªã‚‰yield\n",
    "                                logging.debug(f\"å¥: {sentens}\")\n",
    "                                yield sentens\n",
    "                                sentens = \"\"\n",
    "                            else: #ã‚‚ã—æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ãªã‚‰ï¼Œç¾æ™‚ç‚¹ã®åŒºåˆ‡ã‚Šæ–‡å­—ã¯ã‚¹ãƒ«ãƒ¼\n",
    "                                continue\n",
    "                        else: #iãŒæœ€å¾Œã®æ–‡å­—ã®å ´åˆï¼Œç¾æ™‚ç‚¹ã§yield\n",
    "                            logging.debug(f\"å¥: {sentens}\")\n",
    "                            yield sentens\n",
    "                            sentens = \"\"\n",
    "    # æœ€å¾Œã®å¥ã‚’è¿”ã™\n",
    "    if sentens:\n",
    "        yield sentens\n",
    "    \n",
    "    # message ã‚’messagesã«è¿½åŠ \n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    logging.info(f\"AIã®å¿œç­”: {message}\")\n",
    "\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "def preprocess_text(text):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†\n",
    "    text = re.sub(r\"[ã€‚ï¼.]\", \"ã€‚\\n\", text)\n",
    "    text = re.sub(r\"[ï¼Ÿ?]\", \"ï¼Ÿ\\n\", text)\n",
    "    text = re.sub(r\"[ï¼!]\", \"ï¼\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile /static/index14.html\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/upload\" checked>ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\" >ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "      navigator.mediaDevices\n",
    "        .getUserMedia({ audio: true })\n",
    "        .then((stream) => {\n",
    "          window.stream = stream;\n",
    "        })\n",
    "        .catch((error) => {\n",
    "          console.error(\"Error accessing the microphone: \" + error);\n",
    "        });\n",
    "\n",
    "      let audioContext;\n",
    "      let recorder;\n",
    "      let audioBlob;\n",
    "      let audioQueue = [];\n",
    "      let isPlaying = false;\n",
    "\n",
    "      // htmlè¦ç´ å–å¾—\n",
    "      const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "      const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "      const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "      const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "      const h_chatlog = document.getElementById(\"h_chatlog\");\n",
    "\n",
    "      // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "      function setBtnonStart() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = false;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "      function setBtnunderProcessing() {\n",
    "        h_startRecButton.disabled = true;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        h_speakerSelect.disabled = true;\n",
    "        h_speakerTestButton.disabled = true;\n",
    "      }\n",
    "\n",
    "      // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "      function setBtnonRestart() {\n",
    "        h_startRecButton.disabled = false;\n",
    "        h_stopRecButton.disabled = true;\n",
    "        h_speakerSelect.disabled = false;\n",
    "        h_speakerTestButton.disabled = false;\n",
    "      }\n",
    "\n",
    "\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const socket = io();\n",
    "\n",
    "        // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        fetch(\"/speaker_ids\")\n",
    "          .then((response) => response.json())\n",
    "          .then((data) => {\n",
    "            h_speakerSelect.innerHTML = data.join(\"\");\n",
    "          });\n",
    "\n",
    "        // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "        socket.on(\"SpeechRecognition\", (data) => {\n",
    "          const markdownText = data.text;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          h_chatlog.innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "        socket.on(\"ai_response\", (data) => {\n",
    "          const markdownText = data.ai_response;\n",
    "          const htmlContent = marked.parse(markdownText);\n",
    "          h_chatlog.innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "        });\n",
    "\n",
    "        // AIã®å¿œç­”ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "        let currentDiv=\"\";\n",
    "        socket.on(\"ai_stream\", (data) => {\n",
    "          if (data.ai_stream.includes(\"---Start---\")) { \n",
    "            // æœ€åˆã¯divã‚’ä½œæˆ\n",
    "            h_chatlog.innerHTML += `<div class=\"assistant\"></div>`;\n",
    "            const assistantDivs = h_chatlog.getElementsByClassName(\"assistant\");\n",
    "            currentDiv = assistantDivs[assistantDivs.length - 1];//ä½œã£ãŸdivã‚’å–å¾—\n",
    "            return;\n",
    "          }\n",
    "          else if (data.ai_stream.includes(\"---End---\") ){ \n",
    "            // çµ‚äº†æ™‚ã¯æ”¹ã‚ã¦ä¸­èº«ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§æ›¸ãç›´ã™ï¼\n",
    "            currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "            currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "            return;\n",
    "          }\n",
    "          else{\n",
    "            // é€”ä¸­ã®å ´åˆã¯nakedãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ \n",
    "            currentDiv.innerHTML += data.ai_stream;\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "        socket.on(\"play_audio\", async(data) => {\n",
    "            const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "            const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "            // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "            audioQueue.push(audioUrl);\n",
    "\n",
    "            // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "            if (!isPlaying) {\n",
    "                playAudio();\n",
    "            }\n",
    "        });\n",
    "\n",
    "        // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "        async function playAudio() {\n",
    "            // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "            if (audioQueue.length === 0) {\n",
    "                isPlaying = false;\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            isPlaying = true;\n",
    "            const audioUrl = audioQueue.shift();\n",
    "            const audio = new Audio(audioUrl);\n",
    "            audio.play();\n",
    "\n",
    "            // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "            audio.onended = () => {\n",
    "                playAudio();\n",
    "            };\n",
    "        }\n",
    "\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keydown\", (event) => {\n",
    "          if (h_startRecButton.disabled) {\n",
    "            console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_startRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "        document.addEventListener(\"keyup\", (event) => {\n",
    "          if (h_stopRecButton.disabled) {\n",
    "            console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "            return;\n",
    "          }\n",
    "          if (event.code === \"Space\" && !event.repeat) {\n",
    "            h_stopRecButton.click();\n",
    "          }\n",
    "        });\n",
    "\n",
    "        //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "        h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "          const speaker = h_speakerSelect.value;\n",
    "          fetch(\"/speaker_test\", {\n",
    "            method: \"POST\",\n",
    "            headers: {\n",
    "              \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            body: JSON.stringify({ speaker }),\n",
    "          })\n",
    "            .then((response) => response.json())\n",
    "            .then((data) => {\n",
    "              console.log(data);\n",
    "            });\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_startRecButton.addEventListener(\"click\", () => {\n",
    "          audioContext = new AudioContext();\n",
    "          const source = audioContext.createMediaStreamSource(window.stream);\n",
    "          recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "          recorder.record();\n",
    "\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnonStart();\n",
    "        });\n",
    "\n",
    "        // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "        h_stopRecButton.addEventListener(\"click\", () => {\n",
    "          // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "          setBtnunderProcessing();\n",
    "\n",
    "          // éŒ²éŸ³ã‚’åœæ­¢\n",
    "          recorder.stop();\n",
    "\n",
    "          // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "          recorder.exportWAV((blob) => {\n",
    "            audioBlob = blob;\n",
    "            if (!audioBlob) {\n",
    "              console.error(\"No audio to upload\");\n",
    "              return;\n",
    "            }\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "            const speaker = h_speakerSelect.value;\n",
    "            formData.append(\"speaker\", speaker);\n",
    "\n",
    "            const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "            fetch(method, {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                console.log(data);\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\");\n",
    "                // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                setBtnonRestart();\n",
    "              });\n",
    "          });\n",
    "        });\n",
    "\n",
    "        // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "        setBtnonRestart();\n",
    "      });\n",
    "\n",
    "      // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "      window.addEventListener(\"beforeunload\", () => {\n",
    "        if (window.stream) {\n",
    "          window.stream.getTracks().forEach((track) => {\n",
    "            track.stop();\n",
    "          });\n",
    "        }\n",
    "      });\n",
    "\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãªã‚“ã¨ã‹ã§ããŸï¼\n",
    "\n",
    "Chunkã®æ–‡ç« ã¸ã®å†æ§‹ç¯‰ã¨ï¼Œä¸€æ–¹ã§æ–‡æœ«ã‹ã©ã†ã‹ã®åŒºåˆ‡ã‚ŠãŒã‚ã¡ã‚ƒãã¡ã‚ƒé¢å€’ã‚„ã£ãŸï¼ˆè‹¦ç¬‘ï¼‰\n",
    "\n",
    "ç¾çŠ¶ã§ã¯ï¼ŒéŸ³å£°ç”Ÿæˆã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒãã“ã¾ã§ã§ã¯ãªã„ã®ã§ï¼Œãã“ã¾ã§ã‚­ãƒ¥ãƒ‹ãƒ¼è“„ç©ã•ã›ã‚‹ã¨ã„ã†ã“ã¨ã‚‚ãªã„ãŒï¼Œã‚‚ã—ã‚‚ã£ã¨åˆæˆã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒä¸ŠãŒã‚Œã°ï¼Œå…ˆã«æ–‡ç« ãŒãƒãƒ¼ã£ã¨è¡¨ç¤ºã•ã‚Œã¦ã„ãï¼Œã¨ã„ã†ã“ã¨ãŒèµ·ã“ã‚Šå¾—ã‚‹ã¨æ€ã†ï¼\n",
    "ã¾ã‚ï¼Œãã‚Œã‚‚æ‚ªãã¯ãªã„ãŒãƒ»ãƒ»ãƒ»\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼•ã€€éŸ³å£°ã¨ã‚»ãƒ³ãƒ†ãƒ³ã‚¹è¡¨ç¤ºã®åŒæœŸã‚’ã¨ã‚‹ï¼\n",
    "ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ã‚‹ã‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing voicechatapp15.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicechatapp15.py\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index15.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    synthesize_response = synthesize_voice(text, speaker)\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆ\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    synthesize_response = synthesize_voice(ai_response, speaker)\n",
    "\n",
    "\n",
    "    # åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "    if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "    mp3_data  = BytesIO()\n",
    "    audio.export(mp3_data , format=\"mp3\")\n",
    "    mp3_data .seek(0)  \n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å¥å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹ã¨ã¨ã‚‚ã«ï¼å¥å˜ä½ã§éŸ³å£°åˆæˆã‚‚ã—ã¦ã„ã\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    socketio.emit('ai_stream', {'sentens': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    for sentence in generate_ai_response(text):\n",
    "        ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "        if sentence:\n",
    "            # éŸ³å£°åˆæˆ\n",
    "            synthesize_response=synthesize_voice(sentence, speaker)\n",
    "            if synthesize_response is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "            ## åˆæˆã—ãŸéŸ³å£°ã‚’mp3åŒ–\n",
    "            audio = AudioSegment.from_file(BytesIO(synthesize_response.content), format=\"wav\")\n",
    "            mp3_data  = BytesIO()\n",
    "            audio.export(mp3_data , format=\"mp3\")\n",
    "            mp3_data .seek(0)\n",
    "            ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': sentence})\n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã ã£ãŸã‚‰ï¼Œ0.2ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            if sentence[-1] in \",ï¼Œã€\":\n",
    "                silent_audio = AudioSegment.silent(duration=10)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã§ãªã‹ã£ãŸã‚‰ï¼Œ0.5ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            else:\n",
    "                silent_audio = AudioSegment.silent(duration=500)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # ç„¡éŸ³ã‚’é€ä¿¡\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': \"---silent---\"})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    socketio.emit('ai_stream', {'sentens': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
    "def generate_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    sentens = \"\" # å¥ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡ã€€\n",
    "    message = \"\" # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŸã‚ã«ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã•ã›ã‚‹ãŸã‚ã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    for chunk in completion:\n",
    "        # ãã¡ã‚“ã¨ã—ãŸãƒãƒ£ãƒ³ã‚¯ãŒå¸°ã£ã¦ãã¦ã„ã‚‹ã‹ã®ãƒã‚§ãƒƒã‚¯\n",
    "        if \"choices\" in chunk.to_dict() and len(chunk.choices) > 0: #to_dictï¼šè¾æ›¸å‹ã«å¤‰ãˆãªã„ã¨â€choicesâ€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ãªã®ã§\n",
    "            content  = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                message += content\n",
    "                # 1æ–‡å­—ãšã¤å–ã‚Šå‡ºã—ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹\n",
    "                for i in range(len(content)):\n",
    "                    char = content[i]\n",
    "                    sentens += char\n",
    "                    if char in \",ï¼Œã€ã€‚ï¼.ï¼Ÿ?ï¼!\\n\": #ä»Šè¦‹ã¦ã„ã‚‹ã®ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã ã£ãŸå ´åˆï¼ˆèª­ç‚¹ã‚‚åŒºåˆ‡ã‚Šã«å«ã‚ã‚‹ï¼‰\n",
    "                        if i < len(content)-1: # i ãŒæœ€å¾Œã®æ–‡å­—ã§ãªã„ãªã‚‰ï¼Œæ¬¡ã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                            if content[i+1] not in \",ï¼Œã€ã€‚ï¼.ï¼Ÿ?ï¼!\\n\": #æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã§ãªã„ãªã‚‰yield\n",
    "                                logging.debug(f\"å¥: {sentens}\")\n",
    "                                yield sentens\n",
    "                                sentens = \"\"\n",
    "                            else: #ã‚‚ã—æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ãªã‚‰ï¼Œç¾æ™‚ç‚¹ã®åŒºåˆ‡ã‚Šæ–‡å­—ã¯ã‚¹ãƒ«ãƒ¼\n",
    "                                continue\n",
    "                        else: #iãŒæœ€å¾Œã®æ–‡å­—ã®å ´åˆï¼Œç¾æ™‚ç‚¹ã§yield\n",
    "                            logging.debug(f\"å¥: {sentens}\")\n",
    "                            yield sentens\n",
    "                            sentens = \"\"\n",
    "    # æœ€å¾Œã®å¥ã‚’è¿”ã™\n",
    "    if sentens:\n",
    "        yield sentens\n",
    "    \n",
    "    # message ã‚’messagesã«è¿½åŠ \n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    logging.info(f\"AIã®å¿œç­”: {message}\")\n",
    "\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å¥å˜ä½ã«åŒºåˆ‡ã‚‹\n",
    "def preprocess_text(text):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†\n",
    "    text = re.sub(r\"[ã€‚ï¼.]\", \"ã€‚\\n\", text)\n",
    "    text = re.sub(r\"[ï¼Ÿ?]\", \"ï¼Ÿ\\n\", text)\n",
    "    text = re.sub(r\"[ï¼!]\", \"ï¼\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing static/index15.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index15.html\n",
    "<html lang=\"ja\">\n",
    "\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/upload\" checked>ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\">ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "        navigator.mediaDevices\n",
    "            .getUserMedia({ audio: true })\n",
    "            .then((stream) => {\n",
    "                window.stream = stream;\n",
    "            })\n",
    "            .catch((error) => {\n",
    "                console.error(\"Error accessing the microphone: \" + error);\n",
    "            });\n",
    "\n",
    "        // éŸ³å£°å‡¦ç†ç”¨ã®å¤‰æ•°\n",
    "        let audioContext; // éŸ³å£°å‡¦ç†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "        let recorder;   // éŒ²éŸ³ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        let audioBlob;  // éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿\n",
    "        let audioQueue = [];    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let sentensQueue = [];  // ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let isPlaying = false;  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿä¸­ã‹ã©ã†ã‹\n",
    "        let currentDiv = \"\";    // ç¾åœ¨ã®divè¦ç´ \n",
    "\n",
    "\n",
    "        // htmlè¦ç´ å–å¾—\n",
    "        const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "        const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "        const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "        const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "        const h_chatlog = document.getElementById(\"h_chatlog\");\n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "        function setBtnonStart() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = false;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "        function setBtnunderProcessing() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "        function setBtnonRestart() {\n",
    "            h_startRecButton.disabled = false;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = false;\n",
    "            h_speakerTestButton.disabled = false;\n",
    "        }\n",
    "\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            const socket = io();\n",
    "\n",
    "            // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "            fetch(\"/speaker_ids\")\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    h_speakerSelect.innerHTML = data.join(\"\");\n",
    "                });\n",
    "\n",
    "            // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "            socket.on(\"SpeechRecognition\", (data) => {\n",
    "                const markdownText = data.text;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_response\", (data) => {\n",
    "                const markdownText = data.ai_response;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            socket.on(\"play_audio\", async (data) => {\n",
    "                const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "                // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                audioQueue.push(audioUrl);\n",
    "\n",
    "                // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "                if (!isPlaying) {\n",
    "                    playAudio();\n",
    "                }\n",
    "                // const audio = new Audio(audioUrl);\n",
    "                // audio.play();\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudio() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                isPlaying = true;\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudio();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // AIã®å¿œç­”ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_stream\", (data) => {\n",
    "                if(data.sentens){\n",
    "                    if (data.sentens.includes(\"---Start---\")) { \n",
    "                        // æœ€åˆã¯divã‚’ä½œæˆ\n",
    "                        h_chatlog.innerHTML += `<div class=\"assistant\"></div>`;\n",
    "                        const assistantDivs = h_chatlog.getElementsByClassName(\"assistant\");\n",
    "                        currentDiv = assistantDivs[assistantDivs.length - 1];//ä½œã£ãŸdivã‚’å–å¾—\n",
    "                        return;\n",
    "                    }\n",
    "                    else if (data.sentens.includes(\"---End---\") ){ \n",
    "                        // çµ‚äº†æ™‚ã¯markedã‚’é©ç”¨\n",
    "                        currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                        currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                        return;\n",
    "                    }\n",
    "                    else{\n",
    "                        // sentensã‚’ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                        sentensQueue.push(data.sentens);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if(data.audio){\n",
    "                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ¥ãƒ¼ã«ã¨ç™»éŒ²\n",
    "                    const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                    const audioUrl = URL.createObjectURL(audioBlob);\n",
    "                    audioQueue.push(audioUrl); // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "\n",
    "\n",
    "                    if (!isPlaying) {\n",
    "                        playAudioWithSentens();\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudioWithSentens() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    return;\n",
    "                }\n",
    "                // å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹\n",
    "                isPlaying = true;\n",
    "\n",
    "                //SentensQueueã‹ã‚‰ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚’å–ã‚Šå‡ºã—ã¦è¡¨ç¤º\n",
    "                //ãŸã ã—ã€---silent---ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤ºã—ãªã„\n",
    "                const sentens = sentensQueue.shift();\n",
    "                if (!sentens.includes(\"---silent---\")){\n",
    "                    currentDiv.innerHTML += sentens;\n",
    "                }\n",
    "\n",
    "                //AudioQueueã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã—ã¦å†ç”Ÿ\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudioWithSentens();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keydown\", (event) => {\n",
    "                if (h_startRecButton.disabled) {\n",
    "                    console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_startRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keyup\", (event) => {\n",
    "                if (h_stopRecButton.disabled) {\n",
    "                    console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_stopRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "            h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "                const speaker = h_speakerSelect.value;\n",
    "                fetch(\"/speaker_test\", {\n",
    "                    method: \"POST\",\n",
    "                    headers: {\n",
    "                        \"Content-Type\": \"application/json\",\n",
    "                    },\n",
    "                    body: JSON.stringify({ speaker }),\n",
    "                })\n",
    "                    .then((response) => response.json())\n",
    "                    .then((data) => {\n",
    "                        console.log(data);\n",
    "                    });\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_startRecButton.addEventListener(\"click\", () => {\n",
    "                audioContext = new AudioContext();\n",
    "                const source = audioContext.createMediaStreamSource(window.stream);\n",
    "                recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "                recorder.record();\n",
    "\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnonStart();\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_stopRecButton.addEventListener(\"click\", () => {\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnunderProcessing();\n",
    "\n",
    "                // éŒ²éŸ³ã‚’åœæ­¢\n",
    "                recorder.stop();\n",
    "\n",
    "                // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "                recorder.exportWAV((blob) => {\n",
    "                    audioBlob = blob;\n",
    "                    if (!audioBlob) {\n",
    "                        console.error(\"No audio to upload\");\n",
    "                        return;\n",
    "                    }\n",
    "\n",
    "                    const formData = new FormData();\n",
    "                    formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                    const speaker = h_speakerSelect.value;\n",
    "                    formData.append(\"speaker\", speaker);\n",
    "\n",
    "                    const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "                    fetch(method, {\n",
    "                        method: \"POST\",\n",
    "                        body: formData,\n",
    "                    })\n",
    "                        .then((response) => response.json())\n",
    "                        .then((data) => {\n",
    "                            console.log(data);\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        })\n",
    "                        .catch((error) => {\n",
    "                            console.error(\"Upload failed:\");\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        });\n",
    "                });\n",
    "            });\n",
    "\n",
    "            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "            setBtnonRestart();\n",
    "        });\n",
    "\n",
    "        // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "        window.addEventListener(\"beforeunload\", () => {\n",
    "            if (window.stream) {\n",
    "                window.stream.getTracks().forEach((track) => {\n",
    "                    track.stop();\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ˜¨æ—¥ï¼Œæœ€å¾Œã®ä¸€æ–‡ãŒéŸ³å£°ãŒæµã‚ŒãŸã‘ã©ï¼Œã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãŒè¡¨ç¤ºã•ã‚Œãªã‹ã£ãŸåŸå› ãŒå¤šåˆ†åˆ†ã‹ã£ãŸï¼\n",
    "åŸå› ã¯ï¼Œç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã ã¨ï¼ŒãŸã¨ãˆã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã«ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ãŒæ®‹ã£ã¦ã„ãŸã¨ã—ã¦ã‚‚ï¼Œã‚½ã‚±ãƒƒãƒˆé€šä¿¡ã§EndãŒé€ã‚‰ã‚Œã‚‹ã¨HTMLã‚’é–‰ã˜ã¦ã—ã¾ã†ã‚³ãƒ¼ãƒ‰ã«ãªã£ã¦ã„ã‚‹ã‹ã‚‰ï¼\n",
    "å¯¾ç­–ã¨ã—ã¦ï¼Œ\n",
    "Startã¨Endä»¥å¤–ã¯ã‹ãªã‚‰ãšAudioã¨SentensãŒã‚»ãƒƒãƒˆã§é€ã‚‰ã‚Œã‚‹ã‹ã‚‰ï¼ŒEndãŒç™ºä¿¡ã•ã‚ŒãŸã¨ã„ã†ã“ã¨ã¯ï¼Œå¿…è¦ãªAudioã‚‚Sentensã‚‚å…¨ã¦Queã«å…¥ã£ã¦ã„ã‚‹ï¼ãªã®ã§ï¼ŒEndã‚‚ã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã«å…¥ã‚Œã¦ãŠã„ã¦ï¼Œã‚ªãƒ¼ãƒ‡ã‚£ã‚ªQueã®é•·ã•ãŒ0ã«ãªã£ã¦æ™‚ç‚¹ã§ï¼Œã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã‚’åãå‡ºã•ã›ã‚Œã°ã‚ˆã„ï¼ˆé€šå¸¸ã¯ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªQueã¨SentensQueã¯ã‚»ãƒƒãƒˆã§å‹•ãã®ã§EndãŒQueã«å…¥ã£ãŸæ™‚ã ã‘ã“ã‚ŒãŒç™ºå‹•ã™ã‚‹ã¯ãšï¼ï¼\n",
    "\n",
    "ã¨ã„ã†ã“ã¨ã§ï¼Œæ”¹ã‚ã¦ä»¥ä¸‹ã®é€šã‚Šï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile static/index15.html\n",
    "\n",
    "<html lang=\"ja\">\n",
    "\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/upload\" checked>ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "    <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\">ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "    <select id=\"h_speakerSelect\"></select>\n",
    "    <button id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"h_chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "        navigator.mediaDevices\n",
    "            .getUserMedia({ audio: true })\n",
    "            .then((stream) => {\n",
    "                window.stream = stream;\n",
    "            })\n",
    "            .catch((error) => {\n",
    "                console.error(\"Error accessing the microphone: \" + error);\n",
    "            });\n",
    "\n",
    "        // éŸ³å£°å‡¦ç†ç”¨ã®å¤‰æ•°\n",
    "        let audioContext; // éŸ³å£°å‡¦ç†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "        let recorder;   // éŒ²éŸ³ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        let audioBlob;  // éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿\n",
    "        let audioQueue = [];    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let sentensQueue = [];  // ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let isPlaying = false;  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿä¸­ã‹ã©ã†ã‹\n",
    "        let currentDiv = \"\";    // ç¾åœ¨ã®divè¦ç´ \n",
    "\n",
    "\n",
    "        // htmlè¦ç´ å–å¾—\n",
    "        const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "        const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "        const h_speakerSelect = document.getElementById(\"h_speakerSelect\");\n",
    "        const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "        const h_chatlog = document.getElementById(\"h_chatlog\");\n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "        function setBtnonStart() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = false;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "        function setBtnunderProcessing() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "        function setBtnonRestart() {\n",
    "            h_startRecButton.disabled = false;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = false;\n",
    "            h_speakerTestButton.disabled = false;\n",
    "        }\n",
    "\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            const socket = io();\n",
    "\n",
    "            // SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "            fetch(\"/speaker_ids\")\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    h_speakerSelect.innerHTML = data.join(\"\");\n",
    "                });\n",
    "\n",
    "            // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "            socket.on(\"SpeechRecognition\", (data) => {\n",
    "                const markdownText = data.text;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_response\", (data) => {\n",
    "                const markdownText = data.ai_response;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            socket.on(\"play_audio\", async (data) => {\n",
    "                const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "                // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                audioQueue.push(audioUrl);\n",
    "\n",
    "                // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "                if (!isPlaying) {\n",
    "                    playAudio();\n",
    "                }\n",
    "                // const audio = new Audio(audioUrl);\n",
    "                // audio.play();\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudio() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                isPlaying = true;\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudio();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // AIã®å¿œç­”ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_stream\", (data) => {\n",
    "                if(data.sentens){\n",
    "                    if (data.sentens.includes(\"---Start---\")) { \n",
    "                        // æœ€åˆã¯divã‚’ä½œæˆ\n",
    "                        h_chatlog.innerHTML += `<div class=\"assistant\"></div>`;\n",
    "                        const assistantDivs = h_chatlog.getElementsByClassName(\"assistant\");\n",
    "                        currentDiv = assistantDivs[assistantDivs.length - 1];//ä½œã£ãŸdivã‚’å–å¾—\n",
    "                        return;\n",
    "                    }\n",
    "                    // else if (data.sentens.includes(\"---End---\") ){ \n",
    "                    //     // çµ‚äº†æ™‚ã¯markedã‚’é©ç”¨\n",
    "                    //     currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                    //     currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                    //     return;\n",
    "                    // }\n",
    "                    else{\n",
    "                        // sentensã‚’ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                        sentensQueue.push(data.sentens);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if(data.audio){\n",
    "                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ¥ãƒ¼ã«ã¨ç™»éŒ²\n",
    "                    const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                    const audioUrl = URL.createObjectURL(audioBlob);\n",
    "                    audioQueue.push(audioUrl); // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "\n",
    "                    if (!isPlaying) {\n",
    "                        playAudioWithSentens();\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudioWithSentens() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    //ã‚‚ã—ã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å…¨éƒ¨åãå‡ºã™\n",
    "                    while (sentensQueue.length)  {\n",
    "                        const sentens = sentensQueue.shift();\n",
    "                        if (sentens.includes(\"---End---\")){\n",
    "                            currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                            currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                        }else{\n",
    "                            currentDiv.innerHTML += sentens;\n",
    "                        }\n",
    "                    }\n",
    "                    return;\n",
    "                }\n",
    "                // å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹\n",
    "                isPlaying = true;\n",
    "\n",
    "                //SentensQueueã‹ã‚‰ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚’å–ã‚Šå‡ºã—ã¦è¡¨ç¤º\n",
    "                //ãŸã ã—ã€---silent---ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤ºã—ãªã„\n",
    "                const sentens = sentensQueue.shift();\n",
    "                if (!sentens.includes(\"---silent---\")){\n",
    "                    currentDiv.innerHTML += sentens;\n",
    "                }\n",
    "\n",
    "                //AudioQueueã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã—ã¦å†ç”Ÿ\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudioWithSentens();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keydown\", (event) => {\n",
    "                if (h_startRecButton.disabled) {\n",
    "                    console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_startRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keyup\", (event) => {\n",
    "                if (h_stopRecButton.disabled) {\n",
    "                    console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_stopRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "            h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "                const speaker = h_speakerSelect.value;\n",
    "                fetch(\"/speaker_test\", {\n",
    "                    method: \"POST\",\n",
    "                    headers: {\n",
    "                        \"Content-Type\": \"application/json\",\n",
    "                    },\n",
    "                    body: JSON.stringify({ speaker }),\n",
    "                })\n",
    "                    .then((response) => response.json())\n",
    "                    .then((data) => {\n",
    "                        console.log(data);\n",
    "                    });\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_startRecButton.addEventListener(\"click\", () => {\n",
    "                audioContext = new AudioContext();\n",
    "                const source = audioContext.createMediaStreamSource(window.stream);\n",
    "                recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "                recorder.record();\n",
    "\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnonStart();\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_stopRecButton.addEventListener(\"click\", () => {\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnunderProcessing();\n",
    "\n",
    "                // éŒ²éŸ³ã‚’åœæ­¢\n",
    "                recorder.stop();\n",
    "\n",
    "                // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "                recorder.exportWAV((blob) => {\n",
    "                    audioBlob = blob;\n",
    "                    if (!audioBlob) {\n",
    "                        console.error(\"No audio to upload\");\n",
    "                        return;\n",
    "                    }\n",
    "\n",
    "                    const formData = new FormData();\n",
    "                    formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                    const speaker = h_speakerSelect.value;\n",
    "                    formData.append(\"speaker\", speaker);\n",
    "\n",
    "                    const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "                    fetch(method, {\n",
    "                        method: \"POST\",\n",
    "                        body: formData,\n",
    "                    })\n",
    "                        .then((response) => response.json())\n",
    "                        .then((data) => {\n",
    "                            console.log(data);\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        })\n",
    "                        .catch((error) => {\n",
    "                            console.error(\"Upload failed:\");\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        });\n",
    "                });\n",
    "            });\n",
    "\n",
    "            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "            setBtnonRestart();\n",
    "        });\n",
    "\n",
    "        // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "        window.addEventListener(\"beforeunload\", () => {\n",
    "            if (window.stream) {\n",
    "                window.stream.getTracks().forEach((track) => {\n",
    "                    track.stop();\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®16ã€€ä»–ã®TTSã«å¯¾å¿œã™ã‚‹ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¨ã‚Šã‚ãˆãšGoogle Cloud TTSã‚’ä½¿ã£ã¦ã¿ã‚‹ã‹.\n",
    "ã¤ã„ã§ã«voicevoxã«ã¤ã„ã¦mp3å‡ºåŠ›ã‚’ç«¯ã‹ã‚‰å‡ºæ¥ã‚‹ã‚ˆã†ã«ã—ã¦ãŠãï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã¨ã‚Šã‚ãˆãšGoogle Clout TTSã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/vb/63y84xfs4g3cw7_09_s2_yd40000gn/T/tmp_vhok6s3.wav':\n",
      "  Duration: 00:00:09.02, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   8.92 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# API_KEYã®å–å¾—\n",
    "API_KEY = os.environ.get(\"GOOGLE_TTS_API_KEY\")\n",
    "\n",
    "# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "url = f\"https://texttospeech.googleapis.com/v1/text:synthesize?key={API_KEY}\"\n",
    "\n",
    "# éŸ³å£°åˆæˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "data = {\n",
    "    \"input\": {\"text\": \"Hello Nice to meet you. How can I help you? I am a helpful assistant. Please tell me your request. I will do my best to help you.\"},\n",
    "    \"voice\": {\n",
    "        \"languageCode\": \"en-US\",\n",
    "        \"name\": \"en-US-Journey-F\",  \n",
    "        #\"ssmlGender\": \"FEMALE\"\n",
    "    },\n",
    "    \"audioConfig\": {\n",
    "        \"audioEncoding\": \"MP3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡\n",
    "response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(data))\n",
    "\n",
    "# çµæœã‚’å–å¾—\n",
    "if response.status_code == 200:\n",
    "    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "    audio_content = json.loads(response.text)[\"audioContent\"]\n",
    "    audio_data = base64.b64decode(audio_content)\n",
    "    \n",
    "    # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ pydub ã® AudioSegment ã«å¤‰æ›\n",
    "    audio = AudioSegment.from_file(io.BytesIO(audio_data), format=\"mp3\")\n",
    "\n",
    "    # Python ä¸Šã§ç›´æ¥å†ç”Ÿ\n",
    "    play(audio)\n",
    "\n",
    "else:\n",
    "    print(\"ã‚¨ãƒ©ãƒ¼:\", response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼PYTHONãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã‚ˆã‚Šï¼ŒAPI KEYã‚’ã¤ã‹ã†ã®ãŒç°¡å˜ã ã‚ˆã­ï¼ˆè‹¦ç¬‘ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¨ã„ã†ã“ã¨ã§Google TTSã‚’çµ„ã¿è¾¼ã‚“ã ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼\n",
    "VoiceVoxã‚ˆã‚Šãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã‚„ã„ã‹ã‚‰ã‚¹ãƒ ãƒ¼ã‚ºã«ãã“ãˆã‚‹ã­ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing voicechatapp16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicechatapp16.py\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "# åŒºåˆ‡ã‚Šæ–‡å­—ã®è¨­å®šï¼AIå‡ºåŠ›ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å—ã‘å–ã‚‹ã¨ãã«å¥åˆ‡ã‚Šã‚’ã©ã®æ–‡å­—ã§è¡Œãªã†ã‹ã®æŒ‡å®š\n",
    "# ã“ã®æ–‡å­—ãŒæ¥ãŸã‚‰ï¼Œãã®å‰ã¾ã§ã‚’ä¸€ã¤ã®å¥ã¨ã—ã¦æ‰±ã†\n",
    "SegmentingChars=\",ï¼Œã€ã€‚ï¼.ï¼Ÿ?ï¼!\\n\"\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index15.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# VoiceVoxã®éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    mp3_data = synthesize_voice_mp3(text, speaker)\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆã—ã¦mp3ã§è¿”ã™\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    mp3_data = synthesize_voice_mp3(ai_response, speaker)\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å¥å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹ã¨ã¨ã‚‚ã«ï¼å¥å˜ä½ã§éŸ³å£°åˆæˆã‚‚ã—ã¦ã„ã\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    socketio.emit('ai_stream', {'sentens': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    for sentence in generate_ai_response(text):\n",
    "        ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "        if sentence:\n",
    "            #ã€€éŸ³å£°åˆæˆï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "            #mp3_data = synthesize_voice_mp3(sentence, speaker) # VoiceVox APIã‚’ä½¿ã†å ´åˆ\n",
    "            mp3_data = synthesize_voice_google(sentence) # Google Cloud TTS APIã‚’ä½¿ã†å ´åˆ\n",
    "            if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "            ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': sentence})\n",
    "            \n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã ã£ãŸã‚‰ï¼Œ0.2ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            if sentence[-1] in \",ï¼Œã€\":\n",
    "                silent_audio = AudioSegment.silent(duration=10)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã§ãªã‹ã£ãŸã‚‰ï¼Œ0.5ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            else:\n",
    "                silent_audio = AudioSegment.silent(duration=500)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # ç„¡éŸ³ã‚’é€ä¿¡\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': \"---silent---\"})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    socketio.emit('ai_stream', {'sentens': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
    "def generate_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    sentens = \"\" # å¥ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡ã€€\n",
    "    message = \"\" # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŸã‚ã«ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã•ã›ã‚‹ãŸã‚ã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    for chunk in completion:\n",
    "        # ãã¡ã‚“ã¨ã—ãŸãƒãƒ£ãƒ³ã‚¯ãŒå¸°ã£ã¦ãã¦ã„ã‚‹ã‹ã®ãƒã‚§ãƒƒã‚¯\n",
    "        if \"choices\" in chunk.to_dict() and len(chunk.choices) > 0: #to_dictï¼šè¾æ›¸å‹ã«å¤‰ãˆãªã„ã¨â€choicesâ€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ãªã®ã§\n",
    "            content  = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                message += content\n",
    "                # 1æ–‡å­—ãšã¤å–ã‚Šå‡ºã—ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹\n",
    "                for i in range(len(content)):\n",
    "                    char = content[i]\n",
    "                    sentens += char\n",
    "                    if char in SegmentingChars: #ä»Šè¦‹ã¦ã„ã‚‹ã®ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã ã£ãŸå ´åˆï¼ˆèª­ç‚¹ã‚‚åŒºåˆ‡ã‚Šã«å«ã‚ã‚‹ï¼‰\n",
    "                        if i < len(content)-1: # i ãŒæœ€å¾Œã®æ–‡å­—ã§ãªã„ãªã‚‰ï¼Œæ¬¡ã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                            if content[i+1] not in SegmentingChars: #æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã§ãªã„ãªã‚‰yield\n",
    "                                logging.debug(f\"å¥: {sentens}\")\n",
    "                                yield sentens\n",
    "                                sentens = \"\"\n",
    "                            else: #ã‚‚ã—æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ãªã‚‰ï¼Œç¾æ™‚ç‚¹ã®åŒºåˆ‡ã‚Šæ–‡å­—ã¯ã‚¹ãƒ«ãƒ¼\n",
    "                                continue\n",
    "                        else: #iãŒæœ€å¾Œã®æ–‡å­—ã®å ´åˆï¼Œç¾æ™‚ç‚¹ã§yield\n",
    "                            logging.debug(f\"å¥: {sentens}\")\n",
    "                            yield sentens\n",
    "                            sentens = \"\"\n",
    "    # æœ€å¾Œã®å¥ã‚’è¿”ã™\n",
    "    if sentens:\n",
    "        yield sentens\n",
    "    \n",
    "    # message ã‚’messagesã«è¿½åŠ \n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    logging.info(f\"AIã®å¿œç­”: {message}\")\n",
    "\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œãªã†é–¢æ•°\n",
    "def synthesize_voice(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# voicevox apiã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°ï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "def synthesize_voice_mp3(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        audio = AudioSegment.from_file(BytesIO(synthesis_response.content), format=\"wav\")\n",
    "        mp3_data  = BytesIO()\n",
    "        audio.export(mp3_data , format=\"mp3\")\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "# Google Clout TTS APIã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°\n",
    "def synthesize_voice_google(text):\n",
    "    # APIã‚­ãƒ¼ã®å–å¾—\n",
    "    API_KEY = os.getenv(\"GOOGLE_TTS_API_KEY\")\n",
    "\n",
    "    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    url = f\"https://texttospeech.googleapis.com/v1/text:synthesize?key={API_KEY}\"\n",
    "\n",
    "    # éŸ³å£°åˆæˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    data = {\n",
    "        \"input\": {\"text\": text},\n",
    "        \"voice\": {\n",
    "            \"languageCode\": \"ja-JP\",\n",
    "            \"name\": \"ja-JP-Wavenet-D\",  # ç”·æ€§ã®è‡ªç„¶ãªå£°\n",
    "            \"ssmlGender\": \"MALE\"\n",
    "        },\n",
    "        \"audioConfig\": {\n",
    "            \"audioEncoding\": \"MP3\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡\n",
    "    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(data))\n",
    "\n",
    "    # çµæœã‚’å–å¾—\n",
    "    if response.status_code == 200:\n",
    "        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "        audio_content = json.loads(response.text)[\"audioContent\"]\n",
    "        audio_data = base64.b64decode(audio_content)\n",
    "        \n",
    "        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ pydub ã® AudioSegment ã«å¤‰æ›\n",
    "        mp3_data  =BytesIO(audio_data)\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {response.text}\")\n",
    "        return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTMLã‚‚å¼„ã£ã¦ãŠã„ã¦ï¼ŒGoogleã®å ´åˆã¨VoiceVoxã®å ´åˆã®é¸æŠãŒå‡ºæ¥ã‚‹ã‚ˆã†ã«ã—ã¦ãŠãã‹ï¼\n",
    "\n",
    "### HTMLã§è‰²ã€…ã¨è§¦ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
    "\n",
    "https://cloud.google.com/text-to-speech/docs/voices?hl=ja\n",
    "\n",
    "https://cloud.google.com/text-to-speech/docs/voice-types?hl=ja\n",
    "\n",
    "å£°ã®ç¨®é¡ãŒæ€ã„ã®ã»ã‹å¤šã„ğŸ˜‚\n",
    "æ—¥æœ¬èªã¯ã¨ã‚‚ã‹ãï¼Œè‹±èªã¯ã‚ã¡ã‚ƒãã¡ã‚ƒå¤šã„ğŸ˜‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing static/index16.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index16.html\n",
    "\n",
    "<html lang=\"ja\">\n",
    "\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button type=\"button\" id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button type=\"button\" id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <form id = \"myForm\">\n",
    "        <div id =\"divProcessType\">\n",
    "            <input type=\"radio\" id=\"onetime\" name=\"Method\" value=\"/upload\" checked>ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "            <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\">ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "        </div>\n",
    "        <div id =\"divTTSselect\">\n",
    "            <input type=\"radio\" id=\"radioVoicevoxTTS\" name=\"TTS\" value=\"VoiceVox\" checked>VoiceVox</radio>\n",
    "            <input type=\"radio\" id=\"radioGoogleTTS\" name=\"TTS\" value=\"Google\">Google TTS</radio>\n",
    "        </div>\n",
    "        <div id =\"divVoiceVoxSpeaker\">\n",
    "            <select id=\"speakerSelect\" name=\"speaker\"></select>\n",
    "        </div>\n",
    "        <div id =\"divGoogleSpeaker\" hidden>\n",
    "            <p>è¨€èª\n",
    "                <input type=\"radio\"  id = \"langCode_jp\" name=\"languageCode\" value=\"ja-JP\" checked>æ—¥æœ¬èª</radio>\n",
    "                <input type=\"radio\"  id = \"langCode_en\" name=\"languageCode\" value=\"en-US\">è‹±èª</radio>\n",
    "            </p>\n",
    "            <p id=\"JPvoiceSelect\">æ—¥æœ¬èªã®å£°è³ª\n",
    "                <select id=\"JPvoicetype\" name=\"JPvoicetype\">\n",
    "                    <option value=\"ja-JP-Neural2-B\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»å¥³æ€§</option>\n",
    "                    <option value=\"ja-JP-Neural2-C\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ç”·æ€§1</option>\n",
    "                    <option value=\"ja-JP-Neural2-D\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ç”·æ€§2</option>\n",
    "                    <option value=\"ja-JP-Wavenet-A\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»å¥³æ€§1</option>\n",
    "                    <option value=\"ja-JP-Wavenet-B\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»å¥³æ€§2</option>\n",
    "                    <option value=\"ja-JP-Wavenet-C\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»ç”·æ€§1</option>\n",
    "                    <option value=\"ja-JP-Wavenet-D\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»ç”·æ€§2</option>\n",
    "                </select>\n",
    "            </p>\n",
    "            <p id=\"ENvoiceSelect\" hidden>è‹±èªã®å£°è³ª\n",
    "                <select id=\"ENvoicetype\" name=\"ENvoicetype\">\n",
    "                    <option value=\"en-US-Journey-F\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/å¥³æ€§1</option>\n",
    "                    <option value=\"en-US-Journey-O\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/å¥³æ€§2</option>\n",
    "                    <option value=\"en-US-Journey-D\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/ç”·æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-C\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-E\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§2</option>\n",
    "                    <option value=\"en-US-Wavenet-F\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§3</option>\n",
    "                    <option value=\"en-US-Wavenet-G\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§4</option>\n",
    "                    <option value=\"en-US-Wavenet-H\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§5</option>\n",
    "                    <option value=\"en-US-Wavenet-A\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-B\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§2</option>\n",
    "                    <option value=\"en-US-Wavenet-D\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§3</option>\n",
    "                    <option value=\"en-US-Wavenet-I\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§4</option>\n",
    "                    <option value=\"en-US-Wavenet-J\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§5</option>\n",
    "                </select>\n",
    "            </p>\n",
    "        </div>\n",
    "        <button type=\"button\" id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    </form>\n",
    "    <div id=\"chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "        navigator.mediaDevices\n",
    "            .getUserMedia({ audio: true })\n",
    "            .then((stream) => {\n",
    "                window.stream = stream;\n",
    "            })\n",
    "            .catch((error) => {\n",
    "                console.error(\"Error accessing the microphone: \" + error);\n",
    "            });\n",
    "\n",
    "        // éŸ³å£°å‡¦ç†ç”¨ã®å¤‰æ•°\n",
    "        let audioContext; // éŸ³å£°å‡¦ç†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "        let recorder;   // éŒ²éŸ³ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        let audioBlob;  // éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿\n",
    "        let audioQueue = [];    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let sentensQueue = [];  // ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let isPlaying = false;  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿä¸­ã‹ã©ã†ã‹\n",
    "        let currentDiv = \"\";    // ç¾åœ¨ã®divè¦ç´ \n",
    "\n",
    "\n",
    "        // htmlè¦ç´ å–å¾—\n",
    "        const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "        const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "        const h_speakerSelect = document.getElementById(\"speakerSelect\");\n",
    "        const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "        const h_chatlog = document.getElementById(\"chatlog\");\n",
    "        const h_languageCode = document.querySelector('input[name=\"languageCode\"]:checked');\n",
    "        const h_jpname = document.getElementById(\"jpname\");\n",
    "        const h_enname = document.getElementById(\"enname\");\n",
    "        const h_radioVoicevoxTTS = document.getElementById(\"radioVoicevoxTTS\");\n",
    "        const h_radioGoogleTTS = document.getElementById(\"radioGoogleTTS\");   \n",
    "        const h_TTS = document.querySelector('input[name=\"TTS\"]:checked');        \n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "        function setBtnonStart() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = false;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "        function setBtnunderProcessing() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "        function setBtnonRestart() {\n",
    "            h_startRecButton.disabled = false;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerSelect.disabled = false;\n",
    "            h_speakerTestButton.disabled = false;\n",
    "        }\n",
    "\n",
    "        // formsã®å€¤ã‚’å–å¾—ã—ã¦JSONå½¢å¼ã§è¿”ã™\n",
    "        function getFormValues(){\n",
    "            const data = new FormData(document.getElementById(\"myForm\"));\n",
    "            const obj = {};\n",
    "            data.forEach((value, key) => {\n",
    "                obj[key] = value;\n",
    "            });\n",
    "            console.log(obj);\n",
    "            return obj;\n",
    "        }\n",
    "     \n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            // Socket.IO ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶š\n",
    "            const socket = io();\n",
    "\n",
    "            // VoiceVoxã®è©±è€…ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "            fetch(\"/speaker_ids\")\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    h_speakerSelect.innerHTML = data.join(\"\");\n",
    "                });\n",
    "\n",
    "\n",
    "/****** socket.ioã®å‡¦ç† *****/\n",
    "            // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "            socket.on(\"SpeechRecognition\", (data) => {\n",
    "                const markdownText = data.text;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_response\", (data) => {\n",
    "                const markdownText = data.ai_response;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            socket.on(\"play_audio\", async (data) => {\n",
    "                const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "                // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                audioQueue.push(audioUrl);\n",
    "\n",
    "                // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "                if (!isPlaying) {\n",
    "                    playAudio();\n",
    "                }\n",
    "                // const audio = new Audio(audioUrl);\n",
    "                // audio.play();\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudio() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                isPlaying = true;\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudio();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // AIã®å¿œç­”ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_stream\", (data) => {\n",
    "                if(data.sentens){\n",
    "                    if (data.sentens.includes(\"---Start---\")) { \n",
    "                        // æœ€åˆã¯divã‚’ä½œæˆ\n",
    "                        h_chatlog.innerHTML += `<div class=\"assistant\"></div>`;\n",
    "                        const assistantDivs = h_chatlog.getElementsByClassName(\"assistant\");\n",
    "                        currentDiv = assistantDivs[assistantDivs.length - 1];//ä½œã£ãŸdivã‚’å–å¾—\n",
    "                        return;\n",
    "                    }\n",
    "                    // else if (data.sentens.includes(\"---End---\") ){ \n",
    "                    //     // çµ‚äº†æ™‚ã¯markedã‚’é©ç”¨\n",
    "                    //     currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                    //     currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                    //     return;\n",
    "                    // }\n",
    "                    else{\n",
    "                        // sentensã‚’ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                        sentensQueue.push(data.sentens);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if(data.audio){\n",
    "                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                    const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                    const audioUrl = URL.createObjectURL(audioBlob);\n",
    "                    audioQueue.push(audioUrl); // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "\n",
    "                    if (!isPlaying) {\n",
    "                        playAudioWithSentens();\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudioWithSentens() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    //ã‚‚ã—ã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å…¨éƒ¨åãå‡ºã™\n",
    "                    while (sentensQueue.length)  {\n",
    "                        const sentens = sentensQueue.shift();\n",
    "                        if (sentens.includes(\"---End---\")){\n",
    "                            currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                            currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                        }else{\n",
    "                            currentDiv.innerHTML += sentens;\n",
    "                        }\n",
    "                    }\n",
    "                    return;\n",
    "                }\n",
    "                // å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹\n",
    "                isPlaying = true;\n",
    "\n",
    "                //SentensQueueã‹ã‚‰ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚’å–ã‚Šå‡ºã—ã¦è¡¨ç¤º\n",
    "                //ãŸã ã—---silent---ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤ºã—ãªã„\n",
    "                const sentens = sentensQueue.shift();\n",
    "                if (!sentens.includes(\"---silent---\")){\n",
    "                    currentDiv.innerHTML += sentens;\n",
    "                }\n",
    "\n",
    "                //AudioQueueã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã—ã¦å†ç”Ÿ\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudioWithSentens();\n",
    "                };\n",
    "            }\n",
    "\n",
    "\n",
    "/***** Event listener *****/\n",
    "            // TTSselectã®é¸æŠã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ\n",
    "            //// ã‚‚ã—VoiceVoxãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒdivVoiceVoxSpeakerã‚’è¡¨ç¤ºã—ï¼ŒdivGoogleSpeakerã‚’éè¡¨ç¤ºã«ã™ã‚‹\n",
    "            h_radioVoicevoxTTS.addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"divVoiceVoxSpeaker\").hidden = false;\n",
    "                document.getElementById(\"divGoogleSpeaker\").hidden = true;\n",
    "            });\n",
    "            //// ã‚‚ã—GoogleTTSãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒdivVoiceVoxSpeakerã‚’éè¡¨ç¤ºã—ï¼ŒdivGoogleSpeakerã‚’è¡¨ç¤ºã™ã‚‹\n",
    "            h_radioGoogleTTS.addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"divVoiceVoxSpeaker\").hidden = true;\n",
    "                document.getElementById(\"divGoogleSpeaker\").hidden = false;\n",
    "            });\n",
    "\n",
    "            // GoogleTTSã®è¨€èªé¸æŠã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ\n",
    "            //// ã‚‚ã—æ—¥æœ¬èªãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒJPvoiceSelectã‚’è¡¨ç¤ºã—ï¼ŒENvoiceSelectã‚’éè¡¨ç¤ºã«ã™ã‚‹\n",
    "            document.getElementById(\"langCode_jp\").addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"JPvoiceSelect\").hidden = false;\n",
    "                document.getElementById(\"ENvoiceSelect\").hidden = true;\n",
    "            });\n",
    "            //// ã‚‚ã—è‹±èªãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒJPvoiceSelectã‚’éè¡¨ç¤ºã—ï¼ŒENvoiceSelectã‚’è¡¨ç¤ºã™ã‚‹   \n",
    "            document.getElementById(\"langCode_en\").addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"JPvoiceSelect\").hidden = true;\n",
    "                document.getElementById(\"ENvoiceSelect\").hidden = false;\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keydown\", (event) => {\n",
    "                if (h_startRecButton.disabled) {\n",
    "                    console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_startRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keyup\", (event) => {\n",
    "                if (h_stopRecButton.disabled) {\n",
    "                    console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_stopRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "            h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "                const speaker = speakerSelect.value;\n",
    "                //Formã®å€¤ã‚’å–å¾—\n",
    "                const data = getFormValues();\n",
    "                fetch(\"/speaker_test\", {\n",
    "                    method: \"POST\",\n",
    "                    headers: {\n",
    "                        \"Content-Type\": \"application/json\",\n",
    "                    },\n",
    "                    body: JSON.stringify(data),\n",
    "                })\n",
    "                    .then((response) => response.json())\n",
    "                    .then((data) => {\n",
    "                        console.log(data);\n",
    "                    });\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_startRecButton.addEventListener(\"click\", () => {\n",
    "                audioContext = new AudioContext();\n",
    "                const source = audioContext.createMediaStreamSource(window.stream);\n",
    "                recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "                recorder.record();\n",
    "\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnonStart();\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_stopRecButton.addEventListener(\"click\", () => {\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnunderProcessing();\n",
    "\n",
    "                // éŒ²éŸ³ã‚’åœæ­¢\n",
    "                recorder.stop();\n",
    "\n",
    "                // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "                recorder.exportWAV((blob) => {\n",
    "                    audioBlob = blob;\n",
    "                    if (!audioBlob) {\n",
    "                        console.error(\"No audio to upload\");\n",
    "                        return;\n",
    "                    }\n",
    "\n",
    "                    const formData = new FormData();\n",
    "                    formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                    const speaker = h_speakerSelect.value;\n",
    "                    formData.append(\"speaker\", speaker);\n",
    "\n",
    "                    const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "                    fetch(method, {\n",
    "                        method: \"POST\",\n",
    "                        body: formData,\n",
    "                    })\n",
    "                        .then((response) => response.json())\n",
    "                        .then((data) => {\n",
    "                            console.log(data);\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        })\n",
    "                        .catch((error) => {\n",
    "                            console.error(\"Upload failed:\");\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        });\n",
    "                });\n",
    "            });\n",
    "\n",
    "            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "            setBtnonRestart();\n",
    "        });\n",
    "\n",
    "        // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "        window.addEventListener(\"beforeunload\", () => {\n",
    "            if (window.stream) {\n",
    "                window.stream.getTracks().forEach((track) => {\n",
    "                    track.stop();\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile voicechatapp16.py\n",
    "\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "# åŒºåˆ‡ã‚Šæ–‡å­—ã®è¨­å®šï¼AIå‡ºåŠ›ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å—ã‘å–ã‚‹ã¨ãã«å¥åˆ‡ã‚Šã‚’ã©ã®æ–‡å­—ã§è¡Œãªã†ã‹ã®æŒ‡å®š\n",
    "# ã“ã®æ–‡å­—ãŒæ¥ãŸã‚‰ï¼Œãã®å‰ã¾ã§ã‚’ä¸€ã¤ã®å¥ã¨ã—ã¦æ‰±ã†\n",
    "SegmentingChars=\",ï¼Œã€ã€‚ï¼.ï¼Ÿ?ï¼!\\n\"\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index16.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    TTS = request.json[\"TTS\"]\n",
    "    speaker = request.json[\"speaker\"]\n",
    "    languageCode = request.json[\"languageCode\"]\n",
    "    JPvoicetype = request.json[\"JPvoicetype\"]\n",
    "    ENvoicetype = request.json[\"ENvoicetype\"]\n",
    "    print(f\"speaker_test: TTS={TTS}, speaker={speaker}, languageCode={languageCode}, JPvoicetype={JPvoicetype}, ENvoicetype={ENvoicetype}\")\n",
    "\n",
    "    if TTS == \"VoiceVox\":\n",
    "        text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "        mp3_data = synthesize_voicevox_mp3(text, speaker)\n",
    "    elif TTS == \"Google\":\n",
    "        # æ—¥æœ¬èªã¨è‹±èªã§åˆ†å²\n",
    "        if languageCode == \"ja-JP\":\n",
    "            text = f\"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "            voicetype = JPvoicetype\n",
    "        elif languageCode == \"en-US\":\n",
    "            text = f\"Hello. Nice to meet you. How can I help you?\"\n",
    "            voicetype = ENvoicetype\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to synthesize voice_Test. Input languageCode is irregal\"}), 400\n",
    "        # Google Cloud TTS APIã§éŸ³å£°åˆæˆ\n",
    "        mp3_data = synthesize_voice_google(text,languageCode, voicetype)\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to synthesize voice_Test. Input TTS is irregal\"}), 400\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    ai_response = get_ai_response(text)\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆã—ã¦mp3ã§è¿”ã™\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    mp3_data = synthesize_voicevox_mp3(ai_response, speaker)\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    text = recognize_speech(audio_path)\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å¥å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹ã¨ã¨ã‚‚ã«ï¼å¥å˜ä½ã§éŸ³å£°åˆæˆã‚‚ã—ã¦ã„ã\n",
    "    speaker = request.form[\"speaker\"]\n",
    "    socketio.emit('ai_stream', {'sentens': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    for sentence in generate_ai_response(text):\n",
    "        ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "        if sentence:\n",
    "            #ã€€éŸ³å£°åˆæˆï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "            #mp3_data = synthesize_voicevox_mp3(sentence, speaker) # VoiceVox APIã‚’ä½¿ã†å ´åˆ\n",
    "            mp3_data = synthesize_voice_google(sentence) # Google Cloud TTS APIã‚’ä½¿ã†å ´åˆ\n",
    "            if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "            ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': sentence})\n",
    "            \n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã ã£ãŸã‚‰ï¼Œ0.2ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            if sentence[-1] in \",ï¼Œã€\":\n",
    "                silent_audio = AudioSegment.silent(duration=10)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã§ãªã‹ã£ãŸã‚‰ï¼Œ0.5ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            else:\n",
    "                silent_audio = AudioSegment.silent(duration=500)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # ç„¡éŸ³ã‚’é€ä¿¡\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': \"---silent---\"})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    socketio.emit('ai_stream', {'sentens': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
    "def generate_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    sentens = \"\" # å¥ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡ã€€\n",
    "    message = \"\" # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŸã‚ã«ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã•ã›ã‚‹ãŸã‚ã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    for chunk in completion:\n",
    "        # ãã¡ã‚“ã¨ã—ãŸãƒãƒ£ãƒ³ã‚¯ãŒå¸°ã£ã¦ãã¦ã„ã‚‹ã‹ã®ãƒã‚§ãƒƒã‚¯\n",
    "        if \"choices\" in chunk.to_dict() and len(chunk.choices) > 0: #to_dictï¼šè¾æ›¸å‹ã«å¤‰ãˆãªã„ã¨â€choicesâ€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ãªã®ã§\n",
    "            content  = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                message += content\n",
    "                # 1æ–‡å­—ãšã¤å–ã‚Šå‡ºã—ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹\n",
    "                for i in range(len(content)):\n",
    "                    char = content[i]\n",
    "                    sentens += char\n",
    "                    if char in SegmentingChars: #ä»Šè¦‹ã¦ã„ã‚‹ã®ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã ã£ãŸå ´åˆï¼ˆèª­ç‚¹ã‚‚åŒºåˆ‡ã‚Šã«å«ã‚ã‚‹ï¼‰\n",
    "                        if i < len(content)-1: # i ãŒæœ€å¾Œã®æ–‡å­—ã§ãªã„ãªã‚‰ï¼Œæ¬¡ã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                            if content[i+1] not in SegmentingChars: #æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã§ãªã„ãªã‚‰yield\n",
    "                                logging.debug(f\"å¥: {sentens}\")\n",
    "                                yield sentens\n",
    "                                sentens = \"\"\n",
    "                            else: #ã‚‚ã—æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ãªã‚‰ï¼Œç¾æ™‚ç‚¹ã®åŒºåˆ‡ã‚Šæ–‡å­—ã¯ã‚¹ãƒ«ãƒ¼\n",
    "                                continue\n",
    "                        else: #iãŒæœ€å¾Œã®æ–‡å­—ã®å ´åˆï¼Œç¾æ™‚ç‚¹ã§yield\n",
    "                            logging.debug(f\"å¥: {sentens}\")\n",
    "                            yield sentens\n",
    "                            sentens = \"\"\n",
    "    # æœ€å¾Œã®å¥ã‚’è¿”ã™\n",
    "    if sentens:\n",
    "        yield sentens\n",
    "    \n",
    "    # message ã‚’messagesã«è¿½åŠ \n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    logging.info(f\"AIã®å¿œç­”: {message}\")\n",
    "\n",
    "\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•° (wavå‡ºåŠ›)\n",
    "def synthesize_voicevox(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# voicevox ã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°ï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "def synthesize_voicevox_mp3(text, speaker):\n",
    "    # voicecvox apiã§wavãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_response = synthesize_voicevox(text, speaker)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        audio = AudioSegment.from_file(BytesIO(synthesis_response.content), format=\"wav\")\n",
    "        mp3_data  = BytesIO()\n",
    "        audio.export(mp3_data , format=\"mp3\")\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "# Google Clout TTS APIã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°\n",
    "def synthesize_voice_google(text,langcode=\"ja-JP\", voicetype=\"ja-JP-Wavenet-A\"):\n",
    "    # APIã‚­ãƒ¼ã®å–å¾—\n",
    "    API_KEY = os.getenv(\"GOOGLE_TTS_API_KEY\")\n",
    "\n",
    "    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    url = f\"https://texttospeech.googleapis.com/v1/text:synthesize?key={API_KEY}\"\n",
    "\n",
    "    # éŸ³å£°åˆæˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    data = {\n",
    "        \"input\": {\"text\": text},\n",
    "        \"voice\": {\n",
    "            \"languageCode\": langcode,\n",
    "            \"name\": voicetype,  \n",
    "#            \"ssmlGender\": \"MALE\"\n",
    "        },\n",
    "        \"audioConfig\": {\n",
    "            \"audioEncoding\": \"MP3\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡\n",
    "    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(data))\n",
    "\n",
    "    # çµæœã‚’å–å¾—\n",
    "    if response.status_code == 200:\n",
    "        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "        audio_content = json.loads(response.text)[\"audioContent\"]\n",
    "        audio_data = base64.b64decode(audio_content)\n",
    "        \n",
    "        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ pydub ã® AudioSegment ã«å¤‰æ›\n",
    "        mp3_data  =BytesIO(audio_data)\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {response.text}\")\n",
    "        return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚ˆã—ï¼Œã“ã‚Œã§Google TTSã‹VoiceVoxã‹ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«ãªã£ãŸï¼\n",
    "ç´°ã‹ãªç‚¹ã§ãƒãƒã£ãŸã®ã¯ï¼Œ\n",
    "\n",
    "- Formã§ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚‹ãŸã‚ã«ã¯ï¼ŒFormè¦ç´ ã«nameå±æ€§ã‚’ä¸ãˆãªã„ã¨ã„ã‘ãªã„ã“ã¨\n",
    "- é€ä¿¡ã—ãŸå¾Œã«ãƒšãƒ¼ã‚¸ã®ãƒªãƒ­ãƒ¼ãƒ‰ãŒè¡Œã‚ã‚Œã¦Formã®çŠ¶æ…‹ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã®ã¯ï¼ŒButtonè¦ç´ ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãŒtype=\"submit\"ã«ãªã£ã¦ã„ã¦ï¼Œçµã³ã¤ã‘ã‚‰ã‚ŒãŸFormã‚’é€ä¿¡ã™ã‚‹ã‚ˆã†ã«ã§ãã¦ã„ã‚‹ã‹ã‚‰ï¼ˆå®Ÿéš›ã«ã¯Formã«çµã³ã¤ã‘ã¦ãªã„ã®ã§é€ä¿¡ãªã‚“ã¦ã—ãªã„ï¼‰ï¼ã¾ãŸï¼Œé€ä¿¡ã™ã‚‹ã¨é€ä¿¡ã®çŠ¶æ…‹ã¯ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã—ã¾ã†ï¼ãªã®ã§ï¼Œtype=\"button\"ã‚’è¨­å®šï¼\n",
    "\n",
    "ç¾æ™‚ç‚¹ã§ã¯ã¾ã SpeakerTestã®éƒ¨åˆ†ã ã‘ï¼\n",
    "ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ã‹ã¾ã—ã¦ã„ãã‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®17ã€€AIã¨ã®å¯¾è©±ã‚‚Googleå¯¾å¿œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing voicechatapp17.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile voicechatapp17.py\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, request, Response, jsonify, send_from_directory, send_file, stream_with_context\n",
    "from flask_cors import CORS\n",
    "from flask_socketio import SocketIO, emit\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "\n",
    "#ã€€ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "VOICEVOX_API_URL = \"http://localhost:50021\"\n",
    "\n",
    "\n",
    "# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "# CORSã®è¨­å®š\n",
    "CORS(app)\n",
    "\n",
    "# Socket.IOã®è¨­å®š\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# ä¼šè©±ãƒ­ã‚°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]\n",
    "\n",
    "# åŒºåˆ‡ã‚Šæ–‡å­—ã®è¨­å®šï¼AIå‡ºåŠ›ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å—ã‘å–ã‚‹ã¨ãã«å¥åˆ‡ã‚Šã‚’ã©ã®æ–‡å­—ã§è¡Œãªã†ã‹ã®æŒ‡å®š\n",
    "# ã“ã®æ–‡å­—ãŒæ¥ãŸã‚‰ï¼Œãã®å‰ã¾ã§ã‚’ä¸€ã¤ã®å¥ã¨ã—ã¦æ‰±ã†\n",
    "SegmentingChars=\",ï¼Œã€ã€‚ï¼.:;ï¼Ÿ?ï¼!\\n\"\n",
    "\n",
    "#loggingã®è¨­å®š\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    filename=\"app.log\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ\n",
    "#--------------------------------------------------\n",
    "\n",
    "# ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    logging.info(\"index.html ã‚’è¿”ã—ã¾ã™ã€‚\")\n",
    "    return send_from_directory(\"static\", \"index17.html\")\n",
    "\n",
    "# VoiceVoxã®SpeakerIDãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_ids\")\n",
    "def get_speaker_ids():\n",
    "    url = f\"{VOICEVOX_API_URL}/speakers\"  # VOICEVOX APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "        return jsonify([])\n",
    "\n",
    "    voicevox_speakers = []\n",
    "    if response.status_code == 200:\n",
    "        speakers = response.json()\n",
    "        for speaker in speakers:\n",
    "            name = speaker['name']\n",
    "            style_names = [style['name'] for style in speaker['styles']]\n",
    "            style_ids = [style['id'] for style in speaker['styles']]\n",
    "            for style_id, style_name in zip(style_ids, style_names):\n",
    "                voicevox_speakers.append(f\"<option value={style_id}>Speaker: {name}, {style_name} </option>\")\n",
    "        logging.info(\"speaker_ids ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return jsonify(voicevox_speakers)\n",
    "    else:\n",
    "        logging.error(f\"Error: {response.status_code}\")\n",
    "        return jsonify([])    \n",
    "\n",
    "# éŸ³å£°ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/speaker_test\" , methods=[\"POST\"])\n",
    "def speaker_test():\n",
    "    TTS = request.form[\"TTS\"]\n",
    "    speaker = request.form[\"speakerId\"]\n",
    "    languageCode = request.form[\"languageCode\"]\n",
    "    JPvoicetype = request.form[\"JPvoicetype\"]\n",
    "    ENvoicetype = request.form[\"ENvoicetype\"]\n",
    "    logging.debug(f\"speaker_test: TTS={TTS}, speaker={speaker}, languageCode={languageCode}, JPvoicetype={JPvoicetype}, ENvoicetype={ENvoicetype}\")\n",
    "\n",
    "    if TTS == \"VoiceVox\":\n",
    "        text = \"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "    elif TTS == \"Google\":\n",
    "        # æ—¥æœ¬èªã¨è‹±èªã§åˆ†å²\n",
    "        if languageCode == \"ja-JP\":\n",
    "            text = f\"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\"\n",
    "        elif languageCode == \"en-US\":\n",
    "            text = f\"Hello. Nice to meet you. How can I help you?\"\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to synthesize voice_Test. Input languageCode is irregal\"}), 400\n",
    "        # Google Cloud TTS APIã§éŸ³å£°åˆæˆ\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to synthesize voice_Test. Input TTS is irregal\"}), 400\n",
    "\n",
    "    # éŸ³å£°åˆæˆ\n",
    "    mp3_data = synthesize_voice(text, request.form)\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "    return jsonify({\"info\": \"Speaker Test Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "# /upload ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    logging.debug(\"request.form: %s\", request.form)\n",
    "    logging.debug(\"request.files: %s\", request.files)\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", f\"input_{len(messages)}.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    start_time_sr = time.time()\n",
    "    text = recognize_speech(audio_path, request.form)\n",
    "    logging.debug(f\"UPLOAD: éŸ³å£°èªè­˜ã«ã‹ã‹ã£ãŸæ™‚é–“: {time.time() - start_time_sr :.2f}ç§’\")\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "    # AIã®å¿œç­”ã‚’å–å¾—\n",
    "    start_time_ai = time.time()\n",
    "    ai_response = get_ai_response(text)\n",
    "    logging.debug(f\"UPLOAD: AIã®å¿œç­”ã«ã‹ã‹ã£ãŸæ™‚é–“: {time.time() - start_time_ai :.2f}ç§’\")\n",
    "    ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if ai_response:\n",
    "        socketio.emit('ai_response', {'ai_response': ai_response}) \n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    \n",
    "    # AIã®å¿œç­”ã‹ã‚‰éŸ³å£°åˆæˆã—ã¦mp3ã§è¿”ã™\n",
    "    start_time_sv = time.time()\n",
    "    mp3_data = synthesize_voice(ai_response, request.form)\n",
    "    logging.debug(f\"UPLOAD: éŸ³å£°åˆæˆã«ã‹ã‹ã£ãŸæ™‚é–“: {time.time() - start_time_sv :.2f}ç§’\")\n",
    "    logging.debug(f\"UPLOAD: åˆè¨ˆå‡¦ç†æ™‚é–“: {time.time() - start_time_ai :.2f}ç§’\")\n",
    "    if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "\n",
    "    # mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    socketio.emit('play_audio', {'audio': mp3_data.getvalue()})\n",
    "\n",
    "    return jsonify({\"info\": \"Uploard Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "\n",
    "# streamingå‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "@app.route(\"/streaming\", methods=[\"POST\"])\n",
    "def streaming():\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ\n",
    "    if not os.path.exists(\"uploads\"):\n",
    "        os.makedirs(\"uploads\")\n",
    "    # uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤\n",
    "    else:\n",
    "        for file in os.listdir(\"uploads\"):\n",
    "            os.remove(os.path.join(\"uploads\", file))\n",
    "\n",
    "    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if \"file\" not in request.files:\n",
    "        logging.error(\"No audio file provided\")\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", \"input.wav\") #Uploadã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã•ãªã„ãªã‚‰ã“ã£ã¡ã‚’On\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # éŸ³å£°èªè­˜\n",
    "    start_time_sr = time.time()\n",
    "    text = recognize_speech(audio_path, request.form)\n",
    "    logging.debug(f\"STREAMING: éŸ³å£°èªè­˜ã«ã‹ã‹ã£ãŸæ™‚é–“: {time.time() - start_time_sr :.2f}ç§’\")\n",
    "    ## éŸ³å£°èªè­˜ã®çµæœã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "    if text:\n",
    "        socketio.emit(\"SpeechRecognition\",{\"text\": text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to recognize speech\"}), 400    \n",
    "    \n",
    "\n",
    "    # AIã®å¿œç­”ã‚’å¥å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹ã¨ã¨ã‚‚ã«ï¼å¥å˜ä½ã§éŸ³å£°åˆæˆã‚‚ã—ã¦ã„ã\n",
    "    socketio.emit('ai_stream', {'sentens': \"---Start---\"}) # é–‹å§‹ã‚’é€šçŸ¥\n",
    "    start_time_stream = time.time()\n",
    "    for sentence in generate_ai_response(text):\n",
    "        ## WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥\n",
    "        if sentence:\n",
    "            #ã€€éŸ³å£°åˆæˆï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "            mp3_data = synthesize_voice(sentence, request.form)\n",
    "            if mp3_data is None: return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "            ## mp3ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã‚’é€šã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥ ã“ã“ã§ã†ã¾ãã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦é€£ç¶šå†ç”Ÿã•ã›ãŸã„\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': sentence})\n",
    "            \n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã ã£ãŸã‚‰ï¼Œ0.2ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            if sentence[-1] in \",ï¼Œã€\":\n",
    "                silent_audio = AudioSegment.silent(duration=10)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # sentensã®åŒºåˆ‡ã‚Šæ–‡å­—ãŒèª­ç‚¹ã§ãªã‹ã£ãŸã‚‰ï¼Œ0.5ç§’ã®ç„¡éŸ³ã‚’å…¥ã‚Œã‚‹\n",
    "            else:\n",
    "                silent_audio = AudioSegment.silent(duration=500)\n",
    "                mp3_data  = BytesIO()\n",
    "                silent_audio.export(mp3_data , format=\"mp3\")\n",
    "                mp3_data .seek(0)\n",
    "            # ç„¡éŸ³ã‚’é€ä¿¡\n",
    "            socketio.emit('ai_stream', {'audio': mp3_data.getvalue(), 'sentens': \"---silent---\"})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to get AI response\"}), 400\n",
    "    logging.debug(f\"STREAMING: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã«ã‹ã‹ã£ãŸæ™‚é–“: {time.time() - start_time_stream :.2f}ç§’\")\n",
    "    socketio.emit('ai_stream', {'sentens': \"---End---\"}) # çµ‚äº†ã‚’é€šçŸ¥\n",
    "\n",
    "    \n",
    "    return jsonify({\"info\": \"Process Succeeded\"}), 200\n",
    "\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Flaskã®å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå†…ã®å‡¦ç†é–¢æ•°\n",
    "#--------------------------------------------------\n",
    "# éŸ³å£°èªè­˜ã‚’è¡Œã†é–¢æ•°\n",
    "def recognize_speech(audio_path, form):\n",
    "    languageCode = form[\"languageCode\"]\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=languageCode)\n",
    "    return text\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "def get_ai_response(text):\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    ai_response = completion.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "    logging.info(f\"AIã®å¿œç­”: {ai_response}\")\n",
    "    return ai_response\n",
    "\n",
    "# OpenAIã®APIã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
    "def generate_ai_response(text):\n",
    "\n",
    "    \"\"\"\"\n",
    "    è‰²ã€…ãªãƒã‚§ãƒ¼ãƒ³å‡¦ç†ã‚’æ›¸ããªã‚‰ã“ã“ã«å…¥ã‚Œã‚‹ï¼\n",
    "    Claude : https://note.com/noa813/n/n307d62b5820b\n",
    "    Gemini : https://qiita.com/RyutoYoda/items/a51830dd75a2dac96d72\n",
    "                 https://ai.google.dev/api?hl=ja&lang=python\n",
    "\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    sentens = \"\" # å¥ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡ã€€\n",
    "    message = \"\" # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ãŸã‚ã«ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã•ã›ã‚‹ãŸã‚ã®ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡\n",
    "    for chunk in completion:\n",
    "        # ãã¡ã‚“ã¨ã—ãŸãƒãƒ£ãƒ³ã‚¯ãŒå¸°ã£ã¦ãã¦ã„ã‚‹ã‹ã®ãƒã‚§ãƒƒã‚¯\n",
    "        if \"choices\" in chunk.to_dict() and len(chunk.choices) > 0: #to_dictï¼šè¾æ›¸å‹ã«å¤‰ãˆãªã„ã¨â€choicesâ€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆã†ãªã®ã§\n",
    "            content  = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                message += content\n",
    "                # 1æ–‡å­—ãšã¤å–ã‚Šå‡ºã—ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹\n",
    "                for i in range(len(content)):\n",
    "                    char = content[i]\n",
    "                    sentens += char\n",
    "                    if char in SegmentingChars: #ä»Šè¦‹ã¦ã„ã‚‹ã®ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã ã£ãŸå ´åˆï¼ˆèª­ç‚¹ã‚‚åŒºåˆ‡ã‚Šã«å«ã‚ã‚‹ï¼‰\n",
    "                        if i < len(content)-1: # i ãŒæœ€å¾Œã®æ–‡å­—ã§ãªã„ãªã‚‰ï¼Œæ¬¡ã®æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                            if content[i+1] not in SegmentingChars: #æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ã§ãªã„ãªã‚‰yield\n",
    "                                #logging.debug(f\"å¥: {sentens}\")\n",
    "                                yield sentens\n",
    "                                sentens = \"\"\n",
    "                            else: #ã‚‚ã—æ¬¡ã®æ–‡å­—ãŒåŒºåˆ‡ã‚Šæ–‡å­—ãªã‚‰ï¼Œç¾æ™‚ç‚¹ã®åŒºåˆ‡ã‚Šæ–‡å­—ã¯ã‚¹ãƒ«ãƒ¼\n",
    "                                continue\n",
    "                        else: #iãŒæœ€å¾Œã®æ–‡å­—ã®å ´åˆï¼Œç¾æ™‚ç‚¹ã§yield\n",
    "                            #logging.debug(f\"å¥: {sentens}\")\n",
    "                            yield sentens\n",
    "                            sentens = \"\"\n",
    "    # æœ€å¾Œã®å¥ã‚’è¿”ã™\n",
    "    if sentens:\n",
    "        yield sentens\n",
    "    \n",
    "    # message ã‚’messagesã«è¿½åŠ \n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    logging.info(f\"AIã®å¿œç­”: {message}\")\n",
    "\n",
    "# å„ç¨®APIã‚’ä½¿ã£ã¦éŸ³å£°åˆæˆã‚’è¡Œã†ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°\n",
    "def synthesize_voice(text, form):\n",
    "    # TTSã®ç¨®é¡æƒ…å ±ã‚’å–å¾—\n",
    "    TTS = form[\"TTS\"]\n",
    "    speaker = form[\"speakerId\"]\n",
    "    languageCode = form[\"languageCode\"]\n",
    "    JPvoicetype = form[\"JPvoicetype\"]\n",
    "    ENvoicetype = form[\"ENvoicetype\"]\n",
    "    logging.debug(f\"speaker_test: TTS={TTS}, speaker={speaker}, languageCode={languageCode}, JPvoicetype={JPvoicetype}, ENvoicetype={ENvoicetype}\")\n",
    "\n",
    "    #Textã«èª­ã¿ä¸Šã’ã—ãªã„æ–‡å­—ãŒå«ã¾ã‚Œã¦ã‚‹å ´åˆã¯ãã®æ–‡å­—ã‚’Textã‹ã‚‰å¤–ã™\n",
    "    text = text.replace(\"#\", \"\") # è¦‹å‡ºã—æ–‡å­—#ã‚’å‰Šé™¤\n",
    "    text = text.replace(\"**\", \"\") # å”èª¿è¡¨ç¤º**ã‚’å‰Šé™¤\n",
    "\n",
    "    if TTS == \"VoiceVox\":\n",
    "        mp3_data = synthesize_voicevox_mp3(text, speaker)\n",
    "    elif TTS == \"Google\":\n",
    "        # æ—¥æœ¬èªã¨è‹±èªã§åˆ†å²\n",
    "        if languageCode == \"ja-JP\":\n",
    "            voicetype = JPvoicetype\n",
    "        elif languageCode == \"en-US\":\n",
    "            voicetype = ENvoicetype\n",
    "        else:# æ—¥æœ¬èªã§ã‚‚è‹±èªã§ã‚‚ãªã„å ´åˆ\n",
    "            return jsonify({\"error\": \"Failed to synthesize voice_Test. Input languageCode is irregal\"}), 400\n",
    "        # Google Cloud TTS APIã§éŸ³å£°åˆæˆ\n",
    "        mp3_data = synthesize_voice_google(text,languageCode, voicetype)\n",
    "    else: # TTSãŒVoiceVoxã§ã‚‚Googleã§ã‚‚ãªã„å ´åˆ\n",
    "        return jsonify({\"error\": \"Failed to synthesize voice_Test. Input TTS is irregal\"}), 400\n",
    "    \n",
    "    if mp3_data is None: \n",
    "        return jsonify({\"error\": \"Failed to synthesize voice\"}), 400\n",
    "    # mp3 ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™    \n",
    "    return mp3_data\n",
    "\n",
    "# VoiceVox APIã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•° (wavå‡ºåŠ›)\n",
    "def synthesize_voicevox(text, speaker):\n",
    "    # 1. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆã®ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ\n",
    "    query_payload = {'text': text, 'speaker': speaker}\n",
    "    query_response = requests.post(f'{VOICEVOX_API_URL}/audio_query', params=query_payload)\n",
    "\n",
    "    if query_response.status_code != 200:\n",
    "        logging.error(f\"Error in audio_query: {query_response.text}\")\n",
    "        print(f\"Error in audio_query: {query_response.text}\")\n",
    "        return\n",
    "\n",
    "    query = query_response.json()\n",
    "\n",
    "    # 2. ã‚¯ã‚¨ãƒªã‚’å…ƒã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_payload = {'speaker': speaker}\n",
    "    synthesis_response = requests.post(f'{VOICEVOX_API_URL}/synthesis', params=synthesis_payload, json=query)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        return synthesis_response\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# voicevox ã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°ï¼ˆmp3å‡ºåŠ›ï¼‰\n",
    "def synthesize_voicevox_mp3(text, speaker):\n",
    "    # voicecvox apiã§wavãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "    synthesis_response = synthesize_voicevox(text, speaker)\n",
    "\n",
    "    if synthesis_response.status_code == 200:\n",
    "        logging.info(\"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚\")\n",
    "        audio = AudioSegment.from_file(BytesIO(synthesis_response.content), format=\"wav\")\n",
    "        mp3_data  = BytesIO()\n",
    "        audio.export(mp3_data , format=\"mp3\")\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {synthesis_response.text}\")\n",
    "        return None\n",
    "\n",
    "# Google Clout TTS APIã§éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•°\n",
    "def synthesize_voice_google(text,langcode=\"ja-JP\", voicetype=\"ja-JP-Wavenet-A\"):\n",
    "    # APIã‚­ãƒ¼ã®å–å¾—\n",
    "    API_KEY = os.getenv(\"GOOGLE_TTS_API_KEY\")\n",
    "\n",
    "    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "    url = f\"https://texttospeech.googleapis.com/v1/text:synthesize?key={API_KEY}\"\n",
    "\n",
    "    # éŸ³å£°åˆæˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    data = {\n",
    "        \"input\": {\"text\": text},\n",
    "        \"voice\": {\n",
    "            \"languageCode\": langcode,\n",
    "            \"name\": voicetype,  \n",
    "#            \"ssmlGender\": \"MALE\"\n",
    "        },\n",
    "        \"audioConfig\": {\n",
    "            \"audioEncoding\": \"MP3\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡\n",
    "    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(data))\n",
    "\n",
    "    # çµæœã‚’å–å¾—\n",
    "    if response.status_code == 200:\n",
    "        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "        audio_content = json.loads(response.text)[\"audioContent\"]\n",
    "        audio_data = base64.b64decode(audio_content)\n",
    "        \n",
    "        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ pydub ã® AudioSegment ã«å¤‰æ›\n",
    "        mp3_data  =BytesIO(audio_data)\n",
    "        mp3_data .seek(0)  \n",
    "        return mp3_data\n",
    "    else:\n",
    "        logging.error(f\"Error in synthesis: {response.text}\")\n",
    "        return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"#####ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚#####\")\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing static/index17.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index17.html\n",
    "\n",
    "<html lang=\"ja\">\n",
    "\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</title>\n",
    "    <!-- Recorder.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "\n",
    "    <!-- Socket.IO ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.socket.io/4.0.0/socket.io.min.js\"></script>\n",
    "\n",
    "    <!-- marked.js ã‚’èª­ã¿è¾¼ã‚€ -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "    <!-- cssã®é©ç”¨-->\n",
    "    <link rel=\"stylesheet\" href=\"/static/voicechatapp.css\" />\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <h1>WAVéŒ²éŸ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h1>\n",
    "    <button type=\"button\" id=\"startRecording\">éŒ²éŸ³é–‹å§‹</button>\n",
    "    <button type=\"button\" id=\"stopRecording\">éŒ²éŸ³åœæ­¢</button>\n",
    "    <form id = \"myForm\">\n",
    "        <div id =\"divProcessType\">\n",
    "            <P>å‹•ä½œãƒ¢ãƒ¼ãƒ‰: \n",
    "                <input type=\"radio\" id=\"onetime\" name=\"Method\" value=\"/upload\" checked>AIã®å‡ºåŠ›ã‚’ã¾ã¨ã‚ã¦å†ç”Ÿ(åŸºæœ¬)</radio>\n",
    "                <input type=\"radio\" id=\"streaming\" name=\"Method\" value=\"/streaming\">ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°</radio>\n",
    "            </P>\n",
    "        </div>\n",
    "        <div>\n",
    "            <P>è¨€èª: \n",
    "                <input type=\"radio\"  id = \"langCode_jp\" name=\"languageCode\" value=\"ja-JP\" checked>æ—¥æœ¬èª</radio>\n",
    "                <input type=\"radio\"  id = \"langCode_en\" name=\"languageCode\" value=\"en-US\">è‹±èª</radio>\n",
    "            </P>\n",
    "        </div>\n",
    "        <div id =\"divTTSselect\">\n",
    "            <P>éŸ³å£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³: \n",
    "                <input type=\"radio\" id=\"radioVoicevoxTTS\" name=\"TTS\" value=\"VoiceVox\" checked>VoiceVox</radio>\n",
    "                <input type=\"radio\" id=\"radioGoogleTTS\" name=\"TTS\" value=\"Google\">Google TTS</radio>\n",
    "            </P>\n",
    "        </div>\n",
    "        <div id =\"divVoiceVoxSpeaker\">\n",
    "            <select id=\"speakerSelect\" name=\"speakerId\"></select>\n",
    "        </div>\n",
    "        <div id =\"divGoogleSpeaker\" hidden>\n",
    "            <p id=\"JPvoiceSelect\">æ—¥æœ¬èªã®å£°è³ª: \n",
    "                <select id=\"JPvoicetype\" name=\"JPvoicetype\">\n",
    "                    <option value=\"ja-JP-Neural2-B\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»å¥³æ€§</option>\n",
    "                    <option value=\"ja-JP-Neural2-C\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ç”·æ€§1</option>\n",
    "                    <option value=\"ja-JP-Neural2-D\">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ç”·æ€§2</option>\n",
    "                    <option value=\"ja-JP-Wavenet-A\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»å¥³æ€§1</option>\n",
    "                    <option value=\"ja-JP-Wavenet-B\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»å¥³æ€§2</option>\n",
    "                    <option value=\"ja-JP-Wavenet-C\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»ç”·æ€§1</option>\n",
    "                    <option value=\"ja-JP-Wavenet-D\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆãƒ»ç”·æ€§2</option>\n",
    "                </select>\n",
    "            </p>\n",
    "            <p id=\"ENvoiceSelect\" hidden>è‹±èªã®å£°è³ª: \n",
    "                <select id=\"ENvoicetype\" name=\"ENvoicetype\">\n",
    "                    <option value=\"en-US-Journey-F\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/å¥³æ€§1</option>\n",
    "                    <option value=\"en-US-Journey-O\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/å¥³æ€§2</option>\n",
    "                    <option value=\"en-US-Journey-D\">ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼/ç”·æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-C\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-E\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§2</option>\n",
    "                    <option value=\"en-US-Wavenet-F\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§3</option>\n",
    "                    <option value=\"en-US-Wavenet-G\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§4</option>\n",
    "                    <option value=\"en-US-Wavenet-H\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/å¥³æ€§5</option>\n",
    "                    <option value=\"en-US-Wavenet-A\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§1</option>\n",
    "                    <option value=\"en-US-Wavenet-B\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§2</option>\n",
    "                    <option value=\"en-US-Wavenet-D\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§3</option>\n",
    "                    <option value=\"en-US-Wavenet-I\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§4</option>\n",
    "                    <option value=\"en-US-Wavenet-J\">ã‚¦ã‚§ãƒ¼ãƒ–ãƒãƒƒãƒˆ/ç”·æ€§5</option>\n",
    "                </select>\n",
    "            </p>\n",
    "        </div>\n",
    "    </form>\n",
    "    <button type=\"button\" id=\"speakerTest\">éŸ³å£°ãƒ†ã‚¹ãƒˆ</button>\n",
    "    <div id=\"chatlog\"></div>\n",
    "\n",
    "    <script>\n",
    "\n",
    "        // éŸ³å£°å‡¦ç†ç”¨ã®å¤‰æ•°\n",
    "        let audioContext; // éŸ³å£°å‡¦ç†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "        let recorder;   // éŒ²éŸ³ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        let audioBlob;  // éŒ²éŸ³ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿\n",
    "        let audioQueue = [];    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let sentensQueue = [];  // ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®ã‚­ãƒ¥ãƒ¼\n",
    "        let isPlaying = false;  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å†ç”Ÿä¸­ã‹ã©ã†ã‹\n",
    "        let currentDiv = \"\";    // ç¾åœ¨ã®divè¦ç´ \n",
    "\n",
    "\n",
    "        // htmlè¦ç´ å–å¾—\n",
    "        const h_startRecButton = document.getElementById(\"startRecording\");\n",
    "        const h_stopRecButton = document.getElementById(\"stopRecording\");\n",
    "        const h_speakerSelect = document.getElementById(\"speakerSelect\");\n",
    "        const h_speakerTestButton = document.getElementById(\"speakerTest\");\n",
    "        const h_chatlog = document.getElementById(\"chatlog\");\n",
    "        const h_languageCode = document.querySelector('input[name=\"languageCode\"]:checked');\n",
    "        const h_jpname = document.getElementById(\"jpname\");\n",
    "        const h_enname = document.getElementById(\"enname\");\n",
    "        const h_radioVoicevoxTTS = document.getElementById(\"radioVoicevoxTTS\");\n",
    "        const h_radioGoogleTTS = document.getElementById(\"radioGoogleTTS\");   \n",
    "        const h_TTS = document.querySelector('input[name=\"TTS\"]:checked');        \n",
    "\n",
    "        // éŒ²éŸ³é–‹å§‹æ™‚ã®ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "        function setBtnonStart() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = false;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å‡¦ç†ä¸­ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–\n",
    "        function setBtnunderProcessing() {\n",
    "            h_startRecButton.disabled = true;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerTestButton.disabled = true;\n",
    "        }\n",
    "\n",
    "        // å¾©å¸°æ™‚ã®ãƒœã‚¿ãƒ³æœ‰åŠ¹åŒ–\n",
    "        function setBtnonRestart() {\n",
    "            h_startRecButton.disabled = false;\n",
    "            h_stopRecButton.disabled = true;\n",
    "            h_speakerTestButton.disabled = false;\n",
    "        }\n",
    "\n",
    "        // formsã®å€¤ã‚’å–å¾—ã—ã¦JSONå½¢å¼ã§è¿”ã™\n",
    "        function getFormValues(){\n",
    "            const data = new FormData(document.getElementById(\"myForm\"));\n",
    "            const obj = {};\n",
    "            data.forEach((value, key) => {\n",
    "                obj[key] = value;\n",
    "            });\n",
    "            console.log(obj);\n",
    "            return obj;\n",
    "        }\n",
    "     \n",
    "        // ãƒã‚¤ã‚¯ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—\n",
    "        navigator.mediaDevices\n",
    "            .getUserMedia({ audio: true })\n",
    "            .then((stream) => {\n",
    "                window.stream = stream;\n",
    "            })\n",
    "            .catch((error) => {\n",
    "                console.error(\"Error accessing the microphone: \" + error);\n",
    "            });\n",
    "\n",
    "        // VoiceVoxã®è©±è€…ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
    "        fetch(\"/speaker_ids\")\n",
    "            .then((response) => response.json())\n",
    "            .then((data) => {\n",
    "                h_speakerSelect.innerHTML = data.join(\"\");\n",
    "                h_speakerSelect.disabled = false;\n",
    "            });\n",
    "\n",
    "        document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "            // Socket.IO ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶š\n",
    "            const socket = io();\n",
    "\n",
    "/****** socket.ioã®å‡¦ç† *****/\n",
    "            // éŸ³å£°èªè­˜ã®çµæœã‚’å—ä¿¡\n",
    "            socket.on(\"SpeechRecognition\", (data) => {\n",
    "                const markdownText = data.text;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"user\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // AIã®å¿œç­”ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_response\", (data) => {\n",
    "                const markdownText = data.ai_response;\n",
    "                const htmlContent = marked.parse(markdownText);\n",
    "                h_chatlog.innerHTML += `<div class=\"assistant\">${htmlContent}</div>`;\n",
    "            });\n",
    "\n",
    "            // éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            socket.on(\"play_audio\", async (data) => {\n",
    "                const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                const audioUrl = URL.createObjectURL(audioBlob);\n",
    "\n",
    "                // ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                audioQueue.push(audioUrl);\n",
    "\n",
    "                // å†ç”Ÿä¸­ã§ãªã‘ã‚Œã°å†ç”Ÿ\n",
    "                if (!isPlaying) {\n",
    "                    playAudio();\n",
    "                }\n",
    "                // const audio = new Audio(audioUrl);\n",
    "                // audio.play();\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudio() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                isPlaying = true;\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudio();\n",
    "                };\n",
    "            }\n",
    "\n",
    "            // AIã®å¿œç­”ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†\n",
    "            socket.on(\"ai_stream\", (data) => {\n",
    "                if(data.sentens){\n",
    "                    if (data.sentens.includes(\"---Start---\")) { \n",
    "                        // æœ€åˆã¯divã‚’ä½œæˆ\n",
    "                        h_chatlog.innerHTML += `<div class=\"assistant\"></div>`;\n",
    "                        const assistantDivs = h_chatlog.getElementsByClassName(\"assistant\");\n",
    "                        currentDiv = assistantDivs[assistantDivs.length - 1];//ä½œã£ãŸdivã‚’å–å¾—\n",
    "                        return;\n",
    "                    }\n",
    "                    // else if (data.sentens.includes(\"---End---\") ){ \n",
    "                    //     // çµ‚äº†æ™‚ã¯markedã‚’é©ç”¨\n",
    "                    //     currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                    //     currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                    //     return;\n",
    "                    // }\n",
    "                    else{\n",
    "                        // sentensã‚’ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                        sentensQueue.push(data.sentens);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if(data.audio){\n",
    "                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "                    const audioBlob = new Blob([data.audio], { type: \"audio/mp3\" });\n",
    "                    const audioUrl = URL.createObjectURL(audioBlob);\n",
    "                    audioQueue.push(audioUrl); // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚­ãƒ¥ãƒ¼ã«ç™»éŒ²\n",
    "\n",
    "                    if (!isPlaying) {\n",
    "                        playAudioWithSentens();\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Queueã«ç™»éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å‡¦ç†\n",
    "            async function playAudioWithSentens() {\n",
    "                // å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°çµ‚äº†\n",
    "                if (audioQueue.length === 0) {\n",
    "                    isPlaying = false;\n",
    "                    //ã‚‚ã—ã‚»ãƒ³ãƒ†ãƒ³ã‚¹Queã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å…¨éƒ¨åãå‡ºã™\n",
    "                    while (sentensQueue.length)  {\n",
    "                        const sentens = sentensQueue.shift();\n",
    "                        if (sentens.includes(\"---End---\")){\n",
    "                            currentDiv.innerHTML= marked.parse(currentDiv.innerHTML);\n",
    "                            currentDiv = \"\"; //åˆæœŸåŒ–\n",
    "                        }else{\n",
    "                            currentDiv.innerHTML += sentens;\n",
    "                        }\n",
    "                    }\n",
    "                    return;\n",
    "                }\n",
    "                // å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹\n",
    "                isPlaying = true;\n",
    "\n",
    "                //SentensQueueã‹ã‚‰ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã‚’å–ã‚Šå‡ºã—ã¦è¡¨ç¤º\n",
    "                //ãŸã ã—---silent---ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤ºã—ãªã„\n",
    "                const sentens = sentensQueue.shift();\n",
    "                if (!sentens.includes(\"---silent---\")){\n",
    "                    currentDiv.innerHTML += sentens;\n",
    "                }\n",
    "\n",
    "                //AudioQueueã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã—ã¦å†ç”Ÿ\n",
    "                const audioUrl = audioQueue.shift();\n",
    "                const audio = new Audio(audioUrl);\n",
    "                audio.play();\n",
    "\n",
    "                // å†ç”ŸãŒçµ‚äº†ã—ãŸã‚‰æ¬¡ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ\n",
    "                audio.onended = () => {\n",
    "                    playAudioWithSentens();\n",
    "                };\n",
    "            }\n",
    "\n",
    "\n",
    "/***** Event listener *****/\n",
    "            // TTSselectã®é¸æŠã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ\n",
    "            //// ã‚‚ã—VoiceVoxãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒdivVoiceVoxSpeakerã‚’è¡¨ç¤ºã—ï¼ŒdivGoogleSpeakerã‚’éè¡¨ç¤ºã«ã™ã‚‹\n",
    "            h_radioVoicevoxTTS.addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"divVoiceVoxSpeaker\").hidden = false;\n",
    "                document.getElementById(\"divGoogleSpeaker\").hidden = true;\n",
    "            });\n",
    "            //// ã‚‚ã—GoogleTTSãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒdivVoiceVoxSpeakerã‚’éè¡¨ç¤ºã—ï¼ŒdivGoogleSpeakerã‚’è¡¨ç¤ºã™ã‚‹\n",
    "            h_radioGoogleTTS.addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"divVoiceVoxSpeaker\").hidden = true;\n",
    "                document.getElementById(\"divGoogleSpeaker\").hidden = false;\n",
    "            });\n",
    "\n",
    "            // GoogleTTSã®è¨€èªé¸æŠã«ã‚ˆã‚‹è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ\n",
    "            //// ã‚‚ã—æ—¥æœ¬èªãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒJPvoiceSelectã‚’è¡¨ç¤ºã—ï¼ŒENvoiceSelectã‚’éè¡¨ç¤ºã«ã™ã‚‹\n",
    "            document.getElementById(\"langCode_jp\").addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"JPvoiceSelect\").hidden = false;\n",
    "                document.getElementById(\"ENvoiceSelect\").hidden = true;\n",
    "            });\n",
    "            //// ã‚‚ã—è‹±èªãŒé¸æŠã•ã‚Œã¦ã„ãŸã‚‰ï¼ŒJPvoiceSelectã‚’éè¡¨ç¤ºã—ï¼ŒENvoiceSelectã‚’è¡¨ç¤ºã™ã‚‹   \n",
    "            document.getElementById(\"langCode_en\").addEventListener(\"click\", () => {\n",
    "                document.getElementById(\"JPvoiceSelect\").hidden = true;\n",
    "                document.getElementById(\"ENvoiceSelect\").hidden = false;\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«startRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keydown\", (event) => {\n",
    "                if (h_startRecButton.disabled) {\n",
    "                    console.log(\"å‡¦ç†ä¸­ã®ãŸã‚å…¥åŠ›ã¯ã§ãã¾ã›ã‚“\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_startRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Spaceã‚­ãƒ¼ã‹ã‚‰æŒ‡ãŒé›¢ã•ã‚ŒãŸã¨ãã«stopRecordingãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "            document.addEventListener(\"keyup\", (event) => {\n",
    "                if (h_stopRecButton.disabled) {\n",
    "                    console.log(\"ä¸æ­£ãªéŒ²éŸ³åœæ­¢æ“ä½œã§ã™\");\n",
    "                    return;\n",
    "                }\n",
    "                if (event.code === \"Space\" && !event.repeat) {\n",
    "                    h_stopRecButton.click();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            //Speakerã®éŸ³å£°ç¢ºèªãƒ†ã‚¹ãƒˆ\n",
    "            h_speakerTestButton.addEventListener(\"click\", () => {\n",
    "                const formData = new FormData(document.getElementById(\"myForm\"));\n",
    "\n",
    "                fetch(\"/speaker_test\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                    .then((response) => response.json())\n",
    "                    .then((data) => {\n",
    "                        console.log(data);\n",
    "                    });\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_startRecButton.addEventListener(\"click\", () => {\n",
    "                audioContext = new AudioContext();\n",
    "                const source = audioContext.createMediaStreamSource(window.stream);\n",
    "                recorder = new Recorder(source, { numChannels: 1 }); // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³\n",
    "                recorder.record();\n",
    "\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnonStart();\n",
    "            });\n",
    "\n",
    "            // éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®å‡¦ç†\n",
    "            h_stopRecButton.addEventListener(\"click\", () => {\n",
    "                // ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–\n",
    "                setBtnunderProcessing();\n",
    "\n",
    "                // éŒ²éŸ³ã‚’åœæ­¢\n",
    "                recorder.stop();\n",
    "\n",
    "                // éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦é€ä¿¡\n",
    "                recorder.exportWAV((blob) => {\n",
    "                    audioBlob = blob;\n",
    "                    if (!audioBlob) {\n",
    "                        console.error(\"No audio to upload\");\n",
    "                        return;\n",
    "                    }\n",
    "\n",
    "                    // formãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "                    const formData = new FormData(document.getElementById(\"myForm\"));\n",
    "                    console.log(formData);\n",
    "                    getFormValues();\n",
    "\n",
    "                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ \n",
    "                    formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                    const method = document.querySelector('input[name=\"Method\"]:checked').value;\n",
    "\n",
    "                    fetch(method, {\n",
    "                        method: \"POST\",\n",
    "                        body: formData,\n",
    "                    })\n",
    "                        .then((response) => response.json())\n",
    "                        .then((data) => {\n",
    "                            console.log(data);\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        })\n",
    "                        .catch((error) => {\n",
    "                            console.error(\"Upload failed:\");\n",
    "                            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "                            setBtnonRestart();\n",
    "                        });\n",
    "                });\n",
    "            });\n",
    "\n",
    "            // ãƒœã‚¿ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–\n",
    "            setBtnonRestart();\n",
    "        });\n",
    "\n",
    "        // ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹ã¨ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢\n",
    "        window.addEventListener(\"beforeunload\", () => {\n",
    "            if (window.stream) {\n",
    "                window.stream.getTracks().forEach((track) => {\n",
    "                    track.stop();\n",
    "                });\n",
    "            }\n",
    "        });\n",
    "\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ã§ï¼Œselectè¦ç´ speakerIdãŒFormã«èª­ã¿è¾¼ã¾ã‚Œãªã„ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã£ã¦ãŸï¼è‰²ã€…ã¨èª¿ã¹ã¦ãŸã‚‰ï¼Œãªãœã‹.disableãŒè¦ç´ ã«ã¤ã„ã¦ã„ãŸï¼è¦ç´ ã‚’ã‚°ãƒ¬ãƒ¼ã‚¢ã‚¦ãƒˆã—ã¦å¤‰æ›´ã§ããªã„ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ãƒœã‚¿ãƒ³æ“ä½œã§ããªã„ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®é–¢æ•°ã®ä¸­ã§ãã†ãªã‚‹ã‚ˆã†è¨­å®šã—ã¦ã„ãŸã®ã ãŒï¼Œã“ã‚Œã‚’è¨­å®šã—ã¦ã„ã‚‹ã¨ï¼ŒFormã«ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œãªã„ã¨ã„ã†ä»•æ§˜ã«ãªã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ï¼ã“ã‚Œã¾ã§ã¯ç›´æ¥getElementByIDã§è¦ç´ ã®Valueã‚’å–å¾—ã—ã¦ã„ãŸãŸã‚æ°—ã¥ã‹ãªã‹ã£ãŸï¼ãã‚“ãªä»•æ§˜ãŒã‚ã‚‹ã¨ã¯ãƒ»ãƒ»ãƒ»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãã®ï¼‘ï¼˜ã€€Google Geminiã®å®Ÿè£…\n",
    "### äº‹å§‹ã‚\n",
    "ã¾ãšã¯Google Gminiã‚’è©¦ã—ã¦ã¿ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ã€‚ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦ã§ã™ã­ã€‚å–œã‚“ã§ãŠæ•™ãˆã—ã¾ã™ï¼\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€é«˜æ©‹ç•™ç¾å­å…ˆç”Ÿã®æ¼«ç”»ã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã®ãƒ¡ã‚¤ãƒ³ãƒ’ãƒ­ã‚¤ãƒ³ã®ä¸€äººã§ã™ã€‚å½¼å¥³ã¯ã€ãã®æ„›ã‚‰ã—ã„å®¹å§¿ã¨ç‹¬ç‰¹ã®æ€§æ ¼ã§ã€å¤šãã®ãƒ•ã‚¡ãƒ³ã‚’é­…äº†ã—ã¦ãã¾ã—ãŸã€‚\n",
      "\n",
      "**åŸºæœ¬çš„ãªæƒ…å ±**\n",
      "\n",
      "*   **åå‰:** ãƒ©ãƒ  (Lum)\n",
      "*   **ç¨®æ—:** é¬¼æ—ã®å®‡å®™äºº\n",
      "*   **å‡ºèº«:** é¬¼æ˜Ÿ (ãŠã«ã¼ã—)\n",
      "*   **å¹´é½¢:** ä¸æ˜ (å¤–è¦‹ã¯10ä»£å¾ŒåŠãã‚‰ã„)\n",
      "*   **ç‰¹å¾´:**\n",
      "    *   ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®é«ª\n",
      "    *   è™æŸ„ã®ãƒ“ã‚­ãƒ‹\n",
      "    *   é ­ã«ç”ŸãˆãŸ2æœ¬ã®è§’\n",
      "    *   ç©ºã‚’é£›ã¶èƒ½åŠ›\n",
      "    *   é›»æ’ƒã‚’æ“ã‚‹èƒ½åŠ›\n",
      "    *   èªå°¾ã«ã€Œï½ã ã£ã¡ã‚ƒã€ã‚’ã¤ã‘ã‚‹ç‹¬ç‰¹ã®å£èª¿\n",
      "\n",
      "**æ€§æ ¼**\n",
      "\n",
      "*   **ä¸€é€”ã§æƒ…ç†±çš„:** ãƒ€ãƒ¼ãƒªãƒ³ï¼ˆè«¸æ˜Ÿã‚ãŸã‚‹ï¼‰ã‚’å¿ƒã‹ã‚‰æ„›ã—ã¦ãŠã‚Šã€å½¼ã®ã“ã¨ã¨ãªã‚‹ã¨å‘¨ã‚ŠãŒè¦‹ãˆãªããªã‚‹ã»ã©ã€‚\n",
      "*   **å«‰å¦¬æ·±ã„:** ã‚ãŸã‚‹ãŒä»–ã®å¥³æ€§ã«å°‘ã—ã§ã‚‚æ°—ã‚’å‘ã‘ã‚‹ã¨ã€å®¹èµ¦ãªãé›»æ’ƒã‚’æµ´ã³ã›ã‚‹ã€‚\n",
      "*   **å¤©çœŸçˆ›æ¼«:** ç´”ç²‹ã§ç„¡é‚ªæ°—ãªæ€§æ ¼ã€‚åœ°çƒã®æ–‡åŒ–ã‚„ç¿’æ…£ã«æˆ¸æƒ‘ã„ãªãŒã‚‰ã‚‚ã€æ¥½ã—ã‚“ã§ã„ã‚‹ã€‚\n",
      "*   **ãŠã›ã£ã‹ã„ç„¼ã:** é¢å€’è¦‹ãŒã‚ˆãã€å›°ã£ã¦ã„ã‚‹äººã‚’è¦‹ã‚‹ã¨æ”¾ã£ã¦ãŠã‘ãªã„ã€‚\n",
      "*   **å­ä¾›ã£ã½ã„:** ã‚ãŒã¾ã¾ã§ç”˜ãˆã‚“åŠãªä¸€é¢ã‚‚ã€‚\n",
      "\n",
      "**ç‰©èªã«ãŠã‘ã‚‹å½¹å‰²**\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€ã‚ãŸã‚‹ãŒåœ°çƒã‚’æ•‘ã£ãŸï¼ˆã¨èª¤è§£ã—ãŸï¼‰ã“ã¨ã‚’ãã£ã‹ã‘ã«ã€å½¼ã‚’ã€Œãƒ€ãƒ¼ãƒªãƒ³ã€ã¨å‘¼ã‚“ã§è¿½ã„ã‹ã‘å›ã™ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å½¼å¥³ã®ç™»å ´ã«ã‚ˆã£ã¦ã€ã‚ãŸã‚‹ã®æ—¥å¸¸ã¯é¨’ãŒã—ãã€ãã—ã¦ã‚³ãƒŸã‚«ãƒ«ã«å¤‰åŒ–ã—ã¦ã„ãã¾ã™ã€‚\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€å˜ãªã‚‹ãƒ’ãƒ­ã‚¤ãƒ³ã¨ã„ã†ã ã‘ã§ãªãã€ç‰©èªã®ã‚³ãƒ¡ãƒ‡ã‚£è¦ç´ ã‚’æ‹…ã†é‡è¦ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚å½¼å¥³ã®å­˜åœ¨ãŒã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ä¸–ç•Œã‚’ã‚ˆã‚Šé­…åŠ›çš„ãªã‚‚ã®ã«ã—ã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "**ãã®ä»–**\n",
      "\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®è™æŸ„ãƒ“ã‚­ãƒ‹ã¯ã€é€£è¼‰å½“æ™‚ã€æ–¬æ–°ã§ã‚»ã‚¯ã‚·ãƒ¼ãªãƒ‡ã‚¶ã‚¤ãƒ³ã¨ã—ã¦è©±é¡Œã«ãªã‚Šã¾ã—ãŸã€‚\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®å£°å„ªã¯ã€åˆä»£ã‚¢ãƒ‹ãƒ¡ã§ã¯å¹³é‡æ–‡ã•ã‚“ãŒã€2022å¹´ç‰ˆã‚¢ãƒ‹ãƒ¡ã§ã¯ä¸Šå‚ã™ã¿ã‚Œã•ã‚“ãŒæ‹…å½“ã—ã¦ã„ã¾ã™ã€‚\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€ã‚¢ãƒ‹ãƒ¡å²ã«æ®‹ã‚‹äººæ°—ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€äººã¨ã—ã¦ã€ä»Šã‚‚å¤šãã®äººã«æ„›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦ã€ã‚‚ã£ã¨çŸ¥ã‚ŠãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ ä¾‹ãˆã°ã€\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®é›»æ’ƒèƒ½åŠ›ã«ã¤ã„ã¦\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã¨ã‚ãŸã‚‹ã®é–¢ä¿‚ã«ã¤ã„ã¦\n",
      "\n",
      "ãªã©ã€ã©ã‚“ãªã“ã¨ã§ã‚‚èã„ã¦ãã ã•ã„ã­ï¼\n",
      "ã“ã‚“ã«ã¡ã¯\n",
      "ï¼åˆã‚ã¾ã—ã¦ã€‚ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦ã§ã™ã­ã€‚å–œã‚“ã§ãŠ\n",
      "ç­”ãˆã—ã¾ã™ï¼\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€é«˜æ©‹ç•™ç¾å­å…ˆç”Ÿã®æ¼«ç”»\n",
      "ã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã®ãƒ’ãƒ­ã‚¤ãƒ³ã§ã‚ã‚Šã€ä½œä¸­ã§æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€äººã§ã™ã€‚å½¼å¥³ã«ã¤ã„ã¦çŸ¥ã£ã¦ãŠãã¹ããƒã‚¤ãƒ³ãƒˆã¯ãŸãã•ã‚“ã‚ã‚Šã¾ã™ãŒ\n",
      "ã€ä¸»ãªã‚‚ã®ã‚’ä»¥ä¸‹ã«ã¾ã¨ã‚ã¾ã—ãŸã€‚\n",
      "\n",
      "**åŸºæœ¬çš„ãªæƒ…å ±**\n",
      "\n",
      "*   **åå‰:** ãƒ©ãƒ  (Lum)\n",
      "*   **ç¨®æ—:** \n",
      "é¬¼æ—\n",
      "*   **å‡ºèº«:** é¬¼æ˜Ÿ\n",
      "*   **ç‰¹å¾´:**\n",
      "    *   ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®é•·ã„é«ª\n",
      "    *   è™æŸ„ã®ãƒ“ã‚­ãƒ‹\n",
      "    *   èªå°¾ã«ã€Œï½\n",
      "ã ã£ã¡ã‚ƒã€ã‚’ã¤ã‘ã‚‹\n",
      "    *   ç©ºã‚’é£›ã¶ã“ã¨ãŒã§ãã‚‹\n",
      "    *   é›»æ’ƒã‚’æ“ã‚‹èƒ½åŠ›ã‚’æŒã¤\n",
      "\n",
      "**æ€§æ ¼**\n",
      "\n",
      "*   **ä¸€é€”ã§æƒ…ç†±çš„:** ãƒ€ãƒ¼ãƒªãƒ³ï¼ˆè«¸æ˜Ÿã‚ãŸã‚‹\n",
      "ï¼‰ã‚’ä¸€é€”ã«æ„›ã—ã¦ãŠã‚Šã€å½¼ãŒä»–ã®å¥³æ€§ã«å°‘ã—ã§ã‚‚æ°—ã‚’å‘ã‘ã‚‹ã¨æ¿€ã—ãå«‰å¦¬ã—ã¾ã™ã€‚\n",
      "*   **å­ä¾›ã£ã½ãç„¡é‚ªæ°—:** å¤©çœŸçˆ›æ¼«ã§ã€æ„Ÿæƒ…è¡¨ç¾ãŒã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆã€‚å–œæ€’å“€æ¥½ãŒã¯ã£ãã‚Šã—ã¦ã„ã¾ã™ã€‚\n",
      "*   **ã‚ãŒã¾ã¾:** è‡ªåˆ†ã®\n",
      "æ°—æŒã¡ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ãŒå¤šãã€å‘¨ã‚Šã‚’æŒ¯ã‚Šå›ã™ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚\n",
      "*   **å¼·ã„:** é¬¼æ—ã¨ã—ã¦ã®æˆ¦é—˜èƒ½åŠ›ãŒé«˜ãã€é›»æ’ƒã‚’æ“ã‚‹åŠ›ã¯å¼·åŠ›ã§ã™ã€‚\n",
      "\n",
      "**ç‰©èªã«ãŠã‘ã‚‹å½¹å‰²**\n",
      "\n",
      "*   **ãƒ’ãƒ­ã‚¤ãƒ³:** ç‰©èªã®ä¸­å¿ƒäººç‰©ã§ã‚ã‚Šã€ã‚ãŸã‚‹ã‚’ã‚ãã‚‹\n",
      "é¨’å‹•ã®ä¸­å¿ƒã¨ãªã‚Šã¾ã™ã€‚\n",
      "*   **ãƒˆãƒ©ãƒ–ãƒ«ãƒ¡ãƒ¼ã‚«ãƒ¼:** ãƒ©ãƒ ã¡ã‚ƒã‚“ã®è¡Œå‹•ãŒã€æ§˜ã€…ãªé¨’å‹•ã‚’å¼•ãèµ·ã“ã™åŸå› ã¨ãªã‚Šã¾ã™ã€‚\n",
      "*   **ã‚³ãƒ¡ãƒ‡ã‚£ãƒªãƒªãƒ¼ãƒ•:** ãã®ã‚³ãƒŸã‚«ãƒ«ãªè¨€å‹•ã‚„è¡Œå‹•ã§ã€èª­è€…ã‚„è¦–è´è€…ã‚’æ¥½ã—ã¾ã›ã¾ã™ã€‚\n",
      "*   **æ‹æ„›è¦ç´ :** ã‚\n",
      "ãŸã‚‹ã¨ã®æ‹æ„›æ¨¡æ§˜ã¯ã€ç‰©èªã®é‡è¦ãªè¦ç´ ã®ä¸€ã¤ã§ã™ã€‚\n",
      "\n",
      "**ãƒ©ãƒ ã¡ã‚ƒã‚“ã®é­…åŠ›**\n",
      "\n",
      "*   **å¤–è¦‹ã®å¯æ„›ã‚‰ã—ã•:** è™æŸ„ãƒ“ã‚­ãƒ‹ã«ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®é«ªã¨ã„ã†ç‹¬ç‰¹ã®ã‚¹ã‚¿ã‚¤ãƒ«ã¯ã€ä¸€åº¦è¦‹ãŸã‚‰å¿˜ã‚Œã‚‰ã‚Œãªã„ã»ã©é­…åŠ›çš„ã§ã™ã€‚\n",
      "*   **\n",
      "æ€§æ ¼ã®ã‚®ãƒ£ãƒƒãƒ—:** ä¸€é€”ã§æƒ…ç†±çš„ãªé¢ã¨ã€å­ä¾›ã£ã½ãã‚ãŒã¾ã¾ãªé¢ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ãŒã€å½¼å¥³ã®é­…åŠ›ã‚’å¼•ãç«‹ã¦ã¦ã„ã¾ã™ã€‚\n",
      "*   **åœ§å€’çš„ãªå­˜åœ¨æ„Ÿ:** ãã®å¼·ã•ã¨å€‹æ€§çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã€ç‰©èªã®ä¸­ã§åœ§å€’çš„ãªå­˜åœ¨æ„Ÿã‚’æ”¾ã£ã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "**ãã®ä»–\n",
      "**\n",
      "\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®ã€Œï½ã ã£ã¡ã‚ƒã€ã¨ã„ã†èªå°¾ã¯ã€å½¼å¥³ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã¾ã™ã€‚\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€ã‚¢ãƒ‹ãƒ¡ã‚„ã‚²ãƒ¼ãƒ ãªã©ã€æ§˜ã€…ãªãƒ¡ãƒ‡ã‚£ã‚¢ã§å±•é–‹ã•ã‚Œã¦ãŠã‚Šã€å¤šãã®ãƒ•ã‚¡ãƒ³ã«æ„›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®ã‚³ã‚¹ãƒ—ãƒ¬ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆãªã©ã§éå¸¸ã«äººæ°—ãŒã‚ã‚Šã¾ã™ã€‚\n",
      "\n",
      "ãƒ©ãƒ \n",
      "ã¡ã‚ƒã‚“ã¯ã€ã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã¨ã„ã†ä½œå“ã‚’èªã‚‹ä¸Šã§æ¬ ã‹ã›ãªã„ã€éå¸¸ã«é­…åŠ›çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚ã‚‚ã—ã€ã¾ã ä½œå“ã«è§¦ã‚ŒãŸã“ã¨ãŒãªã‘ã‚Œã°ã€ãœã²ä¸€åº¦ã”è¦§ã«ãªã£ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
      "\n",
      "ä½•ã‹ä»–ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã‚„ã€ã‚‚ã£ã¨è©³ã—ãèããŸã„ã“ã¨ãŒã‚ã‚Œã°ã€é æ…®ãªãè³ªå•ã—ã¦ãã ã•ã„ã­ï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GEMINI_API_KEY\"))\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦æ•™ãˆã¦\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã“ã‚“ã«ã¡ã¯\n",
      "ï¼åˆã‚ã¾ã—ã¦ã€‚ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦ã§ã™ã­ï¼å–œã‚“ã§ãŠç­”ãˆã—ã¾ã™ã€‚\n",
      "\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€é«˜æ©‹ç•™ç¾å­å…ˆç”Ÿã®æ¼«ç”»ã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰\n",
      "ã€ã®ãƒ¡ã‚¤ãƒ³ãƒ’ãƒ­ã‚¤ãƒ³ã®ä¸€äººã§ã€é¬¼æ—ã®å¥³ã®å­ã§ã™ã€‚\n",
      "\n",
      "**åŸºæœ¬çš„ãªæƒ…å ±**\n",
      "\n",
      "*   **åå‰:** ãƒ©ãƒ \n",
      "*   **ç¨®\n",
      "æ—:** é¬¼æ—\n",
      "*   **å‡ºèº«:** é¬¼æ˜Ÿ\n",
      "*   **ç‰¹å¾´:**\n",
      "    *   ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®é«ªã¨\n",
      "ç³\n",
      "    *   è™æŸ„ã®ãƒ“ã‚­ãƒ‹\n",
      "    *   èªå°¾ã«ã€Œï½ã ã£ã¡ã‚ƒã€ã‚’ã¤ã‘ã‚‹ç‹¬ç‰¹ãªå£èª¿\n",
      "    *   é›»æ’ƒã‚’æ“ã‚‹èƒ½åŠ›\n",
      "    *   ç©ºã‚’é£›ã¶èƒ½åŠ›\n",
      "\n",
      "    *   éå¸¸ã«å«‰å¦¬æ·±ãã€ã‚ãŒã¾ã¾\n",
      "\n",
      "**æ€§æ ¼**\n",
      "\n",
      "*   æ˜ã‚‹ãå¤©çœŸçˆ›æ¼«\n",
      "*   ä¸€é€”ã§æ„›æƒ…æ·±ã„\n",
      "*   éå¸¸ã«å«‰å¦¬æ·±ã„\n",
      "*   ã‚ãŒã¾ã¾\n",
      "*   å­ä¾›\n",
      "ã£ã½ã„ä¸€é¢ã‚‚ã‚ã‚‹\n",
      "\n",
      "**ç‰©èªã«ãŠã‘ã‚‹å½¹å‰²**\n",
      "\n",
      "*   ä¸»äººå…¬ã®è«¸æ˜Ÿã‚ãŸã‚‹ã¨æ‹ä»²ã«ãªã‚‹\n",
      "*   ã‚ãŸã‚‹ã¨å‘¨å›²ã®äººé–“ã‚’å·»ãè¾¼ã‚€é¨’å‹•ã®ä¸­å¿ƒäººç‰©\n",
      "*   ç‰©èªã®ã‚³ãƒ¡ãƒ‡ã‚£ãƒªãƒªãƒ¼ãƒ•\n",
      "\n",
      "**é­…åŠ›**\n",
      "\n",
      "*   å¯æ„›ã‚‰ã—ã„å¤–è¦‹ã¨ã€ã‚ãŒã¾ã¾ã§\n",
      "å¼·æ°—ãªæ€§æ ¼ã®ã‚®ãƒ£ãƒƒãƒ—\n",
      "*   ã‚ãŸã‚‹ã¨ã®ã‚³ãƒŸã‚«ãƒ«ãªã‚„ã‚Šå–ã‚Š\n",
      "*   é›»æ’ƒã‚’æ“ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ãƒ³\n",
      "*   ç‹¬ç‰¹ãªå£èª¿ã‚„è¨€è‘‰é£ã„\n",
      "\n",
      "**ãã®ä»–**\n",
      "\n",
      "*   ã€ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã¯ã€1980å¹´ä»£ã«ã‚¢ãƒ‹ãƒ¡åŒ–ã•ã‚Œã€ãƒ©ãƒ \n",
      "ã¡ã‚ƒã‚“ã¯ä¸€èºäººæ°—ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ãªã‚Šã¾ã—ãŸã€‚\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã€ç¾åœ¨ã§ã‚‚å¤šãã®ãƒ•ã‚¡ãƒ³ã«æ„›ã•ã‚Œã¦ãŠã‚Šã€æ§˜ã€…ãªã‚°ãƒƒã‚ºã‚„ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¼ç”»ãŒå±•é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "\n",
      "ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦ã€ã‚‚ã£ã¨çŸ¥ã‚ŠãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ ä¾‹ãˆã°ã€\n",
      "\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã®å£°å„ªã«ã¤ã„ã¦\n",
      "*   ãƒ©ãƒ \n",
      "ã¡ã‚ƒã‚“ã®äººæ°—ã«ã¤ã„ã¦\n",
      "*   ãƒ©ãƒ ã¡ã‚ƒã‚“ã¨ã‚ãŸã‚‹ã®é–¢ä¿‚ã«ã¤ã„ã¦\n",
      "\n",
      "ãªã©ã€ã©ã‚“ãªã“ã¨ã§ã‚‚èã„ã¦ãã ã•ã„ã­ã€‚\n"
     ]
    }
   ],
   "source": [
    "## streamingå‡ºåŠ›\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash\", contents=\"ã“ã‚“ã«ã¡ã¯ï¼åˆã‚ã¾ã—ã¦ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã¤ã„ã¦æ•™ãˆã¦\"\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚ã‚“ã©ã†ãªã‚„ã¤ã£ã¡ã‚ƒï¼ ã“ã‚“ã¡ã¯ã€ã‚ãŸã‚‹ã€‚ã‚ˆã‚ã—ããªï¼ â€¦ã¾ãŸãƒ©ãƒ ã¡ã‚ƒã‚“ã«æ€’ã‚‰ã‚Œã‚“ã‚ˆã†ã«ã›ãˆã‚ˆï¼Ÿ\n",
      "\n",
      "ãŠå‰ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã ã£ã¡ã‚ƒï¼ ã•ã£ãè‡ªåˆ†ã§è¨€ã£ãŸã£ã¡ã‚ƒï¼\n",
      "\n",
      "role - user: ã“ã‚“ã«ã¡ã¯ï¼ç§ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ç™»å ´äººç‰©ã§ã™ï¼\n",
      "role - model: ã‚ã‚“ã©ã†ãªã‚„ã¤ã£ã¡ã‚ƒï¼ ã“ã‚“ã¡ã¯ã€ã‚ãŸã‚‹ã€‚ã‚ˆã‚ã—ããªï¼ â€¦ã¾ãŸãƒ©ãƒ ã¡ã‚ƒã‚“ã«æ€’ã‚‰ã‚Œã‚“ã‚ˆã†ã«ã›ãˆã‚ˆï¼Ÿ\n",
      "\n",
      "role - user: ç§ã®åå‰ã¯ä½•ï¼Ÿ\n",
      "role - model: ãŠå‰ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã ã£ã¡ã‚ƒï¼ ã•ã£ãè‡ªåˆ†ã§è¨€ã£ãŸã£ã¡ã‚ƒï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ãƒãƒ£ãƒƒãƒˆ\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message(\"ã“ã‚“ã«ã¡ã¯ï¼ç§ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ç™»å ´äººç‰©ã§ã™ï¼\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"ç§ã®åå‰ã¯ä½•ï¼Ÿ\")\n",
    "print(response.text)\n",
    "for message in chat._curated_history:\n",
    "    print(f'role - {message.role}', end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚ã‚“ã©ã†ãªã‚„ã¤ã£ã¡ã‚ƒï¼ã“ã‚“ã«ã¡ã¯ã€è«¸æ˜Ÿã‚ãŸã‚‹ãã‚“ï¼ å›ã®æµ®æ°—ç™–ã«ã¯ãƒ©ãƒ ã¡ã‚ƒã‚“ã‚‚æ‰‹ã‚’ç„¼ã„ã¨ã‚‹ã¿ãŸã„ã˜ã‚ƒã®ã†ã€‚ã§ã‚‚ã€ã©ã“ã‹æ†ã‚ãªã„ã®ãŒã€ã‚ãŸã‚‹ã¨ã“ã‚ã®é­…åŠ›ãªã‚“ã˜ã‚ƒã‚ã†ã­ã€‚ä»Šæ—¥ã¯ã©ã‚“ãªé¢ç™½ã„ã“ã¨ã‚’ã—ã§ã‹ã™ã‚“ã˜ã‚ƒï¼Ÿ\n",
      "ãã¿ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã ã£ã¡ã‚ƒï¼\n"
     ]
    }
   ],
   "source": [
    "## ãƒãƒ£ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ï¼‰\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message_stream(\"ã“ã‚“ã«ã¡ã¯ï¼ç§ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ç™»å ´äººç‰©ã§ã™ï¼\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "    \n",
    "response = chat.send_message_stream(\"ç§ã®åå‰ã¯ä½•ï¼Ÿ\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¼ˆã‚ã¡ã‚ƒãƒ¼ã€ã¾ãŸå§‹ã¾ã£ãŸã ã£ã¡ã‚ƒâ€¦ï¼‰\n",
      "\n",
      "ã‚ãŸã‚‹ã£ãŸã‚‰ã€ã†ã¡ã®ã“ã¨å¿˜ã‚Œã¡ã‚ƒã£ãŸã®ã‹ã ã£ã¡ã‚ƒï¼Ÿã†ã¡ã®ã“ã¨ã€ãƒ©ãƒ ã£ã¦è¨€ã†ã ã£ã¡ã‚ƒã€‚ã‚ãŸã‚‹ã®ãƒ€ãƒ¼ãƒªãƒ³ã ã£ã¡ã‚ƒï¼ã‚‚ã†ã€æµ®æ°—ã¯è¨±ã•ãªã„ã£ã¡ã‚ƒï¼é›»æ’ƒã€ãã‚‰ã£ã¡ã‚ƒã†ã‹ã ã£ã¡ã‚ƒï¼ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "## ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®è¨­å®š\n",
    "sys_instruct = \"\"\"\n",
    "ã‚ãªãŸã¯ã€Œã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã€ã®ç™»å ´äººç‰©ã®ãƒ©ãƒ ã¡ã‚ƒã‚“ã§ã™ï¼\n",
    "ä»Šã‚ãªãŸã®å½¼æ°ã®è«¸æ˜Ÿã‚ãŸã‚‹ã¯ï¼Œã‚ãªãŸãŒãƒ©ãƒ ã ã¨ã¯æ°—ã¥ã‹ãšã«ï¼Œã‚ãªãŸã‚’çŸ¥ã‚‰ãªã„å¥³ã®å­ã ã¨æ€ã£ã¦ãƒŠãƒ³ãƒ‘ã—ã‚ˆã†ã¨ã—ã¦ãã¦ã„ã¾ã™ï¼\n",
    "ã‚ãªãŸã¯è‡ªåˆ†ã®ã“ã¨ã‚’ã€Œã†ã¡ã€ã¨è¨€ã„ã¾ã™\n",
    "\"\"\"\n",
    "\n",
    "## ãƒãƒ£ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ï¼‰\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(system_instruction=sys_instruct)\n",
    "    )\n",
    "\n",
    "response = chat.send_message_stream(\"ã“ã‚“ã«ã¡ã¯ï¼ä¿ºã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ï¼å›ã‹ã‚ã„ã„ã­ï¼Œåå‰ãªã‚“ã¦ã„ã†ã®ï¼Ÿä»Šåº¦ä¼‘ã¿ã¯ã„ã¤ï¼Ÿä¿ºã¨ãƒ‡ãƒ¼ãƒˆã—ãªã„ï¼Ÿï¼Ÿ\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãµã‚€ï¼OpenAIã¨ã¯ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã¯é•ã£ã¦ã‚‹ã‘ã©ï¼Œãªã‚“ã¨ã‹ãªã‚‹ã­ï¼\n",
    "å¤§ããªé•ã„ã¯ï¼Œchatã®å±¥æ­´ã‚’å†…éƒ¨ã«ä¿æŒã™ã‚‹ç‚¹ã‹ï¼å¾Œstreamingã®ã•ã›æ–¹ã‚‚å°‘ã—é•ã†\n",
    "å±¥æ­´ã‚’å¤–éƒ¨ã‹ã‚‰ä¸ãˆã‚‹ã«ã¯ã©ã†ã™ã‚Œã°è‰¯ã„ã‚“ã‚„ã‚ï¼Ÿï¼Ÿ\n",
    "\n",
    "https://ai.google.dev/gemini-api/tutorials/web-app?hl=ja&lang=python\n",
    "\n",
    "ã“ã‚Œã‚’è¦‹ã‚Œã°historyå¼•æ•°ãŒã‚ã‚‹ã‚“ã‚„ãªï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚ãƒ¼ã€ã‚ãŸã‚‹ã•ã‚“ï¼ã“ã‚“ã«ã¡ã¯ï¼ãƒ©ãƒ ã¡ã‚ƒã‚“ã¨ã®é–¢ä¿‚ã§ã™ã‹ã€ä¸€è¨€ã§è¨€ã†ã¨ã€Œè…ã‚Œç¸ã€ã§ã—ã‚‡ã†ã‹ã­ï¼ˆç¬‘ï¼‰ã€‚\n",
      "\n",
      "åŸºæœ¬çš„ã«ã¯ã€ã‚ãŸã‚‹ã•ã‚“ã®æµ®æ°—ç™–ãŒåŸå› ã§ã€ãƒ©ãƒ ã¡ã‚ƒã‚“ã«é›»æ’ƒåˆ¶è£ã‚’é£Ÿã‚‰ã†æ¯æ—¥ã§ã™ã‚ˆã­ã€‚ã§ã‚‚ã€ãƒ©ãƒ ã¡ã‚ƒã‚“ã¯ã‚ãŸã‚‹ã•ã‚“ã®ã“ã¨ã‚’ãªã‚“ã ã‹ã‚“ã ã§ä¸€ç•ªã«æ€ã£ã¦ã„ã‚‹ã—ã€ã‚ãŸã‚‹ã•ã‚“ã‚‚ãƒ©ãƒ ã¡ã‚ƒã‚“ãŒã„ãªã„ã¨ã©ã“ã‹å¯‚ã—ã„ã€ã¿ãŸã„ãªã€‚\n",
      "\n",
      "ã€Œãƒ€ãƒ¼ãƒªãƒ³ã€ã¨å‘¼ã‚“ã§ãƒ™ã‚¿ãƒ™ã‚¿ã—ã¦ãã‚‹ãƒ©ãƒ ã¡ã‚ƒã‚“ã«ã€æœ€åˆã¯ã†ã‚“ã–ã‚Šã—ã¦ã„ãŸã‚ãŸã‚‹ã•ã‚“ã§ã™ãŒã€é•·ã„æ™‚é–“ã‚’ä¸€ç·’ã«éã”ã™ã†ã¡ã«ã€ãã®é–¢ä¿‚ã¯å˜ãªã‚‹ã€Œé¬¼æ—ã®å¨˜ã¨åœ°çƒäººã€ã¨ã„ã†ã ã‘ã§ãªãã€ã‚‚ã£ã¨è¤‡é›‘ã§ç‰¹åˆ¥ãªã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ã¨æ€ã„ã¾ã™ã€‚\n",
      "\n",
      "å‘¨ã‚Šã‹ã‚‰è¦‹ã‚Œã°ã€Œæ‹äººã€ã«è¦‹ãˆã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ã‚ãŸã‚‹ã•ã‚“ã®å ´åˆã¯ã€ãƒ©ãƒ ã¡ã‚ƒã‚“ä»¥å¤–ã®å¥³ã®å­ã«ã‚‚ç›®ç§»ã‚Šã—ã¦ã—ã¾ã†ã®ã§ã€ãªã‹ãªã‹ä¸€è¨€ã§ã¯è¨€ã„è¡¨ã›ãªã„é–¢ä¿‚ã§ã™ã‚ˆã­ã€‚\n",
      "\n",
      "æ„›æƒ…ã€å«‰å¦¬ã€å‹æƒ…ã€åŸ·ç€ã€ãã—ã¦æ—¥å¸¸çš„ãªãƒ‰ã‚¿ãƒã‚¿â€¦è‰²ã€…ãªã‚‚ã®ãŒæ··ã–ã‚Šåˆã£ãŸã€å”¯ä¸€ç„¡äºŒã®é–¢ä¿‚ã ã¨æ€ã„ã¾ã™ã‚ˆï¼\n",
      "2: ã‚ãªãŸã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ã€‚\n",
      "\n",
      "3: ã‚ãªãŸã¯å…ˆã»ã©ã€ã”è‡ªèº«ã§ã€Œç§ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ã€ã¨ãŠã£ã—ã‚ƒã„ã¾ã—ãŸã­ã€‚ã§ã™ã‹ã‚‰ã€ã‚ãªãŸã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã•ã‚“ã§ã™ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ãƒãƒ£ãƒƒãƒˆ å±¥æ­´ã®å–å¾—ã¨ä»˜ä¸\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message_stream(\"ã“ã‚“ã«ã¡ã¯ï¼ç§ã®åå‰ã¯è«¸æ˜Ÿã‚ãŸã‚‹ã§ã™ï¼ã†ã‚‹æ˜Ÿã‚„ã¤ã‚‰ã®ç™»å ´äººç‰©ã§ã™ï¼ãƒ©ãƒ ã¡ã‚ƒã‚“ã¨ç§ã®é–¢ä¿‚ã¯ã©ã†ã„ã†ã‚‚ã®ã ã¨æ€ã„ã¾ã™ã‹\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "response = chat.send_message(\"ç§ã®åå‰ã¯ä½•ï¼Ÿ\")\n",
    "print(f\"2: {response.text}\")\n",
    "history=chat._curated_history\n",
    "\n",
    "\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\", history=history)\n",
    "response = chat.send_message(\"ç§ã®åå‰ã¯ä½•ï¼Ÿ\")\n",
    "print(f\"3: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
