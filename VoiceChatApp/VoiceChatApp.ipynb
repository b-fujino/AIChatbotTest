{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask を使った簡易Webアプリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは必要なライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2898.53s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: flask_cors in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (5.0.1)\n",
      "Requirement already satisfied: speechrecognition in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (3.14.1)\n",
      "Requirement already satisfied: openai in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.63.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask->-r requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from speechrecognition->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: standard-aifc in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from speechrecognition->-r requirements.txt (line 3)) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from speechrecognition->-r requirements.txt (line 3)) (0.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from Jinja2>=3.1.2->flask->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 4)) (2.27.2)\n",
      "Requirement already satisfied: standard-chunk in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from standard-aifc->speechrecognition->-r requirements.txt (line 3)) (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その１　とりあえず音声ファイルをアップロードできるようにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>Voice Chat App</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Voice Chat App</h1>\n",
    "    <button id=\"start\">開始</button>\n",
    "    <button id=\"stop\" disabled>停止</button>\n",
    "    <p><strong>文字起こし:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIの応答:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "      document.addEventListener(\"DOMContentLoaded\", () => {\n",
    "        const startButton = document.getElementById(\"start\");\n",
    "        const stopButton = document.getElementById(\"stop\");\n",
    "        const transcriptionElement = document.getElementById(\"transcription\");\n",
    "        const aiResponseElement = document.getElementById(\"aiResponse\");\n",
    "        let mediaRecorder;\n",
    "        let audioChunks = [];\n",
    "\n",
    "        startButton.addEventListener(\"click\", async () => {\n",
    "          const stream = await navigator.mediaDevices.getUserMedia({\n",
    "            audio: true,\n",
    "          });\n",
    "          mediaRecorder = new MediaRecorder(stream);\n",
    "\n",
    "          mediaRecorder.ondataavailable = (event) => {\n",
    "            audioChunks.push(event.data);\n",
    "          };\n",
    "\n",
    "          mediaRecorder.onstop = async () => {\n",
    "            const audioBlob = new Blob(audioChunks, { type: \"audio/webm\" });\n",
    "            audioChunks = [];\n",
    "\n",
    "            const formData = new FormData();\n",
    "            formData.append(\"audio\", audioBlob, \"recording.webm\");\n",
    "\n",
    "            fetch(\"/upload\", {\n",
    "              method: \"POST\",\n",
    "              body: formData,\n",
    "            })\n",
    "              .then((response) => response.json())\n",
    "              .then((data) => {\n",
    "                transcriptionElement.textContent =\n",
    "                  data.text || \"認識できませんでした。\";\n",
    "                aiResponseElement.textContent =\n",
    "                  data.ai_response || \"AIの応答なし。\";\n",
    "              })\n",
    "              .catch((error) => {\n",
    "                console.error(\"Upload failed:\", error);\n",
    "                transcriptionElement.textContent = \"エラーが発生しました。\";\n",
    "                aiResponseElement.textContent = \"\";\n",
    "              });\n",
    "          };\n",
    "\n",
    "          mediaRecorder.start();\n",
    "          startButton.disabled = true;\n",
    "          stopButton.disabled = false;\n",
    "        });\n",
    "\n",
    "        stopButton.addEventListener(\"click\", () => {\n",
    "          mediaRecorder.stop();\n",
    "          startButton.disabled = false;\n",
    "          stopButton.disabled = true;\n",
    "        });\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app01.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app01.py\n",
    "\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "import os\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"audio\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"audio\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2909.93s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app01'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その２　アップロードした音声ファイルをWavファイルに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app02.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app02.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")  # フロントエンドのHTMLを表示\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"audio\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"audio\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    convert_webm_to_wav(audio_path, \"uploads/output.wav\")\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "\n",
    "def convert_webm_to_wav(input_path, output_path):\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_path,  # 入力ファイル\n",
    "        \"-ar\", \"16000\",  # サンプリングレート 16kHz\n",
    "        \"-ac\", \"1\",  # モノラル変換\n",
    "        \"-preset\", \"ultrafast\",  # 速度最優先\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "# 使い方\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app02'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "127.0.0.1 - - [26/Feb/2025 22:49:28] \"GET / HTTP/1.1\" 200 -\n",
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'uploads/recording.webm':\n",
      "  Metadata:\n",
      "    major_brand     : iso5\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isomiso5hlsf\n",
      "    creation_time   : 2025-02-26T13:49:33.000000Z\n",
      "  Duration: 00:00:04.89, start: 0.000000, bitrate: 184 kb/s\n",
      "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 181 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-02-26T13:49:33.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "\u001b[1;35m[out#0/wav @ 0x7fb9bba08740] \u001b[0m\u001b[0;33mCodec AVOption preset (Encoding preset) has not been used for any stream. The most likely reason is either wrong type (e.g. a video option with no video streams) or that it is a private option of some decoder which was not actually used for any stream.\n",
      "\u001b[0mStream mapping:\n",
      "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'output.wav':\n",
      "  Metadata:\n",
      "    major_brand     : iso5\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isomiso5hlsf\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-02-26T13:49:33.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 pcm_s16le\n",
      "\u001b[1;35m[out#0/wav @ 0x7fb9bba08740] \u001b[0mvideo:0KiB audio:153KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.049894%\n",
      "size=     153KiB time=00:00:04.88 bitrate= 256.1kbits/s speed= 168x    \n",
      "127.0.0.1 - - [26/Feb/2025 22:49:39] \"POST /upload HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app02.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換に少々時間取られるな．．．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その３　アップロードを直接Wavファイルにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換に少々時間がかかるのが気になるので，アップロードの段階で直接Wavファイルをアップできないか探ってみたら，Record.jsなるものがあるようだ．\n",
    "https://github.com/mattdiamond/Recorderjs\n",
    "Recorder.jsをダウンロードして\n",
    "これをhtmlに組み込んでみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index.html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>WAV録音＆アップロード</title>\n",
    "    <!-- Recorder.js を読み込む -->\n",
    "    <script src=\"https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs@master/dist/recorder.js\"></script>\n",
    "    <!-- <script src=\"recorder.js\"></script> --> \n",
    "    \n",
    "</head>\n",
    "<body>\n",
    "    <h1>WAV録音＆アップロード</h1>\n",
    "    <button id=\"startRecording\">録音開始</button>\n",
    "    <button id=\"stopRecording\" disabled>録音停止</button>\n",
    "    <!-- <audio id=\"audioPlayback\" controls></audio> -->\n",
    "    <!-- <button id=\"uploadAudio\" disabled>アップロード</button> -->\n",
    "    <p><strong>文字起こし:</strong> <span id=\"transcription\"></span></p>\n",
    "    <p><strong>AIの応答:</strong> <span id=\"aiResponse\"></span></p>\n",
    "\n",
    "    <script>\n",
    "        let audioContext;\n",
    "        let recorder;\n",
    "        let audioBlob;\n",
    "                \n",
    "\n",
    "        document.getElementById(\"startRecording\").addEventListener(\"click\", async () => {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "            audioContext = new AudioContext();\n",
    "            const source = audioContext.createMediaStreamSource(stream);\n",
    "            recorder = new Recorder(source, { numChannels: 1 }); // モノラル録音\n",
    "            recorder.record();\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = true;\n",
    "            document.getElementById(\"stopRecording\").disabled = false;\n",
    "        });\n",
    "\n",
    "        document.getElementById(\"stopRecording\").addEventListener(\"click\", () => {\n",
    "            recorder.stop();\n",
    "            recorder.exportWAV((blob) => {\n",
    "                audioBlob = blob;\n",
    "\n",
    "                if (!audioBlob) {\n",
    "                    console.error(\"No audio to upload\");    \n",
    "                    return;\n",
    "                }\n",
    "\n",
    "                const formData = new FormData();\n",
    "                formData.append(\"file\", audioBlob, \"recorded_audio.wav\");\n",
    "\n",
    "                fetch(\"/upload\", {\n",
    "                    method: \"POST\",\n",
    "                    body: formData,\n",
    "                })\n",
    "                .then((response) => response.json())\n",
    "                .then((data) => {\n",
    "                    document.getElementById(\"transcription\").textContent =\n",
    "                    data.text || \"認識できませんでした。\";\n",
    "                    document.getElementById(\"aiResponse\").textContent =\n",
    "                    data.ai_response || \"AIの応答なし。\";\n",
    "                })\n",
    "                .catch((error) => {\n",
    "                    console.error(\"Upload failed:\");\n",
    "                    document.getElementById(\"transcription\").textContent = \"エラーが発生しました。\";\n",
    "                    document.getElementById(\"aiResponse\").textContent = \"\";\n",
    "                });\n",
    "            });\n",
    "\n",
    "            document.getElementById(\"startRecording\").disabled = false;\n",
    "            document.getElementById(\"stopRecording\").disabled = true;\n",
    "\n",
    "\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3924.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app01'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:04] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1536, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1514, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/VoiceChatApp/app01.py\", line 9, in index\n",
      "    return send_from_directory(\"static\", \"index.html\")\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'send_from_directory' is not defined\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:04] \"GET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:04] \"GET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:04] \"GET /?__debugger__=yes&cmd=resource&f=console.png&s=0NSZQw8jg8v1WqT6MbPs HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:07] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1536, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1514, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages/flask/app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"/Users/fujinohidenori/dev/project/VoiceChatApp/app01.py\", line 9, in index\n",
      "    return send_from_directory(\"static\", \"index.html\")\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'send_from_directory' is not defined\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:07] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:07] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:07:07] \"\u001b[36mGET /?__debugger__=yes&cmd=resource&f=console.png&s=0NSZQw8jg8v1WqT6MbPs HTTP/1.1\u001b[0m\" 304 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORSの問題でアップロードで弾かれているようだ．．．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flask_corsを使って，サーバの側でCORS問題を無視するように設定する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask_cors\n",
      "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Requirement already satisfied: flask>=0.9 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask_cors) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask_cors) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from flask>=0.9->flask_cors) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/fujinohidenori/dev/project/venv/lib/python3.13/site-packages (from Werkzeug>=0.7->flask_cors) (3.0.2)\n",
      "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: flask_cors\n",
      "Successfully installed flask_cors-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app03.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app03.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "    \n",
    "    text = \"test\"\n",
    "    ai_response = \"test\"\n",
    "    return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4051.27s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app03'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "127.0.0.1 - - [27/Feb/2025 06:09:09] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Feb/2025 06:09:15] \"POST /upload HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よし，とりあえず問題は解決した．\n",
    "ハマった理由は，fetchのインタフェースをフォルダ名と勘違いしていたこと．つまり，app.routeでは/uploadとしているのに，javascriptの方で/uploadsとしていた．これにより当然ながらインタフェースがないわけで４０４エラーが返させるということになっていた．分れば馬鹿馬鹿しい勘違いやった😂\n",
    "\n",
    "あと，デバッグ環境ではルートディレクトリがprojectになるというところもハマった😂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その４　Speech Recognitionにかける\n",
    "よし，ここからはpythonの側の処理に集中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app04.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app04.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # 音声認識\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # デバッグモードの場合\n",
    "            print(text)\n",
    "            \n",
    "        ai_response = \"test\"\n",
    "        return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5082.37s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app04'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "127.0.0.1 - - [27/Feb/2025 06:26:20] \"GET / HTTP/1.1\" 200 -\n",
      "マイクテストマイクテストマイクテスト\n",
      "127.0.0.1 - - [27/Feb/2025 06:26:31] \"POST /upload HTTP/1.1\" 200 -\n",
      "マイクテストマイクテスト\n",
      "127.0.0.1 - - [27/Feb/2025 06:26:43] \"POST /upload HTTP/1.1\" 200 -\n",
      "こんにちは初めまして 藤野秀典 と言います\n",
      "127.0.0.1 - - [27/Feb/2025 06:26:54] \"POST /upload HTTP/1.1\" 200 -\n",
      "私の名前は 藤野秀典です あなたの名前は何ですか\n",
      "127.0.0.1 - - [27/Feb/2025 06:27:06] \"POST /upload HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その５　 openai の　Chat＿Compelationを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app05.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app05.py\n",
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__, static_folder=\"static\")  \n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_audio():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "    \n",
    "    audio_file = request.files[\"file\"]\n",
    "    audio_path = os.path.join(\"uploads\", audio_file.filename)\n",
    "    audio_file.save(audio_path)\n",
    "\n",
    "    # 音声認識\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "        text = r.recognize_google(audio, language=\"ja-JP\")\n",
    "        if __debug__: # デバッグモードの場合\n",
    "            print(text)\n",
    "\n",
    "        # AIの応答\n",
    "        client = OpenAI()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ]\n",
    "        )\n",
    "        ai_response = completion.choices[0].message.content\n",
    "        return jsonify({\"text\": text, \"ai_response\": ai_response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5911.99s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app05'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 286-038-734\n",
      "127.0.0.1 - - [27/Feb/2025 06:40:12] \"\u001b[36mGET / HTTP/1.1\u001b[0m\" 304 -\n",
      "こんにちは はじめまして\n",
      "127.0.0.1 - - [27/Feb/2025 06:40:22] \"POST /upload HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app05.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ふむ．とりあえずは単発会話はできるようになった．\n",
    "現時点の違和感・修正したい点は\n",
    "現状だと，入力テキストとレスポンスが同時に帰ってきてしまう．\n",
    "どうにか，その部分をいじれないか．レスポンスをまたつに先に入力テキストを返して，画面に表示させておいて，レスポンスが帰ってきたら，改めてそれを返すという感じ．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
